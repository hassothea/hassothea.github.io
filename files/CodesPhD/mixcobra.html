<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.358">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Sothea HAS">

<title>MixCOBRARegressor of gradientcobra v1.0.8 package</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="MixCOBRARegressor_files/libs/clipboard/clipboard.min.js"></script>
<script src="MixCOBRARegressor_files/libs/quarto-html/quarto.js"></script>
<script src="MixCOBRARegressor_files/libs/quarto-html/popper.min.js"></script>
<script src="MixCOBRARegressor_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="MixCOBRARegressor_files/libs/quarto-html/anchor.min.js"></script>
<link href="MixCOBRARegressor_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="MixCOBRARegressor_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="MixCOBRARegressor_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="MixCOBRARegressor_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="MixCOBRARegressor_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script type="text/javascript">
window.PlotlyConfig = {MathJaxConfig: 'local'};
if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}
if (typeof require !== 'undefined') {
require.undef("plotly");
requirejs.config({
    paths: {
        'plotly': ['https://cdn.plot.ly/plotly-2.20.0.min']
    }
});
require(['plotly'], function(Plotly) {
    window._Plotly = Plotly;
});
}
</script>


  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#installing-and-importing-packages" id="toc-installing-and-importing-packages" class="nav-link active" data-scroll-target="#installing-and-importing-packages">Installing and importing packages</a>
  <ul class="collapse">
  <li><a href="#importing-packages" id="toc-importing-packages" class="nav-link" data-scroll-target="#importing-packages">Importing packages</a></li>
  <li><a href="#simulated-data" id="toc-simulated-data" class="nav-link" data-scroll-target="#simulated-data">Simulated data</a>
  <ul class="collapse">
  <li><a href="#mixcobraregressor-with-default-parameters" id="toc-mixcobraregressor-with-default-parameters" class="nav-link" data-scroll-target="#mixcobraregressor-with-default-parameters"><code>MixCOBRARegressor</code> with default parameters</a></li>
  <li><a href="#mixcobraregressor-with-non-default-parameters" id="toc-mixcobraregressor-with-non-default-parameters" class="nav-link" data-scroll-target="#mixcobraregressor-with-non-default-parameters"><code>MixCOBRARegressor</code> with non-default parameters</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#real-dataset" id="toc-real-dataset" class="nav-link" data-scroll-target="#real-dataset">Real dataset</a>
  <ul class="collapse">
  <li><a href="#compare-to-adaboost" id="toc-compare-to-adaboost" class="nav-link" data-scroll-target="#compare-to-adaboost">Compare to Adaboost</a></li>
  </ul></li>
  <li><a href="#pretrained-basic-estimators" id="toc-pretrained-basic-estimators" class="nav-link" data-scroll-target="#pretrained-basic-estimators">Pretrained basic estimators</a></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">MixCOBRARegressor of <a href="https://pypi.org/project/gradientcobra/"><code>gradientcobra v1.0.8</code></a> package</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p><a href="https://hassothea.github.io/"><code>Sothea HAS</code></a> </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>

<section id="installing-and-importing-packages" class="level1">
<h1>Installing and importing packages</h1>
<p><a href="https://pypi.org/project/gradientcobra/">gradientcobra</a> can be installed from <a href="https://pypi.org/">pypi</a> using <code>pip</code>:</p>
<blockquote class="blockquote">
<p><code>pip install gradientcobra</code></p>
</blockquote>
<section id="importing-packages" class="level2">
<h2 class="anchored" data-anchor-id="importing-packages">Importing packages</h2>
<div id="f3c9c479" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Metric of error</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error, mean_absolute_error, mean_absolute_percentage_error</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting figures</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> cm</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Import class MixCOBRA from the mixcobra module of gradientcobra library</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gradientcobra.mixcobra <span class="im">import</span> MixCOBRARegressor</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>sns.<span class="bu">set</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="simulated-data" class="level2">
<h2 class="anchored" data-anchor-id="simulated-data">Simulated data</h2>
<p>We simulate a regression data with <span class="math inline">\(1000\)</span> observations and <span class="math inline">\(10\)</span> inputs variables.</p>
<div id="52052ba0" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># For simulating dataset</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_regression</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>X1, y1 <span class="op">=</span> make_regression(n_samples<span class="op">=</span><span class="dv">1000</span>, n_features<span class="op">=</span><span class="dv">10</span>, noise<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now, let’s randoly split the simulated data into <span class="math inline">\(80\%-20\%\)</span> training-testing data.</p>
<div id="99f501df" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>X_train1, X_test1, y_train1, y_test1 <span class="op">=</span> train_test_split(X1, y1, test_size<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'shape: x_train = </span><span class="sc">{}</span><span class="st"> , x_train = </span><span class="sc">{}</span><span class="st"> , y_train = </span><span class="sc">{}</span><span class="st"> , y_test = </span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    X_train1.shape, </span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    X_test1.shape, </span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    y_train1.shape, </span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    y_test1.shape))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>shape: x_train = (800, 10) , x_train = (200, 10) , y_train = (800,) , y_test = (200,)</code></pre>
</div>
</div>
<section id="mixcobraregressor-with-default-parameters" class="level3">
<h3 class="anchored" data-anchor-id="mixcobraregressor-with-default-parameters"><code>MixCOBRARegressor</code> with default parameters</h3>
<p>We create <code>MixCOBRARegressor</code> object called <code>gc1</code>, with the default parameters, then fit it to the training data.</p>
<blockquote class="blockquote">
<p>Note that by default, we use grid search algorithm to estimate the optimal parameter of the method.</p>
</blockquote>
<div id="a06f03ad" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>gc1 <span class="op">=</span> MixCOBRARegressor()</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>gc1_fit <span class="op">=</span> gc1.fit(X_train1, y_train1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    * Grid search algorithm of two parameters with radial kernel is in progress...
        ~ Full process|--------------------------------------------------|100%
        ~   Processing|==================================================|100%</code></pre>
</div>
</div>
<p>The estimated optimal bandwidth is given by <code>gc1.optimization_outputs['opt_bandwidth']</code>.</p>
<div id="bcfb8bc4" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># MixCOBRA with default parameter</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Estimated (alpha, beta) = (</span><span class="sc">{}</span><span class="st">, </span><span class="sc">{}</span><span class="st">)"</span>.<span class="bu">format</span>(gc1_fit.optimization_outputs[<span class="st">'opt_alpha'</span>], gc1_fit.optimization_outputs[<span class="st">'opt_beta'</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Estimated (alpha, beta) = (1e-05, 1.0606139393939396)</code></pre>
</div>
</div>
<p>We can look at the learning curve (surface) of the algorithm using <code>draw_learning_curve()</code> method.</p>
<div id="72016fe2" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>gc1_fit.draw_learning_curve()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>                            <div id="36279417-96d8-4a8e-9937-fe73b3fe3b7a" class="plotly-graph-div" style="height:450px; width:500px;"></div>            <script type="text/javascript">                require(["plotly"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("36279417-96d8-4a8e-9937-fe73b3fe3b7a")) {                    Plotly.newPlot(                        "36279417-96d8-4a8e-9937-fe73b3fe3b7a",                        [{"name":"Loss","opacity":0.8,"showlegend":false,"x":[1e-05,0.0505149494949495,0.10101989898989899,0.1515248484848485,0.202029797979798,0.2525347474747475,0.303039696969697,0.3535446464646465,0.404049595959596,0.4545545454545455,0.505059494949495,0.5555644444444444,0.606069393939394,0.6565743434343434,0.707079292929293,0.7575842424242424,0.8080891919191919,0.8585941414141415,0.9090990909090909,0.9596040404040405,1.0101089898989901,1.0606139393939396,1.111118888888889,1.1616238383838384,1.212128787878788,1.2626337373737375,1.313138686868687,1.3636436363636366,1.414148585858586,1.4646535353535355,1.515158484848485,1.5656634343434346,1.616168383838384,1.6666733333333335,1.717178282828283,1.7676832323232325,1.818188181818182,1.8686931313131314,1.919198080808081,1.9697030303030305,2.02020797979798,2.0707129292929296,2.121217878787879,2.1717228282828285,2.222227777777778,2.2727327272727273,2.323237676767677,2.3737426262626267,2.424247575757576,2.4747525252525255,2.525257474747475,2.5757624242424244,2.626267373737374,2.6767723232323233,2.727277272727273,2.7777822222222226,2.828287171717172,2.8787921212121215,2.929297070707071,2.9798020202020203,3.0303069696969698,3.0808119191919197,3.131316868686869,3.1818218181818185,3.232326767676768,3.2828317171717174,3.333336666666667,3.3838416161616163,3.434346565656566,3.4848515151515156,3.535356464646465,3.5858614141414145,3.636366363636364,3.6868713131313133,3.7373762626262628,3.7878812121212126,3.838386161616162,3.8888911111111115,3.939396060606061,3.9899010101010104,4.04040595959596,4.090910909090909,4.141415858585859,4.191920808080808,4.242425757575758,4.292930707070707,4.3434356565656564,4.393940606060606,4.444445555555555,4.494950505050505,4.545455454545454,4.595960404040404,4.646465353535353,4.696970303030303,4.747475252525253,4.797980202020202,4.848485151515152,4.898990101010101,4.949495050505051,5.0],"y":[1e-05,0.0505149494949495,0.10101989898989899,0.1515248484848485,0.202029797979798,0.2525347474747475,0.303039696969697,0.3535446464646465,0.404049595959596,0.4545545454545455,0.505059494949495,0.5555644444444444,0.606069393939394,0.6565743434343434,0.707079292929293,0.7575842424242424,0.8080891919191919,0.8585941414141415,0.9090990909090909,0.9596040404040405,1.0101089898989901,1.0606139393939396,1.111118888888889,1.1616238383838384,1.212128787878788,1.2626337373737375,1.313138686868687,1.3636436363636366,1.414148585858586,1.4646535353535355,1.515158484848485,1.5656634343434346,1.616168383838384,1.6666733333333335,1.717178282828283,1.7676832323232325,1.818188181818182,1.8686931313131314,1.919198080808081,1.9697030303030305,2.02020797979798,2.0707129292929296,2.121217878787879,2.1717228282828285,2.222227777777778,2.2727327272727273,2.323237676767677,2.3737426262626267,2.424247575757576,2.4747525252525255,2.525257474747475,2.5757624242424244,2.626267373737374,2.6767723232323233,2.727277272727273,2.7777822222222226,2.828287171717172,2.8787921212121215,2.929297070707071,2.9798020202020203,3.0303069696969698,3.0808119191919197,3.131316868686869,3.1818218181818185,3.232326767676768,3.2828317171717174,3.333336666666667,3.3838416161616163,3.434346565656566,3.4848515151515156,3.535356464646465,3.5858614141414145,3.636366363636364,3.6868713131313133,3.7373762626262628,3.7878812121212126,3.838386161616162,3.8888911111111115,3.939396060606061,3.9899010101010104,4.04040595959596,4.090910909090909,4.141415858585859,4.191920808080808,4.242425757575758,4.292930707070707,4.3434356565656564,4.393940606060606,4.444445555555555,4.494950505050505,4.545455454545454,4.595960404040404,4.646465353535353,4.696970303030303,4.747475252525253,4.797980202020202,4.848485151515152,4.898990101010101,4.949495050505051,5.0],"z":[[20269.809111212213,20265.766747960577,20261.72566012884,20257.68582345047,20253.647230804476,20249.60990309004,20245.573832748953,20241.539001813504,20237.505439212826,20233.47312210728,20229.44205022815,20225.412237775203,20221.383665637037,20217.35634475127,20213.330292278908,20209.305474788227,20205.281886585384,20201.259577519206,20197.238478140887,20193.218643207885,20189.200075948,20185.18272824348,20181.166628755098,20177.1517665569,20173.138164707732,20169.12579042901,20165.114662599073,20161.10476917197,20157.0961197585,20153.08870880839,20149.082539736082,20145.077613332516,20141.073929016173,20137.07146774485,20133.07026001479,20129.070265775772,20125.071530331767,20121.074017689254,20117.077739288958,20113.082697871778,20109.088891931653,20105.096313486087,20101.104971537858,20097.11486654778,20093.125985358438,20089.138331778166,20085.151915620863,20081.16671293136,20077.182745237285,20073.20002261774,20069.21851274775,20065.23823166907,20061.25917707781,20057.281346757394,20053.30474530052,20049.329371225896,20045.355197472407,20041.382270770395,20037.410561316872,20033.440084074937,20029.47080436955,20025.50277310738,20021.535946344633,20017.57033776198,20013.60594984317,20009.642785448246,20005.680839084285,20001.720109024314,19997.760591903894,19993.802291908807,19989.845205204874,19985.889343434246,19981.934688141937,19977.981252133497,19974.029042735645,19970.07801590009,19966.12821924687,19962.179629236307,19958.232248715296,19954.286080930888,19950.341135704166,19946.397375811535,19942.454854968084,19938.51351170129,19934.573390093523,19930.63448266717,19926.696759960967,19922.76025794846,19918.824961823007,19914.890866618163,19910.957996760844,19907.026299792135,19903.095813519427,19899.16654610143,19895.23846040805,19891.311597414493,19887.38591486278,19883.46144631098,19879.5381665625,19875.61609022747],[1010.3338755851904,1010.3192606696564,1010.3046579673153,1010.290056849846,1010.27546652805,1010.260843118885,1010.2461898103159,1010.2316565147352,1010.2170328415808,1010.2024171656925,1010.1878172822671,1010.1732354004525,1010.1585682222834,1010.143945208453,1010.1293335513801,1010.1147107436202,1010.1000824032402,1010.0854046184188,1010.0708342881999,1010.0562118049071,1010.0415480935959,1010.0269246146624,1010.0122972781677,1009.9976111406406,1009.9830632318788,1009.9683820392672,1009.953714964406,1009.9391202176288,1009.9244370269702,1009.9097251060499,1009.8951101438691,1009.8804728274099,1009.8657828086398,1009.8511407195125,1009.8364621711098,1009.8218276434961,1009.8071436488419,1009.7924803231032,1009.7778243426013,1009.7631360295666,1009.7484890907159,1009.7337768564654,1009.7191126712362,1009.7044134186877,1009.6897960351416,1009.6750647199797,1009.6604004538136,1009.6457110623105,1009.6310611946316,1009.6162959025921,1009.6016104651875,1009.5868916817341,1009.5722485536896,1009.5575263784951,1009.542847890508,1009.5281567543805,1009.5134252624728,1009.4987420659781,1009.4840149025962,1009.4692971475939,1009.4545747756905,1009.4398846626915,1009.4251500082506,1009.4103970905138,1009.3956810289928,1009.3809943874996,1009.3662836930835,1009.351508392682,1009.3367878297611,1009.3220246318986,1009.3073169437937,1009.2925656119111,1009.2778298246394,1009.2630790807167,1009.248400963785,1009.2336588468336,1009.2188700420025,1009.2041451284227,1009.18934816751,1009.1746522075857,1009.1598710893917,1009.1451260499282,1009.1303517635977,1009.1155962798193,1009.1008182620395,1009.0860751082691,1009.0712819502172,1009.0565738127013,1009.0417612555157,1009.0269942838908,1009.0122340371865,1008.9974428189832,1008.9826421366026,1008.9678782450061,1008.9530755096199,1008.9383234444298,1008.9235574947157,1008.908788391636,1008.8939536952263,1008.8792023613114],[452.02939463210396,452.0275221066521,452.0256017237696,452.0237781495974,452.02189054008676,452.02004304725006,452.018179505495,452.0163003486471,452.0144859445396,452.0126541721729,452.0108230531324,452.0089817342591,452.0071640613188,452.00534988791543,452.00355318427626,452.00176195957965,451.999969877058,451.99816761299627,451.99643155238454,451.994630849989,451.9928935501821,451.9911366434185,451.9893844056152,451.98763537417545,451.98586777945684,451.9841888054789,451.98244597893336,451.9806883064913,451.97905643403936,451.97728101549126,451.97560075174323,451.97393973524584,451.9722589240012,451.97059170744825,451.96891737436397,451.96724991683493,451.9655693359702,451.963952323997,451.9623106492694,451.9606276772556,451.9590333454356,451.9574073302994,451.95573223162563,451.95415294773255,451.9525394531526,451.95095500599444,451.9493333869732,451.9477825913374,451.9461722708896,451.9446149816853,451.94305930838243,451.9414933582768,451.9399557438927,451.93832158524435,451.9368597980115,451.9353198265011,451.9337638411247,451.9322416177712,451.9307622856697,451.9292228634011,451.9277238453371,451.926235702118,451.9247173693814,451.92325126078623,451.9217754235051,451.92030351887905,451.91881715232046,451.9174002148917,451.9159052151807,451.91448398791124,451.91303464484315,451.9116092347634,451.91017330832335,451.90877562721664,451.90734388456485,451.90589704387804,451.90455136686506,451.9031490399437,451.90175841138745,451.9003532651388,451.8989792875115,451.89762366020284,451.8962426443601,451.89486639971636,451.89352836343534,451.8921923230422,451.8907957184696,451.889515140722,451.8881667998421,451.88682131079366,451.88553179311674,451.88420083367765,451.882887544259,451.8816152643111,451.88028579202654,451.8790622842015,451.87776663479053,451.87647218016025,451.87523767790407,451.8739575929717],[288.1753125508569,288.17493387572915,288.1745695370428,288.17423051959196,288.1738846116815,288.1735516945946,288.1731987756336,288.1728935800227,288.1725863949087,288.17228429784427,288.1720400493217,288.17175184752307,288.17139789888506,288.17112110364496,288.17087591495084,288.17058045135724,288.1703480857902,288.1700844628831,288.1698224484606,288.16962838172856,288.1693252742573,288.16914788078674,288.16893089306376,288.16871380449766,288.16848027026106,288.1682962850543,288.168141501009,288.16794201326996,288.1677398046434,288.167585264756,288.1674228596702,288.1672617206026,288.16710764980223,288.1669596999637,288.16684204258206,288.16670774767556,288.1665811586141,288.1664657137418,288.1663279841359,288.166296561362,288.1661251678003,288.16603316988113,288.1659364293336,288.1659116718043,288.1658221236654,288.16574680098995,288.16568682668407,288.1656458629438,288.1655714151038,288.16551814263914,288.165480121752,288.16546366130063,288.16545343124335,288.1654346264133,288.1654556106121,288.1654276328372,288.16546695989337,288.16546879550083,288.16546178399693,288.1655038953364,288.16553719010614,288.1655559614759,288.16563156025035,288.165697835543,288.1657291028101,288.16576677853584,288.1658636494387,288.1659509891254,288.16601458139337,288.16610594261795,288.16620974077966,288.1663143989466,288.16640403345406,288.16655456194974,288.1666599109675,288.16678053507655,288.1669257265457,288.16706364818134,288.1672259087003,288.16737027707484,288.1675159081193,288.167688293017,288.1678938238359,288.1680450971303,288.16823488478497,288.16843550047935,288.1686071698855,288.1688147169542,288.1690476622209,288.16922588659037,288.1694742642366,288.16970714856996,288.1699600671275,288.17017337172547,288.17044287298484,288.17070452337873,288.1709171967078,288.17120778387743,288.17149189971764,288.17177211363315],[215.11736383828924,215.11712119320268,215.11687309420012,215.11663226315022,215.11638029628875,215.1161949754863,215.1159477737208,215.1157439939921,215.1155135990045,215.11533136960415,215.1151395470889,215.11494633023239,215.1147604270177,215.11456289783828,215.1144455860922,215.11424868162058,215.11409259680607,215.11394417408033,215.11380176621256,215.11365558053643,215.11353592304204,215.11342462360662,215.11329241115354,215.11318296825863,215.11309585557265,215.11299548762221,215.11286766880386,215.11278569844026,215.11270224766022,215.11265367697942,215.1125767985521,215.11251442976064,215.1124534426877,215.11241162907237,215.11236428704223,215.11231941299056,215.11230604171973,215.11226402421954,215.11223872520978,215.11222546709632,215.11222573401187,215.11224273326525,215.11226969780597,215.11225205215706,215.11228065159608,215.11228845689388,215.11232950626717,215.11239343526432,215.1124129143259,215.11247287086985,215.11252990241096,215.11259340686306,215.11267382256818,215.11270578411003,215.11281341288787,215.11288211906944,215.11299753874124,215.11310129075568,215.11317782372208,215.11329960366908,215.1134332882692,215.1135589381866,215.11365919371846,215.1138446956373,215.11396183023118,215.11411296664954,215.1142680846448,215.11442129298908,215.11460728521212,215.11475746122696,215.1149363624191,215.11509348645956,215.11532286356314,215.1155280923835,215.11572617507198,215.1159122283454,215.11612285127808,215.1163455819056,215.11658503110849,215.1168106023653,215.1170456927727,215.11729635521493,215.11755618258857,215.11778913523796,215.11804909834564,215.1183159426667,215.11859560434692,215.1188932678204,215.1191645963516,215.11946037634613,215.11975372827465,215.12007614021528,215.12039212076198,215.120706398535,215.12101114541414,215.12134496756056,215.1216717754698,215.1219926561626,215.1223560343679,215.1227033663833],[175.39509271745186,175.3945662670423,175.39413853911904,175.39367396988501,175.39318501303046,175.39269178493424,175.39228586425153,175.39182564402228,175.39140096170172,175.39093481313662,175.39053252822004,175.39010258710874,175.38969439330316,175.38927901218568,175.3888489796844,175.388457261668,175.38807085844695,175.38766750103133,175.38729472710145,175.38692663069847,175.38657014962845,175.38618654230285,175.3858397838326,175.38548017106848,175.38516302866017,175.38481826124575,175.38445801793864,175.38417101009867,175.38384355502737,175.383528896187,175.383209723115,175.38291353365182,175.38264603796407,175.3823246202848,175.38205693036346,175.38177651970742,175.38148247624417,175.38123197742573,175.38096348274516,175.38074727886342,175.38049545930156,175.38026498572657,175.380017616409,175.37979365668016,175.3796022124561,175.37935423633274,175.37914528575914,175.37895133513214,175.37875849207325,175.3785796741102,175.37840840881353,175.3782024049247,175.3780370231421,175.3778652342145,175.3777163537634,175.37755425257373,175.37741906627323,175.37725098690157,175.37714026482524,175.37699155584127,175.3768930035275,175.3767333486232,175.3766606238355,175.3765391310837,175.37644433269742,175.37635498758215,175.3762584047335,175.3761737662108,175.3760876024654,175.37603281450117,175.37595624728408,175.37590166490148,175.37584723611013,175.37579488769515,175.37576319967428,175.3757172217193,175.37571506594216,175.37569777080506,175.375668445667,175.37566394142598,175.37564275991818,175.37565365679842,175.37562803104444,175.37566627686027,175.37567652213872,175.37572251844315,175.37574972180218,175.3757988079583,175.37582518352968,175.3758491896802,175.37590600345442,175.37597467099775,175.3760407752307,175.37612537137946,175.37618268203627,175.37627335939263,175.37635710053814,175.37646054716373,175.37657426568336,175.3766820173317],[151.05720755355495,151.0565141463057,151.05582240056066,151.05518151062853,151.05449634405383,151.0538553550743,151.0531919390904,151.05255040520677,151.0519108334826,151.05127682876005,151.05064010830387,151.05002536894511,151.04940839228126,151.04881303260854,151.04818694685534,151.0476051092707,151.04701059799797,151.04643514071023,151.04586304196286,151.04527100451537,151.04471027350823,151.04416970512017,151.04360045117784,151.04307625745483,151.04251691798459,151.04196842127828,151.04145112193237,151.04094004671668,151.0403933773564,151.0399179488672,151.0393862558182,151.03889762396804,151.0384091062257,151.03792270963342,151.03742410656977,151.03696019854695,151.03650513090884,151.03605728765737,151.03558205823873,151.0351432625185,151.03469369156733,151.0342664627825,151.03383210525504,151.03340186958513,151.0329893348045,151.03258108289384,151.032173926498,151.03176615895495,151.03138347839104,151.03100181389016,151.0306054277236,151.03024603169254,151.0298412281629,151.02948295252213,151.02912442543126,151.02881092509872,151.02845411996796,151.0281061407499,151.02777527681818,151.0274570465067,151.0271206310939,151.0268150045469,151.0264912438152,151.02616985236008,151.0258875832278,151.0256115709392,151.02532094252413,151.0250133548521,151.02476459647772,151.02449939095013,151.02424550938872,151.02397923023776,151.023725221171,151.0235094728113,151.02325109620364,151.02302373897416,151.02280295290228,151.02257428544564,151.02236851734722,151.02214045427007,151.02194966231932,151.02174769856887,151.021568281615,151.02138673249752,151.02120777726174,151.02101844388648,151.0208802425874,151.02069115529733,151.02052483609754,151.02040846009234,151.02025381836907,151.02012490832257,151.01997917120474,151.0198443726943,151.0197406957212,151.0196166266848,151.01949636765895,151.01941788399319,151.0193135881131,151.0192152423428],[134.9783493296437,134.97762574914697,134.97685014800487,134.9761210617313,134.97539074238222,134.97468180466927,134.97394885763953,134.97326716864853,134.97258261441897,134.97184247327388,134.97120756436078,134.97048346959508,134.96979797888065,134.9691440593469,134.96846714963098,134.9678290909951,134.9671635950853,134.96650357161943,134.96588094595958,134.96527586191473,134.9646108968364,134.96401233881062,134.96339305844043,134.96277764390658,134.96218950132106,134.9615695960294,134.96096604762516,134.96041003551633,134.95985179970768,134.95925949407777,134.95867569144545,134.95814774577167,134.9575951801864,134.95702325388868,134.95646228265062,134.95595094955837,134.955413178142,134.95490923127178,134.95436065857388,134.95385611457908,134.95335601951973,134.95283831642593,134.95238894717673,134.95188731215183,134.95137263885937,134.95092715026695,134.95047747845825,134.9499988976126,134.9495442825109,134.9491341240992,134.9486562271631,134.9482237299805,134.9477768584105,134.94737540592095,134.9469381408217,134.94651759824774,134.9461127909329,134.94571416021284,134.94531773235474,134.9449176006334,134.94453510500588,134.94416828849324,134.9437813792716,134.94342446180755,134.94307020499522,134.94270900377097,134.94236864017995,134.94202018059406,134.9416847120596,134.94134507677617,134.94101316548196,134.94070463520833,134.94040234821284,134.9400918368661,134.93978944324914,134.93950731136468,134.93921875184526,134.93893736076376,134.9386833306621,134.93840388556936,134.9381285378849,134.93786471366053,134.9376192537597,134.93736944486716,134.93713184321885,134.93689074341518,134.93666848897743,134.93643846859453,134.9362342237601,134.9360166674303,134.93580061055286,134.93559182061122,134.9354043633377,134.9352146652229,134.93502288309472,134.9348693766694,134.9347049060818,134.93455300247868,134.93437257810407,134.93422870849437],[123.83127654698151,123.83060098556697,123.82993107046084,123.82927725560212,123.82863317491994,123.82794642997924,123.82734035315134,123.8266646655441,123.82603542150635,123.82542707283035,123.82482582831315,123.8241997184681,123.82359576200265,123.82300488759748,123.82241044360083,123.82182339109909,123.82124116678551,123.82066048178869,123.82010572620743,123.81953138322339,123.81897335947663,123.81842226938852,123.81785923602449,123.81733634102166,123.81682882488808,123.81629015125345,123.8157663700279,123.81523197821018,123.81475332631064,123.81424615237768,123.81375535996354,123.81326773515957,123.81278344230418,123.81230267176576,123.81183769196241,123.81136719611882,123.810898604557,123.81046854777576,123.80999146511526,123.80957177151006,123.80914248387663,123.80869055522419,123.80830275051794,123.80786284098266,123.80747459252947,123.80706721801216,123.80666759740109,123.80627301586124,123.80585998606348,123.80549946275323,123.80510933700664,123.80475103619241,123.80438590673464,123.8040361108505,123.80368657158033,123.80334145386,123.80300959992073,123.80266419254811,123.8023370631676,123.80201742085217,123.80171203295029,123.80141471400043,123.80110289108343,123.8008051346716,123.80050936125413,123.80022553041965,123.79993605012612,123.79967792896664,123.79940580663546,123.79915607141388,123.79890632050528,123.79865243688853,123.79839144866905,123.79817828260425,123.79792635193526,123.79772905714454,123.79750269289548,123.7972605771372,123.7970793162691,123.7968689610465,123.79668420181683,123.79649765938788,123.79629363652911,123.79612272733698,123.79594841814355,123.79576336166856,123.79563582847447,123.7954711737074,123.7953133134927,123.79520201406676,123.79503703842188,123.79491748885854,123.79478979664626,123.79468398488106,123.79454745518521,123.79443691537548,123.79434705799522,123.79424785208039,123.79415038704136,123.79407333481954],[115.86060187466516,115.86009842301249,115.85959622865077,115.8591208123225,115.85862677253775,115.85817001687614,115.85767677207407,115.85722468066842,115.85675811788644,115.85631533235035,115.85589056324962,115.85543227912731,115.85500576514774,115.85458580444313,115.85416867406222,115.85372965494996,115.85333285648092,115.8529152675537,115.85254479296036,115.85213712565454,115.85176858362578,115.85139899818651,115.85100656964016,115.85063613632649,115.85029387172855,115.84992585428328,115.84958942844779,115.84924050931996,115.84890144588307,115.84857084394801,115.84825620259008,115.84795903516617,115.84764565603908,115.8473094020854,115.8470274443436,115.84671543149685,115.84644523602715,115.84612681767017,115.84587645347499,115.84560353580625,115.8453313897526,115.84507963777826,115.84482379952121,115.84459072937196,115.84435325672762,115.8441120852843,115.84390468342603,115.84366519983516,115.84344326940888,115.84322723631878,115.84303692420386,115.84282773709656,115.84263345583963,115.84245206538223,115.8422812868226,115.84208455862696,115.84191951816703,115.8417413094198,115.84160490221605,115.84145588262194,115.84130634460264,115.8411523227553,115.84101301239737,115.84091034516807,115.84079641562225,115.84065305430389,115.84055962315506,115.84044637574303,115.84035307857907,115.84024869260065,115.84015904217881,115.84006427644358,115.84000086410988,115.83994406903908,115.83986736155244,115.83982120237106,115.83974403437325,115.83972593981999,115.8396700951558,115.83965276222568,115.83959872623043,115.83959242789228,115.83956509199967,115.83956837557284,115.83955403848961,115.83956071729081,115.83954267120896,115.83956311860156,115.83959067216952,115.83962630149327,115.839637085605,115.83966473068162,115.8397183033255,115.83975348311272,115.83980695541952,115.83984612754712,115.83993865101442,115.83996906560624,115.84005988629933,115.84013427691791],[110.04919757548176,110.04893661509948,110.0486918898808,110.04843243397363,110.04822424823541,110.0479573169553,110.04771235382432,110.04748977715892,110.04731587710891,110.04707883289953,110.0468603804183,110.0466523007519,110.04646152621697,110.04627185939623,110.04609870537884,110.0459290738244,110.04572392589007,110.04557079406477,110.04542258536954,110.04526545963438,110.04512142760908,110.0449811255028,110.04482140529701,110.04470976116022,110.04459573273951,110.04446871039283,110.04434143158926,110.04424386612781,110.04415292753951,110.04403329373551,110.04394441029618,110.04385288173194,110.04380138192444,110.04370431635053,110.04365584528728,110.04358386698497,110.0435312941765,110.04347779083278,110.0434367831484,110.04341115048855,110.04335322210633,110.04335959287084,110.04332933993192,110.04330602542537,110.04331768656535,110.04329408031724,110.04329118682426,110.04331207895268,110.0433435859986,110.04335576153399,110.04336996883701,110.04339927226883,110.04345840800052,110.04347797509433,110.04353012228903,110.04358232586158,110.04362779730509,110.04370690559021,110.04379792143975,110.04387812904663,110.04393113121338,110.04405620829068,110.04413082193659,110.04423869700663,110.04434026394918,110.04445080811595,110.04455297899362,110.04468041757612,110.04482906634416,110.0449443722268,110.04506494772315,110.04520757256446,110.04537019103353,110.04553257578964,110.04570703701711,110.04587149819884,110.0460533457677,110.04624328238621,110.04641901028731,110.04660423351538,110.04681030390972,110.04698844001571,110.04718921981082,110.04740949424843,110.04764292228928,110.04784957816976,110.04809437908789,110.0483483906446,110.04857052906839,110.04881593237519,110.04907368909414,110.0493298488042,110.04956373521517,110.04987586638643,110.05014988129054,110.05040532074989,110.05067552961086,110.05099622209934,110.05130343673909,110.05160669922641],[105.76346410848892,105.76347021997276,105.7635046237825,105.7634958862869,105.7635225167099,105.76355654801671,105.76358907900344,105.7636498585106,105.76367851258786,105.76373632457235,105.76380285735698,105.76388458721594,105.76396248957272,105.76400154127711,105.76408483963507,105.76417077876688,105.76427632505082,105.76439380276766,105.76448484898708,105.7646208275357,105.7647143043201,105.76483513506018,105.76494673797318,105.76508385427402,105.76523168121844,105.76535028613986,105.76552579467113,105.76566067142866,105.76583964065955,105.76601461734685,105.76617958017967,105.76636063471187,105.76655681983964,105.76672626957254,105.766945013643,105.76714249568322,105.76734323966056,105.76753993921575,105.76776920552977,105.76800213671861,105.76822920093886,105.76847291510839,105.76869062493522,105.76896059837993,105.7692038886659,105.76945691396914,105.76974098629,105.76998189449907,105.77024940074284,105.77053791825301,105.7708411632751,105.7711443656078,105.77140270741623,105.77172252547689,105.77203458923505,105.77233839203373,105.77266269525532,105.77297972407908,105.77330332929202,105.77364514688702,105.77397087456362,105.77435137821351,105.77466389629956,105.77502608186361,105.77540980163592,105.7757685906985,105.77616035550234,105.77651228940722,105.77693304579527,105.77726843155065,105.77768576967567,105.77806716782409,105.77849114712505,105.7789087236458,105.77931871958364,105.77975697544923,105.780173667671,105.78059840526552,105.78102618885971,105.78149517258751,105.78194411710228,105.78238113291818,105.78285258382648,105.78329643812249,105.78379057413807,105.78427730757524,105.78476449675952,105.78525382554513,105.78572739011611,105.78624224889252,105.78671972260672,105.7872438139512,105.7877528750488,105.78828217609825,105.78881040797907,105.7893355988233,105.7898863199883,105.79042031822833,105.79096848577242,105.79151741858834],[102.58586231697181,102.5861452071362,102.58644495339463,102.58673339356058,102.58701693301967,102.58732011384923,102.58763369737423,102.58792389631328,102.58824898769277,102.58859394099363,102.58891311963036,102.58926789989843,102.58962335327314,102.58995878526086,102.59028746623565,102.59066627229822,102.59103928844267,102.59139228931095,102.59175503921836,102.59215421441777,102.5925420523618,102.59292992848627,102.59332413248474,102.5937274437913,102.59416506820321,102.59458090268261,102.59499395135371,102.59543307793702,102.59582993886121,102.5962749300141,102.59672372622455,102.59713635953224,102.59761126092596,102.59806618579209,102.59850935824575,102.59897541107837,102.59945669059023,102.59992155465075,102.60040902932,102.60089439136746,102.601392662982,102.60188843116012,102.60238717882808,102.6029064490189,102.60342412136436,102.60393098413908,102.60448418731266,102.60501370588857,102.60553960755465,102.60610410988974,102.60663454402197,102.60720284482957,102.60777443267284,102.60831904483314,102.60889427406191,102.60946605488735,102.61004401841426,102.61064026567128,102.61123605726542,102.61183263055113,102.61242045860813,102.61305163127604,102.61360444751169,102.61425296321697,102.61486920758072,102.6155017764678,102.61611169956277,102.61675651882074,102.61742931120777,102.61807313036707,102.61871512010414,102.61938808601845,102.62004123593029,102.6207292644497,102.62138901851131,102.62209467090834,102.62276994942343,102.62346283591403,102.62416625039543,102.62484204119497,102.62553365628949,102.62627836583974,102.62698974593226,102.62770380755585,102.62843378737031,102.62914960575549,102.62989759386349,102.63064178972498,102.6313947022629,102.63214119356921,102.63290443963142,102.6336554452212,102.6344236462933,102.63520409438736,102.6359596597382,102.63679376516912,102.637567095354,102.63834168740452,102.63917610660341,102.63998504628725],[100.22915781545109,100.22968454150742,100.2302476020051,100.23077760706224,100.23135008883824,100.2319355970363,100.23251424635005,100.23307620787465,100.23364630252982,100.2342213833703,100.23482054676859,100.23544002180275,100.2360336357885,100.2366631698248,100.23722243359103,100.23785278808724,100.23847691521672,100.23912215213669,100.23973427847945,100.24039101332966,100.24102673764338,100.24167587795125,100.2423268684816,100.24298713425716,100.24365351718606,100.24430394000288,100.24498759060536,100.24568544842121,100.2463675474104,100.24704613482135,100.24771897644052,100.24843681564212,100.24915738137399,100.24985681079029,100.25059277287002,100.25127927600491,100.25201504872129,100.25273432749127,100.25347546841051,100.25423180428933,100.25498522732369,100.2557325443891,100.25647949591375,100.25723775408734,100.25799632428323,100.25878125693671,100.25955780336028,100.260345906708,100.26113831879896,100.26195171994459,100.26272039481168,100.26355231610133,100.26433538785282,100.265167599272,100.26599316994471,100.2668118230778,100.2676399088527,100.26848459464892,100.26931518408682,100.27016088086091,100.27102144739658,100.27185992596176,100.27273276004775,100.27359065830078,100.27446634757614,100.27533959543854,100.2762142250539,100.27710737026005,100.2779966013724,100.27889132324185,100.279788493783,100.28069911676707,100.28160238370792,100.2825316272762,100.28346521888318,100.28438687544482,100.2853022250067,100.28625995426385,100.28718777190147,100.28813649575451,100.2890877185234,100.29004301145203,100.29100589278433,100.29195658532869,100.29292301765585,100.29390718656693,100.29488763172955,100.29586584633094,100.2968486706049,100.29784985907239,100.29884936398034,100.29987125275194,100.30086412744674,100.30188918963147,100.30290886179735,100.30394027185433,100.3049688242813,100.3059918415336,100.3070393133462,100.30811319392049],[98.48915413903019,98.48992038000122,98.49071482435889,98.49151046770905,98.49230512325641,98.49311009953058,98.49392450887765,98.49473142152705,98.49555591232037,98.49638255754552,98.49720824735553,98.49805528254208,98.49888682638537,98.49971352554118,98.50057570012616,98.50141749145558,98.50229703935197,98.50312594574669,98.50401962682302,98.50489253719407,98.50577439973833,98.50664167710822,98.50752606547059,98.50841583858252,98.50930710047594,98.51021858358975,98.51115160028516,98.51206354325579,98.5129709540428,98.5139049369839,98.51482763934536,98.5157585775958,98.51670735757605,98.51764083347261,98.51856958720045,98.51954356977832,98.52050084838804,98.52147930202631,98.52241996896062,98.5234222769093,98.52439615549835,98.5253785641922,98.5263626612585,98.52735645583677,98.52835518368369,98.5293528110797,98.53034661815695,98.53138934074907,98.53239195458585,98.53342152229175,98.53446084664584,98.53548819235321,98.5365229929466,98.53755608878677,98.53861604359045,98.5396512380846,98.54072498080073,98.54177745736578,98.54283529177408,98.54393109477274,98.54499600057623,98.54605709278454,98.54716235759955,98.54825999861791,98.54934492195339,98.55044065490564,98.55154249315869,98.552655617834,98.55379330024275,98.5549363304039,98.55603488165181,98.55717354780963,98.55832024375744,98.55944041839595,98.56058926654487,98.5617391974426,98.56290005130244,98.56403799185856,98.56521667858058,98.56639794090623,98.56755778666081,98.568747095329,98.56993728877674,98.57111906320901,98.57234327665793,98.57350899923435,98.5747018310489,98.5759196537863,98.57713489629684,98.57836588216355,98.57956501321988,98.58081972493392,98.58205039603743,98.5832621188155,98.58451409769285,98.58578145717823,98.58701502665758,98.58827923294695,98.5895414727848,98.59079580623519],[97.21723989748224,97.21824686402525,97.2192584118867,97.22023239627791,97.22126247528684,97.22227248140105,97.2232964711292,97.22431519875741,97.22535426564943,97.22635630133273,97.22741270320374,97.22844991660286,97.2295153526231,97.2305764960775,97.23161631200922,97.2326963741684,97.23376716428277,97.2348151687747,97.23591496425976,97.23700664365529,97.23807593071365,97.23916465228244,97.24028103306762,97.24137544320007,97.24246796831923,97.24357780762276,97.24471652607994,97.24582573014543,97.24694255949058,97.24809504278831,97.24921383626865,97.25034952876015,97.25150349750956,97.25263670454999,97.2537981470515,97.25497808907399,97.25611956750133,97.25729187831267,97.25848098560985,97.25967920528399,97.26082261058511,97.26201561487774,97.26322862478024,97.26443121343765,97.26562080462449,97.26682344177682,97.26804194726145,97.26924927814582,97.27048008453099,97.27168241998723,97.27292574054312,97.27417089013599,97.2754105612356,97.27664386042444,97.27791078766293,97.27918443424467,97.28042223852947,97.28168993013203,97.2829538959704,97.28421874764697,97.28550540245251,97.28680565294515,97.28807150576881,97.2893749455989,97.29066149165646,97.29197788354298,97.29329960149879,97.29458072404013,97.29589637021371,97.29723713422322,97.29857741536641,97.29991021032272,97.30122150630613,97.30256542759754,97.3038944149051,97.30526498695119,97.30660419195378,97.30797841174672,97.30933593391185,97.31069978386981,97.31206436086995,97.31344992512071,97.3148263450806,97.31622481798341,97.31761400722525,97.3190031226806,97.32040621417066,97.32179934500721,97.32322251342585,97.32462082263108,97.32605003119552,97.32747430587631,97.32892620772789,97.33033080302604,97.33177674316656,97.3332179247976,97.33466520180093,97.3361101201166,97.33757743971515,97.33904706648882],[96.30327926380669,96.3044548161869,96.30567342092738,96.30685402830719,96.30803465638803,96.30920648485443,96.31043519212024,96.31163758674484,96.3128630278006,96.31406992727383,96.31532397071962,96.31653193927363,96.3177560548523,96.31898667339667,96.32024661404718,96.32147662000709,96.32271899510134,96.32398121766826,96.32525180753893,96.32651386923398,96.32780820293206,96.32906962184691,96.33034829922622,96.33163577436571,96.33289524554672,96.33420525741079,96.33549790801729,96.33680282019085,96.33812502017827,96.33943918016577,96.34072977713993,96.34207551234911,96.34338622324576,96.34473024602752,96.34606131924245,96.34738681495614,96.34874663367546,96.35008871050456,96.35145213936006,96.35279503748232,96.35417497484676,96.35553928206834,96.35691967539714,96.35828107223193,96.3596754043616,96.36105040159444,96.36244456892588,96.36382976462355,96.36520529224863,96.36663984515978,96.3680396385304,96.36943636637886,96.37089914874443,96.37229247137265,96.37374949472569,96.37514020053527,96.37657955929691,96.37803329634659,96.37948883519644,96.380931501426,96.38237582900805,96.38385757879784,96.38532141975472,96.38676130538622,96.38824910679514,96.38973195756928,96.39120129405863,96.39269046862023,96.39419732735315,96.39568017591873,96.39720797857899,96.3986755980576,96.40019567650208,96.4017159445958,96.40322620901149,96.40477154051064,96.40627362100078,96.4078032566142,96.40934342377952,96.41087822963662,96.41244037604227,96.41398691179367,96.41553872539677,96.41708799842208,96.41864409731703,96.42022499589473,96.42180297949055,96.4233767386347,96.42497200908834,96.42656286040156,96.42812543049973,96.42973129417982,96.43130715177716,96.43294191496761,96.43452518699063,96.43615674691817,96.43776277867171,96.43939410214516,96.44101750836306,96.44265170464885],[95.66483367872647,95.66618485755103,95.66753883670735,95.66888230914468,95.67022783550985,95.67158408192711,95.67297008233086,95.67433748842765,95.67569833486836,95.67706944004348,95.67845241209308,95.67982027925555,95.68120989057435,95.6826244439344,95.68402693702782,95.68541669837845,95.6868570460276,95.68823015331384,95.68966530983242,95.69107742362978,95.69251563070294,95.69392411557256,95.69538580844626,95.69682106977451,95.6982697626951,95.69972573613295,95.70115976658606,95.70262652473632,95.70408404462054,95.70556494437636,95.70704055998695,95.70850730130691,95.70999473442342,95.71146047932919,95.712963086359,95.71446825907876,95.71596375827372,95.71746599307673,95.71895878987485,95.7204900027455,95.72197888836709,95.72351452586281,95.72504446990001,95.72655710287754,95.72811932188789,95.72965489411106,95.73117570075894,95.73273976392248,95.7342720033793,95.73585631772838,95.7374045144673,95.73895932707919,95.74053424776551,95.74213074173647,95.7437023266859,95.74526898647034,95.74685946435488,95.74846419237522,95.75006968597239,95.75164970431112,95.75328095716779,95.75487758072123,95.75648040397151,95.75811459882343,95.75971856462024,95.76135263798072,95.76298412563236,95.76465163173144,95.76627952193785,95.76790246784982,95.76956639049016,95.77119898430139,95.77287702154783,95.77454222852455,95.77621155627453,95.77790443072796,95.7795726570955,95.78125121346157,95.7829195967885,95.7846101204324,95.7862950606591,95.78801235244399,95.78972094163713,95.79142558294545,95.79314675747924,95.7948458427235,95.79657874647054,95.79827480974443,95.80003922397205,95.80174494402331,95.80349088525202,95.80523577583234,95.80698396435422,95.80873042197321,95.81050459766763,95.81226980206552,95.81400306494625,95.81578557204466,95.81755166060135,95.819330513086],[95.23960760118105,95.24107390119532,95.24257290743184,95.24406953396488,95.24553626681839,95.24702115891435,95.2485269489172,95.25005059829499,95.25154377349914,95.2530475180947,95.25457017073778,95.25609211226151,95.25763681455555,95.25915557950233,95.26069692283903,95.26222586623526,95.26377161599302,95.26530670895511,95.26686812641252,95.26842665908757,95.26997610448782,95.27154286528773,95.27310634951891,95.27468949837989,95.27627950705181,95.27785053446019,95.27945568142937,95.28105253840313,95.28263004840223,95.28422604298697,95.28583438882629,95.28745942717424,95.28906181090242,95.29065917208209,95.29229178879845,95.29390960186157,95.29555649016643,95.29719589013942,95.29882572330877,95.30046518892485,95.30211899122244,95.30377971242599,95.30542375089804,95.3070803110583,95.30875031073099,95.31042750707385,95.31211560583886,95.3137735326932,95.31547811267919,95.31713330519537,95.31885293427828,95.32054327111153,95.32224289996817,95.32394074631438,95.32567330629644,95.3273694834503,95.32907579080009,95.33080458015647,95.33253140672477,95.33425389397057,95.33600379736917,95.33774497258716,95.33948557686517,95.34124041496969,95.34300305829314,95.3447465694497,95.3465113875981,95.34826611403265,95.3500498710619,95.35180132165358,95.35359400711846,95.35538577345591,95.35717243639118,95.35895542713143,95.36076621176068,95.36254791429425,95.3643750036337,95.36619074579514,95.36799691628643,95.36979608265614,95.37161869390954,95.37343415262583,95.37528448524267,95.37708861364614,95.37895903358137,95.38079063970285,95.38263823961168,95.38447596333587,95.38634404017454,95.38821849455097,95.39006018381724,95.3919386246101,95.39379567588355,95.39569647333077,95.39756486221809,95.39945568318194,95.40135163699915,95.40322449026613,95.40512472282941,95.40704239784162],[94.9802517603728,94.98185814111903,94.98344317976532,94.98504516618368,94.98663621359728,94.98826451795966,94.98986452471131,94.99148486311863,94.99311129533828,94.9947484572184,94.99637486629133,94.99799473600956,94.99966133259875,95.00128147907185,95.00293072648803,95.00459089334439,95.00624792438853,95.00791885106635,95.00957435263805,95.0112583185004,95.0129135061374,95.01461103202429,95.01629995571291,95.01799023340517,95.0196680776032,95.02135633901584,95.0230651192024,95.02477591644812,95.02649518125452,95.02819865892977,95.02991759461183,95.03162764029737,95.03337229449895,95.03509660391298,95.03682794374713,95.03855355561252,95.0403198849614,95.04205688245807,95.04379830815951,95.04556185806595,95.04733055939806,95.04912234673347,95.05086049634376,95.05264690571951,95.05443843956436,95.05620143474566,95.05797907150821,95.05978796128043,95.0615627573817,95.0633735582162,95.06519109212863,95.06696668898935,95.06879325474775,95.07060699114062,95.07244969801806,95.07424021702127,95.07606452949958,95.07790834628415,95.0797746053683,95.08160713348438,95.08343785527373,95.08528420666296,95.08713345827789,95.08902509791812,95.09088515871989,95.09272141469962,95.09462633681547,95.09647487688117,95.09836694884493,95.10024376988474,95.10212606948117,95.10402570042838,95.10592904206084,95.10783414893076,95.10975167855601,95.11164635258301,95.11355923003515,95.11546013837817,95.11739219918286,95.11930517301366,95.12122122622016,95.12316933529232,95.12510096890082,95.12705143476838,95.12900878648318,95.13097087402446,95.13290406632322,95.13485069478284,95.13683360241431,95.13879334998873,95.14076910091983,95.14274597309948,95.14472227371432,95.1467168624466,95.1487181719965,95.1506849449681,95.15269547884473,95.15468432967704,95.1566892064179,95.15871711068826],[94.85069858210765,94.8523684529734,94.85406333682428,94.85579682804253,94.85747994642435,94.85919071572756,94.86088317762326,94.86261834474362,94.86434184248587,94.86608422427688,94.86781749344507,94.86954488851777,94.87126084678084,94.87301949128957,94.8747721471317,94.87652453587935,94.87826632492711,94.88003097954056,94.88180669802776,94.8835388493803,94.88533680190478,94.88709459093239,94.8888787135097,94.89067151644596,94.89245405548218,94.89425046278376,94.89604602608493,94.89786123243246,94.89966308958958,94.90147767859665,94.90326642132517,94.90510192238922,94.90694028064844,94.90874708388702,94.91058009749251,94.91242661739986,94.91425945315305,94.91611389564389,94.91796296282233,94.91980500668862,94.9216611762481,94.92352869694977,94.92539880098502,94.92726368782421,94.92912518058532,94.9310159677108,94.93289030987037,94.93476442566636,94.93667668536811,94.93854583325103,94.94045755265181,94.9423549831683,94.94427012144723,94.94615387027412,94.94809777517915,94.95000809466993,94.95192207437398,94.95386155930834,94.95578865290592,94.95771212296489,94.95964906653083,94.96160705305127,94.96356594838515,94.9655033451141,94.96746784822321,94.9694229689456,94.97140311975815,94.97336276530532,94.97532457076284,94.97731765147783,94.97928610233812,94.9812905553173,94.98325847451369,94.98525649043783,94.9872645155014,94.9892705232802,94.99126745586192,94.99329304303888,94.99529554502587,94.99730496541079,94.99933319557181,95.0013757678922,95.00337710273678,95.00541560476897,95.007473613467,95.00951069569072,95.01155116492286,95.01360869168907,95.01565964075539,95.01772670058801,95.01977806389615,95.0218581198109,95.02392036213041,95.02600475915163,95.0280782394017,95.03014297669657,95.03225089909975,95.03432043900473,95.03643300563877,95.03854515791198],[94.82335779870405,94.82513983990154,94.82692316014754,94.82870534680349,94.8304714162821,94.83227172457342,94.8340685783723,94.83586043289037,94.8376823203632,94.83949417931827,94.84128945864195,94.84310729204901,94.84493149643828,94.84674716485458,94.84858461371206,94.85040304659557,94.85226569849272,94.85409858426527,94.85594787139067,94.85779428132608,94.85965485543998,94.86153207107819,94.86338669972316,94.86523542988633,94.86712522290807,94.86899021986319,94.87086383349121,94.87274657462302,94.8746458809834,94.87654995691102,94.87843125973794,94.88032238605544,94.88224173933278,94.88416082933138,94.88606586910001,94.88799089252942,94.88990448353127,94.89182758810097,94.89376245772561,94.89567680159203,94.89762390144125,94.899562551971,94.90150861708433,94.90344581157899,94.90540886775341,94.90737486344135,94.90933422264015,94.91132631133979,94.9132796797992,94.9152427044293,94.9172251051344,94.91921381635196,94.92120014501921,94.92319719605388,94.92518803999508,94.92719267232572,94.92918684471388,94.93121412990571,94.93319421963244,94.93523166237128,94.93726192061658,94.93928123695392,94.9413031462097,94.94332880353485,94.94536345945312,94.94739354296512,94.94946338148371,94.95149615061324,94.95354431096247,94.95562217108211,94.95768103938425,94.95972448092637,94.96180169138651,94.96388340854026,94.9659583003432,94.96804566253441,94.97010635219843,94.9722104190946,94.97430628336585,94.9763955190617,94.97846551230359,94.98060386326632,94.98272407957846,94.98483339175543,94.98695452128,94.98906524948629,94.99118471246814,94.99333656932744,94.99547387263189,94.99755953847503,94.99970300128558,95.00187706189483,95.00400396255009,95.00616278024626,95.00834955351039,95.01050700482261,95.01267272912762,95.01481090028001,95.01698781937847,95.01915996697024],[94.87705087010613,94.87890304843071,94.8807476961921,94.88259448014247,94.8844696018323,94.88632631738186,94.88819931102464,94.8900468004045,94.89193931788893,94.893809742969,94.89570866072378,94.89762263190178,94.89949923804022,94.90137985742193,94.90328760480307,94.90520332344529,94.90708798427855,94.90901084215793,94.91095783194984,94.91285718896219,94.91480016850828,94.91671065121467,94.91865298114894,94.92058384387234,94.92252270266103,94.92446918648268,94.92641966012597,94.92835815508208,94.93033474437748,94.93230197761036,94.93425725233384,94.93622814420596,94.93820062428428,94.94017836846402,94.94215657644224,94.94414363987113,94.94612228221871,94.94813209906803,94.95012270904213,94.95212381197373,94.95416191542738,94.95615607206926,94.95817949039184,94.96017446741874,94.96221281687919,94.96423019249718,94.9662689419657,94.9683064766864,94.97034422260516,94.97238929761002,94.97442963084839,94.97649089727079,94.97856207414506,94.98062521190653,94.98267012140235,94.98474152637979,94.98680310958378,94.98889130923946,94.990972497471,94.99304487344119,94.99512931986558,94.9972386706855,94.99932212723566,95.00142277528477,95.00351114435875,95.00563438631012,95.00774491798211,95.00986898991894,95.01198943179614,95.01410902279709,95.01624579304317,95.01836542722769,95.02050503502889,95.02263040487405,95.02478897178045,95.02693216163031,95.0290792924769,95.03126269060765,95.03339201914267,95.03556620552659,95.0377322353431,95.03989470713796,95.04209430600898,95.04425371188358,95.04644601147066,95.04862211488634,95.05083686423136,95.05302079008501,95.05522992818734,95.05741704209045,95.05962902506961,95.0618405008072,95.06404114488808,95.06627962082712,95.06849408543253,95.07071063285021,95.0729604770889,95.07519947169456,95.07742069908548,95.07967986849141],[94.99549510971636,94.99739643763454,94.99930933202977,95.00121196900132,95.00314994198753,95.00505865437125,95.00701720950607,95.00894114791194,95.0108642231352,95.01281655093234,95.0147700684634,95.01673070582888,95.01867209834349,95.02059547700804,95.02258819354917,95.02455192146508,95.02650980235381,95.0284851709287,95.03045297781696,95.0324531294853,95.03443834336353,95.03642946183479,95.03840053383016,95.04041911727771,95.04240970787785,95.04440333567194,95.04644159607693,95.04845378448438,95.05044821779202,95.05248459224353,95.054517466565,95.05654804576757,95.05858884402718,95.06062465012761,95.06263164343682,95.06470328171729,95.06676063326789,95.06881568866869,95.07085788668141,95.07292064806038,95.07499093382364,95.07707029652897,95.07913762073245,95.08122389570421,95.08330220643975,95.08538621200479,95.08747470675641,95.08956667975116,95.0916543868793,95.0937620092217,95.09587756406013,95.09796835044993,95.10008067564695,95.10221226016071,95.10433196575178,95.10642933744013,95.10857011422246,95.11072951725758,95.11286237373024,95.11500418464979,95.11715868940033,95.11929084721227,95.12144209050965,95.12360752736602,95.12577434093711,95.1279088462896,95.13009976192306,95.1322794720144,95.134455973436,95.13662896557479,95.13882399245617,95.1409998527306,95.14321388260045,95.14538360320448,95.14761626099144,95.14977932700545,95.15199936712477,95.15423531339012,95.15643408846456,95.15865467546112,95.16089517170451,95.16309916630438,95.16535392389099,95.16757226386859,95.16980946663004,95.17205075054734,95.17430014041868,95.1765664039498,95.17882161603706,95.18106302186536,95.18335354202026,95.18563605008704,95.18786677067297,95.19015030554998,95.19245504007839,95.19471960961909,95.19702752164658,95.19929785689926,95.20160240697524,95.2039100225688],[95.166108271386,95.16806515932566,95.17002368097218,95.17199867024128,95.17397229580465,95.17596172058259,95.17792261854773,95.17994516575627,95.18190330635137,95.18390165975846,95.18590372815834,95.18787689014724,95.18989725109654,95.19189250489985,95.19392752991175,95.19595177276138,95.19796542939312,95.19997619422332,95.2020011897886,95.20405293131007,95.20608164860738,95.20813053281523,95.21017718883992,95.21221312224367,95.21425813173974,95.21632661927433,95.21836898455754,95.2204428044254,95.22252165340424,95.22457827046242,95.22666321335069,95.22875529882324,95.23083531657741,95.23292172913582,95.23503004985768,95.23709652908477,95.23922142377639,95.24131662945447,95.24342010080224,95.24554681888748,95.24764065457711,95.24977522178287,95.25187295739129,95.25401138489138,95.25613858039698,95.25828218012094,95.26041236284289,95.26255946228551,95.2646894019142,95.26686906949965,95.26901115273918,95.27118899698321,95.27334242947964,95.27550456457286,95.27766912218496,95.27986294712898,95.28202595723374,95.28421112856483,95.28638752185094,95.28860184446367,95.29077910196135,95.29297386789156,95.2951717636713,95.29738819541649,95.29960380379953,95.30180437905958,95.30401068307339,95.3062540758185,95.30847386848468,95.31069841877357,95.31293501550176,95.31515962170388,95.31741751255291,95.31968403255692,95.32191144189618,95.32415684721175,95.32642902290702,95.32867405691482,95.33095884658748,95.33320180426423,95.33548844554126,95.33775515795259,95.3400299055859,95.34232302707707,95.34462549490054,95.34691556806405,95.34920260721624,95.35150814558024,95.35380007486162,95.35611186816291,95.35844351313844,95.36073980147926,95.36307262688406,95.36539038096579,95.36773155202027,95.37004210686754,95.37237653444201,95.37469992344224,95.37706775026741,95.37938163853741],[95.37910737242217,95.38111015666456,95.3831166159625,95.38512850029073,95.38714901600662,95.38917473552922,95.39121352382581,95.3932196477111,95.39525162103203,95.39728917028047,95.39932907316934,95.40136654509965,95.40342661807182,95.405475090935,95.40753502583041,95.40959174881667,95.41166222418846,95.41372375456781,95.41581006924784,95.41787535146055,95.41997217216681,95.4220198516937,95.42411804218037,95.42622355748912,95.42830232594741,95.43039662366097,95.4325162140659,95.43463947723662,95.4367390143991,95.43886877978107,95.44098777493423,95.44309370717079,95.44523473763903,95.44734901489531,95.44947727295879,95.4516020977106,95.45375457988024,95.45590838784095,95.4580656338687,95.46021292615964,95.46237083486189,95.46455342378486,95.46670821217481,95.46888589747792,95.47104516470733,95.47324070510426,95.47540622426192,95.47758730218264,95.4797746140011,95.4819760762077,95.4841572657874,95.48635616035331,95.48858090944059,95.49077507640072,95.49298093339054,95.49519977630001,95.49742664202181,95.49965047721443,95.50188288343793,95.50412480409479,95.5063502417679,95.50859647035044,95.51082394086225,95.51308651151577,95.51531549513538,95.51757542612414,95.51981005625339,95.52209879391617,95.52436984467894,95.52663317413082,95.52891168901688,95.53119692586085,95.53346358314124,95.53575537809758,95.53805292041466,95.54032636539344,95.54263161512193,95.54493223214253,95.54723514800912,95.54954908590105,95.55184863242674,95.55418603768209,95.55651789161203,95.55883784725982,95.5611484897516,95.56346196092244,95.56581419884552,95.56815504720325,95.57048905559819,95.57285496459515,95.57517660261921,95.57754052928742,95.57990502406471,95.58228157896387,95.58464716124199,95.58698690414793,95.58937480788555,95.59176935153201,95.5941335925616,95.5965237694858],[95.6268427732993,95.62890602531701,95.63096247845326,95.632998596066,95.63503227843549,95.63710250690741,95.63915770286309,95.64122183463205,95.6433235008422,95.64538477042277,95.64744714189742,95.64953833707463,95.65162063206682,95.6536928171328,95.65578153500067,95.65790818176393,95.65999738805236,95.66209339967538,95.66420851967042,95.66634047800326,95.66846356497149,95.67056000955392,95.67269536517395,95.67481487587888,95.67695813830741,95.67906767435404,95.6812020682126,95.68337110710806,95.68550565063472,95.68765875702117,95.68982711657127,95.69198042810434,95.69413958978853,95.69629089339422,95.69847253547745,95.70063362454158,95.70281703047439,95.7050063192461,95.70718102865746,95.70937524792645,95.71157712614497,95.71377367342131,95.71597106975841,95.71817153950323,95.72037749722361,95.72260644275698,95.72481910993159,95.7270109424564,95.72924350015823,95.7314649506558,95.73372406705349,95.7359732226985,95.73818815798563,95.74041473604785,95.74267536416315,95.74491305031935,95.74717361548764,95.74944413459443,95.75168632306404,95.75397657782071,95.7562392407134,95.75852498729381,95.76080311842853,95.76306002165221,95.76534291367393,95.76764978915261,95.76995264581554,95.77223712268903,95.77452004391941,95.7768261800032,95.77914731532212,95.78145365710733,95.78378344165336,95.78610440965993,95.7884299450737,95.79076941465173,95.79309399202293,95.79540243383096,95.79774460056075,95.80009282031314,95.80243474737959,95.80477768265311,95.80714075606967,95.80949596007824,95.81184853394365,95.81421524314634,95.81657548370534,95.81895161194788,95.82134226389373,95.82372246693572,95.82607130134173,95.82848206672006,95.83089549862203,95.83328045576869,95.83566307980166,95.83808134394815,95.84047856424493,95.84287980522838,95.84530531432794,95.84770844084542],[95.90334208387851,95.90543974503699,95.9074993762954,95.90958385355786,95.91166742202928,95.91376264380541,95.91586243175827,95.91795359057109,95.92004778775832,95.9221427361719,95.9242537367915,95.92635560125292,95.92848712462734,95.93059067129886,95.93271966935346,95.93485977615862,95.93697757410747,95.93912101704151,95.94124006529316,95.94339296851476,95.94555605173755,95.9477048428518,95.94985146631632,95.95200996615722,95.95416000972533,95.95633507845409,95.95851447542589,95.9606889842524,95.96285563538747,95.96504237386007,95.96724260557056,95.96940178706753,95.97159626372996,95.97378430640829,95.97599219907013,95.97820030164347,95.98039146206222,95.98259015816758,95.98483669647968,95.98703586569457,95.98926891555682,95.99149121644454,95.99370623179173,95.99595769844419,95.99819666304545,96.00046562813637,96.00269399951524,96.00493410664431,96.00718583581727,96.00946627723252,96.01168310461671,96.01397702935392,96.01624668043277,96.01852555325515,96.02079492429561,96.02305562940893,96.02533376532273,96.027657532276,96.02991421951569,96.03221976055264,96.03451841344034,96.03682034891372,96.03912850825587,96.04143914846847,96.04375496929904,96.04605532864946,96.04838973793053,96.05072135996,96.0530381526156,96.05538151476097,96.05769992841708,96.06003505571024,96.06238073842614,96.06473130502168,96.06709763102991,96.06945357875291,96.07177475940534,96.07414132634463,96.07651517952681,96.07889476260506,96.08126625127889,96.0836466071004,96.0860306175643,96.088413316005,96.09078445340886,96.09318205689009,96.09558586817099,96.09797803472387,96.10039774580096,96.10278986866889,96.10519719275898,96.10761403754836,96.11001210859635,96.11244480401817,96.11488317786578,96.11729463588003,96.11972846158962,96.12216504389951,96.12461257609479,96.12705717730158],[96.20382970647677,96.20591252863943,96.20802809773872,96.21012100688702,96.21225929463664,96.2143491023655,96.21647617219796,96.21859076768436,96.22073311221864,96.22283511512308,96.22499100029516,96.22712692453089,96.22926564168864,96.23140762393767,96.2335477093903,96.23570803934561,96.23787325547873,96.24001353904734,96.2421867668247,96.24434442163553,96.24651086404373,96.2487120386055,96.25086438909601,96.25306621637961,96.2552378491146,96.25742706448463,96.25961957776585,96.26183737871565,96.26401812697205,96.26623472711275,96.26845738496453,96.27065285917726,96.2728632751382,96.2750997758782,96.27730403338973,96.27952236868757,96.28175588691184,96.28402429603987,96.28624798083602,96.28848454740094,96.29073835331644,96.29298270292522,96.29523087584124,96.29751894173907,96.29975399172628,96.30202090935276,96.30428936933818,96.30655456045544,96.30884713764561,96.31112231821521,96.31340796950064,96.31569277700905,96.31797121327632,96.32028659410074,96.32257552312174,96.3248578251552,96.32716636343156,96.32949107181595,96.33180797343455,96.33411752688764,96.33645412204953,96.33878076764742,96.34108994184699,96.34342609626574,96.34578016166921,96.34812422111713,96.35045453649705,96.35280781986744,96.3551622442877,96.35749908869875,96.35985646072724,96.3622073358732,96.36457222694955,96.36695994156756,96.3693102224349,96.37170050206144,96.37407929851274,96.3764608494063,96.37885142372416,96.3812239933097,96.38363006920483,96.38602546281045,96.38843304918319,96.39083100937016,96.39323751104435,96.39565763058877,96.39808679898422,96.40050717272626,96.40293076400285,96.40535356696883,96.40778192721622,96.41021572183071,96.41266133773111,96.41509718084824,96.41752318799523,96.4199948306501,96.42244263574047,96.42490648738263,96.42737104067626,96.42982358989855],[96.52441658776294,96.526518290479,96.52864954129281,96.53079004395553,96.5329161821057,96.53503961990181,96.53717866578897,96.53933824987686,96.54150370520443,96.54363491907822,96.54578446743547,96.54793625139737,96.55009050345254,96.55227256256958,96.55442266092389,96.5566125539654,96.55880477111378,96.5609562767369,96.56315248570617,96.56531829736907,96.56753261724802,96.56973912854858,96.5719306332206,96.57410924623126,96.57631454072057,96.57854452173231,96.58076645539322,96.58299601791413,96.5851901826298,96.58741598864361,96.58963024955428,96.59186705639348,96.59412106553808,96.59635245127927,96.59859842882317,96.60085667416675,96.60309095413457,96.60535583896112,96.6076198218274,96.60986538616667,96.61213340761071,96.61439644795003,96.61666466042895,96.6189635147836,96.6212320571615,96.6234950761775,96.62579550038973,96.62808378936376,96.63038789494867,96.6326977073907,96.63498021033703,96.6372918399249,96.63959538402328,96.64192065603376,96.64422550890794,96.64655732999006,96.64885908057066,96.65118936146925,96.65354058511534,96.65586063352083,96.65820886365432,96.66053946637108,96.66290146437329,96.6652303668853,96.66758692575951,96.66994282211841,96.67230208596519,96.67467935479266,96.67702781479946,96.67940580152734,96.68179794768886,96.68417227346802,96.68653634264197,96.6889473330904,96.69134420908314,96.6937379410761,96.69611928400674,96.69851045759536,96.70093154660783,96.70335294945531,96.70574214653898,96.70815908334365,96.71057778723782,96.71297161595326,96.7154462165024,96.71785115578682,96.7202793039082,96.72272009759547,96.72518288066311,96.72758848554847,96.73008689997485,96.73250493180441,96.73496125113913,96.7374290875475,96.73988990783221,96.7423483395348,96.74481760919207,96.747286417639,96.74976801771132,96.75224605708182],[96.86204293888754,96.86418982403163,96.86631002036674,96.8684739266668,96.87061011204477,96.87278157366259,96.87493932336648,96.87709686159353,96.87924993127862,96.88142179097899,96.88357054289214,96.88576942119525,96.88793010520341,96.89013605094564,96.8923186240329,96.89449308364446,96.89668961282226,96.89887975549969,96.90108394174582,96.90328628050926,96.90550282952903,96.90770719634504,96.90993477526021,96.91215709767414,96.91435313976207,96.91660014425116,96.91880651150464,96.92103060155925,96.92328034482345,96.92551426303099,96.92775244162853,96.93001197950056,96.93224341179845,96.934509395363,96.93676536636238,96.93903612713397,96.94130227525164,96.94354795934645,96.9458458647849,96.9481085678855,96.95038143788847,96.95267797126874,96.95496293403683,96.9572493308159,96.95953940480285,96.96185476770843,96.9641655893585,96.96642250432215,96.96875527612173,96.97106212726631,96.97337539560647,96.97570339064166,96.97802055384044,96.98036214847639,96.98268369081988,96.98503167053263,96.98736507440742,96.9896819896858,96.99205344450446,96.99440542129396,96.99675524823064,96.99910618665639,97.00147537247031,97.00380405657421,97.00619858026593,97.00856032665148,97.01091184831834,97.01330480460788,97.01570606571903,97.01807915466598,97.02045273074185,97.02286028810093,97.02524560493808,97.02766075650779,97.03004727308216,97.032438208632,97.0348655814772,97.03727253227513,97.03967665042725,97.04211694276378,97.04454022696953,97.04695322736197,97.04937922527888,97.05182864962458,97.05426688068249,97.05668913518329,97.05916204702274,97.06161025795146,97.06403092822305,97.06648735207264,97.06896137276274,97.07144334782556,97.07387357926127,97.07635341531567,97.0788381388836,97.08130798599628,97.08378759136363,97.08626483886995,97.0887297219185,97.09126890859028],[97.21417299549874,97.21631915839338,97.21846584292665,97.22063170333189,97.22277420465176,97.22494389772652,97.22711956595235,97.22929252734919,97.23145230988226,97.23364603699747,97.23580660532232,97.23799823734429,97.24021788135539,97.24237488642387,97.24458103931005,97.24676975804356,97.24896638872069,97.25119509275376,97.25339736168932,97.25561230141311,97.25784696855328,97.26006999863233,97.26228850522492,97.26452346136331,97.26675689522361,97.26898478452657,97.27122453480304,97.2734670610547,97.27573256550602,97.2779686990142,97.28021961868082,97.28248912789633,97.28473800606137,97.28701254958594,97.28928133728682,97.29154938059877,97.29383278396446,97.2960955869593,97.2983729739378,97.30066332365617,97.30295926287036,97.30528036847895,97.30754929695595,97.30984648450847,97.31215990687129,97.31447087859289,97.31677822493887,97.31909908952957,97.32140460614796,97.32371844960444,97.32606036033208,97.32839976455908,97.33072152433422,97.33305506903349,97.33541256733415,97.33772172152436,97.34007988783928,97.3424412223485,97.34478735576398,97.34714446209253,97.3495057954842,97.35186324688269,97.3542390250013,97.35661016783868,97.35899586250784,97.36137878253227,97.36375629781779,97.36612742559677,97.36855088057627,97.37091290106655,97.37330786910357,97.37571718566757,97.3781202486471,97.38052252963658,97.38293046293563,97.38532587033869,97.38776112984681,97.39016898564373,97.39262909713268,97.39502226773178,97.39746925057386,97.39989019031245,97.40232456759786,97.40477092768859,97.4072291369933,97.40969486360379,97.41210312256275,97.41458181602135,97.41702777580043,97.4194970221203,97.42197867178179,97.42441730282788,97.42690342081762,97.42938109292979,97.43188138151498,97.43435190555135,97.43681299542686,97.43932814480965,97.44181932793313,97.44431424832605],[97.57861729723618,97.58078531096459,97.58292059847733,97.58510960475913,97.5872822389046,97.58945318614035,97.59163371051173,97.59380702457666,97.59598958421236,97.59818521761744,97.60035040423838,97.60256206903526,97.60474082326927,97.60695708371638,97.60913802835965,97.61135028787238,97.61359347554972,97.61579297159682,97.61802237571041,97.62024457096973,97.62245081449035,97.62469162522964,97.62691751176519,97.62914563116593,97.63138609233063,97.63363283607957,97.63590897630266,97.63816587794618,97.64041173428699,97.64264728967419,97.64491921060836,97.64718762418045,97.64944308382687,97.65171771760504,97.65400590918854,97.65629464369933,97.65855466121559,97.6608574293117,97.66311579057788,97.66544336429665,97.66771941783131,97.67002460704974,97.67233331064838,97.67465669203315,97.67693716122298,97.67926872422163,97.68158557956598,97.68390462680522,97.68619858010675,97.68853827685929,97.6909011200914,97.69321303896123,97.69552550246388,97.69790229806229,97.70023109419647,97.70258377157235,97.70495857456953,97.70729788668277,97.70966577806314,97.7120288016748,97.7143649217574,97.71675458482243,97.71914905592972,97.72150437871846,97.72389080868018,97.72626134805718,97.72864355754092,97.73103543235183,97.7334600561957,97.73584202416528,97.73821994451507,97.74063208405367,97.74305123180636,97.74545491226169,97.74788180423764,97.75031252537642,97.75273570319436,97.7551411575989,97.75755035014762,97.76001240561371,97.76245308661184,97.76487478398035,97.7673200913262,97.76976900934547,97.77222833804292,97.7746600486657,97.77710346453998,97.7795598929913,97.78203066239186,97.78450226916776,97.78698784791825,97.78945516282104,97.79193278156409,97.7944275274952,97.79689052226408,97.79937265202732,97.80183885786154,97.80434461513302,97.80685020788593,97.8093406700829],[97.95361942761518,97.9557976331287,97.95795277615795,97.96012117668297,97.96228849004058,97.96447366584457,97.96664556645811,97.96885037271805,97.97104355036889,97.97322892651148,97.97542840274278,97.97761686334619,97.97981400676369,97.98203075748081,97.98424034750909,97.98644166900341,97.98867653896725,97.99088698562551,97.99310939233746,97.9953424076546,97.99757056585884,97.99981061862123,98.0020465999016,98.00431331041526,98.00651993034163,98.00878444850395,98.01103050813833,98.0132764850554,98.01552971899889,98.01779698554648,98.0200552408621,98.02232386572716,98.02459700633563,98.0268914672222,98.02917128911064,98.03143498822801,98.03374436306996,98.03600898995852,98.03830815015831,98.04059455739377,98.0428720955093,98.0451859793416,98.04750588105401,98.04981291643013,98.0521184657296,98.05445795350678,98.05677641579567,98.05910488763456,98.06142351595453,98.0637411782466,98.06608159023253,98.0684352354157,98.07076102643194,98.07310699185709,98.07544260962813,98.0778086128717,98.08014530049988,98.08250293485027,98.08488990283993,98.08722017888286,98.08959820596347,98.09199358136463,98.09435107646964,98.09674957980198,98.0991075524056,98.10148749180033,98.1038910814942,98.10626690587011,98.10865880779275,98.1110754439134,98.11346143892449,98.11589156726635,98.11829090629747,98.12071210556444,98.1231231134988,98.12553860443016,98.12793358666093,98.13038755231568,98.13282050182048,98.13524507001095,98.13767930725062,98.14013018014901,98.1425505412391,98.14501785447102,98.1474488586509,98.14991547447849,98.15236262015868,98.15481198021828,98.15729823298558,98.15975413190309,98.16223025233646,98.16468865465016,98.16716697675176,98.16966645934741,98.17212068367526,98.17460520561828,98.17710481663998,98.17958605116003,98.1820874776002,98.18459087313502],[98.33760374036815,98.3397741016255,98.34195868135353,98.3441262327228,98.34631107124375,98.34848517736776,98.35070174599029,98.35286539220182,98.35504952826555,98.35726821172521,98.35944570936664,98.36165981611751,98.36385729245222,98.36607326518343,98.36830626186507,98.37048560043851,98.3727059789849,98.37493912982086,98.37714625918666,98.37938127931024,98.38159836154131,98.38383659285536,98.38608249541167,98.38833195339701,98.39057616979571,98.3928161591585,98.3950836923751,98.39734064015067,98.39958123641696,98.4018461077903,98.40413066687567,98.40639111920432,98.40866010004045,98.41094962708773,98.41322545251589,98.41547711633015,98.41779070694756,98.4200576425283,98.42236552720856,98.42467331394376,98.42696734506403,98.42926191669139,98.43154760350214,98.4338516361106,98.43619082446841,98.43850790808187,98.44082041023478,98.443140498941,98.44547418203683,98.44779856776336,98.4501242960413,98.45246236470726,98.45481293415588,98.45715066391763,98.4594766798237,98.46185167555032,98.4642145401173,98.46656219129073,98.46892388749441,98.47127197118323,98.47363759774616,98.47601838116569,98.47837414270221,98.48075945832815,98.48316109649411,98.48552959709313,98.48791052923116,98.49030427157422,98.49269851768955,98.49509650725177,98.49748061267775,98.49989400297952,98.5022961174771,98.5047209497811,98.50714304593693,98.50952235624092,98.51192926808741,98.51437467001179,98.51682185771226,98.51924079735042,98.52164442074482,98.52408911225251,98.52652890296996,98.52895944949464,98.53141329279471,98.53388211591712,98.53633365817946,98.53878922057956,98.54125708530603,98.54370843424331,98.546175796303,98.54864144162458,98.55110986392532,98.55358170820689,98.55607783613263,98.5585175403846,98.56103207448896,98.56351754877367,98.56601122122129,98.5684899484232],[98.72932244680283,98.73149534792728,98.73366835972915,98.73583293420157,98.73800711086257,98.74020987922708,98.74238797659048,98.74456448037618,98.74674060703549,98.74894877450942,98.75114884488924,98.75333136555953,98.75555112167004,98.75773935666714,98.75996012908436,98.76217565293628,98.76439884101983,98.76659457104797,98.76882073153607,98.77105336896336,98.77326122629879,98.77550481164465,98.7777558076045,98.77999742536441,98.78224725439198,98.78449685019515,98.78673959129046,98.789000128934,98.79124346765052,98.79348623487081,98.7957620526269,98.79801995823239,98.80029887341509,98.80258373721925,98.80485397266916,98.8071400457933,98.80943677639928,98.81169545549001,98.81399556870983,98.81627642011627,98.8185674748958,98.8208828364096,98.82320389265789,98.82547113677774,98.82778678966194,98.8300872942028,98.83242755773168,98.83472701647445,98.83705454152805,98.83940490499347,98.84171590697545,98.84405209050668,98.84638359028737,98.84872004253296,98.85105155099934,98.85339863345455,98.8557812931854,98.8581131227132,98.86045594167894,98.86280514964915,98.86518033985935,98.86754116149726,98.86989566544159,98.87228438469592,98.87465879519684,98.87703817181016,98.87942319003669,98.88180749834268,98.88420224534403,98.8865865558754,98.8889666128392,98.89137978369601,98.89376479217938,98.89619214166339,98.89857436493843,98.90100143990868,98.90343247748845,98.90583634746292,98.9082686192212,98.91068376923414,98.91309449790266,98.91553138425225,98.91796082652861,98.92040625232902,98.92284092514177,98.92529341749737,98.9277300288817,98.93017794858245,98.93262436477103,98.93508201633657,98.93753117909753,98.93999802571699,98.94244605039644,98.94492093210485,98.94738729323424,98.94987863054844,98.95234581509068,98.95481765985002,98.95730269236596,98.95981157655993],[99.12754157923975,99.12971079406684,99.13187824935954,99.13402725458275,99.13622018392518,99.13839441914908,99.14056407703897,99.14275611675947,99.14493962779126,99.14712831689464,99.1493197077871,99.15152458111501,99.15371867325949,99.1559146736332,99.15810758215531,99.16032278526117,99.16253553975895,99.16475278975089,99.16698857112885,99.16918261873472,99.1714064936273,99.1736355293394,99.17586819925876,99.17811951733535,99.18035354593984,99.1825991016757,99.18484605406141,99.1870808073827,99.18934635252904,99.19159072554108,99.19384872214547,99.19610824278165,99.19837451811517,99.20065518823316,99.20290750637375,99.20517935046553,99.2074497087042,99.20971935338386,99.2120251532866,99.2143081804471,99.21659839940811,99.2188819802275,99.22119642923754,99.22347778468614,99.22577740554487,99.22808730363975,99.23038722758665,99.23270882973375,99.23503006833305,99.2373521400036,99.23968323553059,99.24199551182893,99.24431915065625,99.24663508853288,99.24898095109643,99.2513338146747,99.25365923184998,99.25600745063899,99.25836232497016,99.26070588450231,99.26305342017918,99.26541192982876,99.2677730609262,99.27014506631441,99.27249572042656,99.27488275345841,99.27725697432074,99.27961882090217,99.28199841069048,99.28438739171432,99.28675291506909,99.28916411475434,99.29157271589705,99.29396607350974,99.2963367699459,99.29875598714611,99.3011465852284,99.30356255741832,99.30595962798476,99.30838205399151,99.31081386468553,99.31323368754431,99.31564534891459,99.31807237201426,99.32051688609417,99.32294703641787,99.32537234962084,99.32781618530362,99.33026384753259,99.33271524974197,99.33514878571317,99.33759846629033,99.34007043878147,99.34251407307435,99.34498231814788,99.34744423889074,99.34992259579171,99.35237436578532,99.35486513920883,99.35733746429601],[99.5312276458722,99.53337969343505,99.53555725662765,99.5377074262717,99.5398769706374,99.54204282748994,99.54421836260323,99.54641117791508,99.54858512860794,99.55078078952863,99.55293386621788,99.55512324703349,99.55733597208538,99.55953418978409,99.56173373640975,99.56393079093736,99.56611823393163,99.5683487393407,99.57054502697272,99.57276915237179,99.57498702455487,99.5771860862338,99.57943065689204,99.58166410966878,99.58388797303556,99.58611822930523,99.5883404514488,99.59059737089449,99.59285484993227,99.59508171490565,99.59734578182184,99.59958016979017,99.60183802706244,99.60410111243652,99.60636122544157,99.60862748998898,99.61088661783012,99.61317600929834,99.61542438097362,99.6177148740454,99.61999327065517,99.62228148139943,99.62457500739798,99.62684632717601,99.62916629921786,99.63144658438304,99.63376284777044,99.63605403729446,99.63838541814208,99.64067867359523,99.6429627322959,99.64530596607239,99.64760492596939,99.64993997909619,99.65227941077967,99.65459901649868,99.65691796295778,99.65926556062448,99.6615966854694,99.66395093228954,99.66628970873181,99.6686422192214,99.67098474479177,99.67334119080229,99.67568243166842,99.6780456081183,99.6804171595671,99.68277720687459,99.6851323651106,99.68751778425228,99.68988346839325,99.69225897058861,99.6946576234649,99.69701062922204,99.69942475440614,99.70182777934187,99.70421882940862,99.70658141492845,99.70900070561143,99.71140835197659,99.71379372260168,99.71623518213275,99.71862098393527,99.72104080146175,99.72345644591674,99.72589326266589,99.72830411431428,99.73073348365361,99.73318348692487,99.73558762648841,99.73802489590959,99.74047630191619,99.74293832789394,99.7453766297151,99.74780023044146,99.75026180458882,99.75270974405977,99.75519244586704,99.7576428846901,99.76010751811307],[99.93950359582112,99.94163833933872,99.94381583982401,99.9459678638635,99.94812658577302,99.95027876510468,99.95242458712966,99.95461062562815,99.95677963823523,99.95896157690235,99.96113309510594,99.96330268144122,99.96547644230233,99.96768432986948,99.96986452609184,99.97207233137107,99.97423888636153,99.97645547439029,99.97865354583021,99.98085925079963,99.98307147828464,99.98527871543888,99.98748353016025,99.98971005611006,99.99193525831551,99.99415671067202,99.99638266278133,99.99860377390145,100.00087501346358,100.00305876584315,100.00529834042727,100.00755859076233,100.00979513492794,100.0120521565726,100.01430151001196,100.01653954954881,100.0188150979908,100.02108203903518,100.02333399608929,100.0256022233481,100.02786999906458,100.03015010413836,100.03240732540118,100.0346942036737,100.0369798930905,100.03926752028632,100.04156980963681,100.04384729395609,100.04614693427294,100.04844743294564,100.0507302693566,100.0530233212479,100.05534729876274,100.05765281461869,100.05997922536359,100.06228279267748,100.06460078912805,100.06692645640173,100.06925283667529,100.07158411034753,100.07391794090177,100.0762443056407,100.07858810113734,100.08092142606444,100.08327048882798,100.08562005325332,100.08797337738494,100.09031188993814,100.09267600943302,100.09501809286134,100.09739711293025,100.0997622912219,100.10213066655938,100.10449400221871,100.10687509643962,100.10924951463016,100.11162346415668,100.11399633181804,100.11637058931221,100.11878979575201,100.12116478461972,100.12358031752167,100.12596380449551,100.12837300716366,100.13078097692156,100.13317672729761,100.13558505632348,100.13798866467178,100.1404172221497,100.14284234571488,100.14525151666037,100.14766997656486,100.15010056767443,100.15255421387448,100.15497385192671,100.15741039381325,100.15985485468835,100.16228628296653,100.16473846957737,100.16719079723109],[100.3515151435759,100.35367056873352,100.35580461838371,100.35793021270092,100.36007981157425,100.36224538584246,100.36437627431798,100.36653588719298,100.36869867204769,100.37085546546805,100.37302777390978,100.3752187437589,100.37735930197803,100.3795507154551,100.38173479939482,100.38390790193128,100.38608916922946,100.3882747188655,100.39044574368612,100.39264898697013,100.39485586029778,100.39702618357607,100.39923915904595,100.40144476822363,100.403661794575,100.40587827458393,100.40808920620128,100.41028961927664,100.41250909208536,100.41475274785901,100.4169853427239,100.41920371841987,100.42142472994387,100.42366432353158,100.42590501182748,100.42816571212502,100.43039660019159,100.43264865816629,100.43491129245577,100.43714646450428,100.43940404548682,100.4416637264817,100.4439447753149,100.44617765265485,100.44844539142612,100.45073098604364,100.45298558206592,100.4552798139089,100.45757225232236,100.4598368348817,100.46211066211507,100.46442181777289,100.46672361561522,100.46899584879768,100.471321163331,100.47362235922617,100.47590055071274,100.47821593624407,100.48052463055939,100.48284827738878,100.48515785568557,100.48746617893651,100.48980026641375,100.49211668868683,100.49446814715014,100.49680148508843,100.49912755788553,100.50146396889185,100.50379888098425,100.50613907775124,100.50849113683546,100.51082798229412,100.51317167629409,100.51553360176972,100.51790807506048,100.52024598330175,100.52261271148843,100.52499436994262,100.52736096043714,100.52972305737973,100.53210171977277,100.53446636521514,100.5368476974133,100.53925623063442,100.5416400602577,100.54401727473946,100.54641544589695,100.54882394427958,100.55118899548006,100.55361843291897,100.55602123374987,100.55841366065752,100.5608410928277,100.56326208684888,100.5656703509006,100.56808414964064,100.57048663046838,100.5729337138616,100.5753550261366,100.57778589951337],[100.7665220943457,100.76864695609723,100.77077257092643,100.77290463963921,100.77502759451241,100.7771790740218,100.77931639198066,100.7814406951431,100.783615389756,100.78575993855718,100.78788147058546,100.79005341678166,100.79222708758648,100.79436177679959,100.79653660704705,100.79872568251088,100.80088535539434,100.80306170730591,100.80522947128456,100.80740806758749,100.80960700711746,100.81179229067291,100.81395384523395,100.81615946105968,100.81835639797285,100.82055229423702,100.8227429749409,100.82495441245106,100.82713927033362,100.8293627055065,100.83156429109957,100.83378387717042,100.836015844867,100.83822955255228,100.84043247463804,100.84267909077673,100.84489878631645,100.84712054422548,100.84938689382727,100.85160724059826,100.85383199757614,100.8561133804982,100.85834537156593,100.86060979330303,100.86286665189935,100.86511052953139,100.86735432647863,100.86961109143107,100.87189291878563,100.87414622553932,100.87641680331257,100.87869724999135,100.88095982220153,100.88325337492321,100.88554765162418,100.88781140949402,100.89010946921142,100.89240831727332,100.89469362065111,100.8969689882267,100.89928629528922,100.90158641022782,100.90390072018644,100.90623133584977,100.90849594805728,100.91081822566794,100.9131397586256,100.9154552677481,100.91778884772177,100.92012180346755,100.92242920933899,100.924758379932,100.9271201774864,100.9294541938722,100.93179056259471,100.93411994948096,100.93645476743438,100.93880617244244,100.94116016640977,100.94351731521354,100.94588195662115,100.948234209258,100.95058608227654,100.95298338194331,100.95533393438693,100.95770281003666,100.96009042389403,100.9624515735061,100.96482965351285,100.96722217660312,100.96960405895183,100.97198701618251,100.97437344722658,100.97677116283486,100.97918271375397,100.98155185523567,100.98396375111459,100.98638347081334,100.98878764834487,100.99118359049922],[101.18386920928297,101.18599019192685,101.18811655603756,101.19021305865843,101.19233640786933,101.19444677385295,101.19659171672086,101.19870446009075,101.20085570395338,101.20296802720495,101.20509585527594,101.20726236976537,101.20938213985497,101.21155771061319,101.21367253828795,101.21583033945112,101.21798065731718,101.22015225291433,101.22231978341448,101.22446982422285,101.22663348296092,101.22880916845293,101.23096133518825,101.23315389135482,101.23533185725326,101.23752097420926,101.23969056631694,101.24189322213371,101.24406535495619,101.2462702794886,101.24845131084514,101.25063593291345,101.25283427657686,101.25506262782923,101.25726879386846,101.25949052377688,101.26169770093142,101.26389331323456,101.26612162464825,101.2683443122846,101.27056397589516,101.27278091259225,101.27500167022512,101.2772271352994,101.27948481343613,101.28171095684641,101.28395457189373,101.28620672861192,101.2884603970162,101.29069135546193,101.29294848144045,101.29519912989149,101.29746585697191,101.29973071592154,101.30198351213521,101.3042322077751,101.30651533838632,101.30878282001086,101.31106047079243,101.31337042245123,101.31561093589406,101.3178993402993,101.32019613252311,101.32248448811417,101.32478993545735,101.32707738105958,101.32935292600413,101.3316629844522,101.33395734016099,101.336270410966,101.33859992867951,101.34091223649918,101.34319935575216,101.34550208349646,101.34782388863654,101.35016018509496,101.35249215709293,101.35482550998857,101.35713989054511,101.35947520051259,101.36181220306626,101.36417073173416,101.36651109336533,101.3688568034913,101.37118272529162,101.37351615175913,101.37589855453442,101.37823246104549,101.38062528468349,101.38297601334435,101.38533606474208,101.38770660724632,101.39006843166061,101.39243570287795,101.3948207823872,101.39720198347052,101.39956394756177,101.401958640489,101.40435089561689,101.40673708303697],[101.60293383063716,101.60503335825578,101.60712470796554,101.60922656645404,101.61132074138575,101.61343921554847,101.6155571951895,101.61767569229885,101.61978996378788,101.62187801661847,101.62402990217115,101.6261377051548,101.62826458614502,101.63040420539184,101.63250583033035,101.6346526751134,101.63679305362425,101.63894564061326,101.6410925043609,101.64321047757474,101.64537265869322,101.64750467578294,101.6496870470957,101.65184024193412,101.65399561234581,101.65614704190082,101.65830951491662,101.66050449408965,101.66265080711946,101.66484111790525,101.66701292132447,101.66918527243809,101.67135638022347,101.67354268931383,101.67573911219331,101.67793092587038,101.68013513234584,101.68231437078948,101.68452462734345,101.68673701969183,101.6889232248836,101.6911423752211,101.69333903272633,101.69555074700148,101.69778532383194,101.70000016275053,101.70219906414812,101.70443215964892,101.70665043038274,101.70887635183279,101.7111214254704,101.71335818349051,101.71557527734004,101.71780511834024,101.72007609472305,101.72232995519829,101.72456073499579,101.72682454194276,101.72906638937556,101.73134097349481,101.73359540410411,101.73585943591691,101.73812061937971,101.74038320282287,101.74263764818224,101.74494146857249,101.74720326780982,101.74947763497642,101.75177537122744,101.7540197710535,101.75632426046315,101.75862095164987,101.76093028479494,101.763216979592,101.76548813453779,101.76781909661628,101.77011290363875,101.77242048332423,101.77473644676142,101.77705568875287,101.7793551340888,101.7816650126281,101.78400330635168,101.7863264006265,101.78862835078473,101.79098880536864,101.79328971295745,101.79564199844421,101.797966319597,101.80032211156824,101.80267288033298,101.80501966369906,101.80734154386326,101.80969219106791,101.81205207249691,101.81439514347551,101.81678099107789,101.81913381830603,101.8214945585125,101.82385218911449],[102.02320015567412,102.02527332090364,102.02734429947124,102.0294303175417,102.03152784547315,102.03362513038077,102.03569123491467,102.0378044520689,102.03987266090992,102.04196354509267,102.04408700838862,102.04618279479008,102.04828657585269,102.05039699076355,102.05250734261112,102.05464939068133,102.05676506396937,102.05887004006146,102.06096568756521,102.06310115669518,102.0652499951328,102.06736041780178,102.06951315572712,102.07164897953228,102.07379196342484,102.07593016701775,102.07808723986338,102.08022909744776,102.08236833096237,102.08452187415872,102.08666490510205,102.08883576323115,102.09099934957203,102.09314970077992,102.0953278186088,102.09750732971665,102.09967712492963,102.1018535868349,102.10404736954285,102.1062181411193,102.10840546161833,102.11057911639983,102.112761496374,102.1149466993636,102.11715909556072,102.11934307276047,102.121561679921,102.1237531283722,102.12595081096761,102.12816887575894,102.13037855923679,102.13260673192407,102.13479589928218,102.13702596530355,102.13924168404188,102.14149092537886,102.14369960149712,102.14592790548706,102.14813423120845,102.15037954544702,102.15262710344913,102.15485935153826,102.15710837643921,102.15933704534604,102.16160677264395,102.16384974492956,102.16612453952949,102.16836256497575,102.17059843371074,102.17288666898267,102.1751504462626,102.17740594461004,102.17968651792009,102.18195029987979,102.184222382692,102.18650363505321,102.18880196253753,102.19107648417992,102.19336742859737,102.19563820681817,102.19793169612628,102.20023181428738,102.20252193416853,102.20482568532971,102.20711464504856,102.20943898367557,102.21174669076609,102.21404903953945,102.21636904363035,102.2186910580822,102.2210028088,102.22330148753751,102.22563289382,102.22797000903392,102.23030096342409,102.23262202769618,102.23496286504059,102.23730728931444,102.23963585047815,102.2419776002069],[102.4441062207923,102.44617793289963,102.44822157688914,102.4502816016198,102.45235983227909,102.45443312008251,102.45650661140128,102.45855795832453,102.46064115503115,102.46271192840281,102.46479371985114,102.46689461965305,102.46896310110631,102.47106224517093,102.47315859034495,102.47525057819253,102.47733228884309,102.47943249740209,102.48155243824765,102.48365858296611,102.48576222829891,102.48786420935718,102.48999853677044,102.49209649867005,102.49423715829539,102.4963491714401,102.49844352412427,102.50057978045325,102.50270220563183,102.50483254832557,102.50698881405216,102.50911435260377,102.51125625462555,102.51341755743867,102.51557259339116,102.5176988126947,102.51984433604943,102.52200003243199,102.52416418832624,102.52630720870575,102.52848862198073,102.53063569256456,102.53282119351427,102.53497768351262,102.53713396649876,102.53932118046059,102.54148634392018,102.54365006783387,102.5458607669751,102.54804926152956,102.55022540043288,102.5524109067298,102.5546196006615,102.55680546989927,102.55900812447346,102.5612299255874,102.56339856966115,102.56559638535387,102.56782469603561,102.57001076408935,102.57223989651075,102.57445624510073,102.57668427742051,102.57890824342272,102.58111491718164,102.58337724688253,102.58559984328636,102.58780607452715,102.59005012893067,102.59228506110055,102.59452259079622,102.59677828880857,102.59900319319772,102.60127909622437,102.60349963520571,102.6057864396139,102.6080314629705,102.61028735362615,102.61254035326365,102.61479054785369,102.617074878667,102.6193208300903,102.62160612524704,102.62387705025932,102.62617430141226,102.62845190380047,102.63074556668157,102.63299484942104,102.63529127727551,102.63759903812918,102.63986069576272,102.64216638621322,102.64444604651901,102.64676884658243,102.64906529257243,102.6513775221343,102.6536756811496,102.65600914660203,102.65830767746345,102.66062529261895],[102.86523997090748,102.86729281984003,102.86932975673457,102.87136314053991,102.87341449544208,102.87548131212816,102.87752084136218,102.87955897395457,102.88162119452059,102.88367910147126,102.88574874098808,102.8877972135361,102.88986323278289,102.89193337873826,102.89398984173836,102.89608383795485,102.8981508521077,102.90020244721336,102.90229084528002,102.90438665646727,102.90646600610657,102.90854118529015,102.91065507309267,102.91273096414739,102.91482053352782,102.91693734174662,102.91901056897635,102.92112443377418,102.92323243604861,102.92534347288472,102.92746371450967,102.92956303206776,102.93170078895862,102.93380476925995,102.93592996178344,102.93808188565818,102.9401990519186,102.94232005906285,102.9444577196065,102.94658679580657,102.94872357002298,102.95086149633144,102.95299400492968,102.95514920442729,102.95729615620114,102.95944139125811,102.96159185870276,102.96374534072588,102.96591663373108,102.96806504732982,102.97021720904908,102.97241277551805,102.97456575285246,102.97673291559666,102.9789076190962,102.98108029655309,102.98325451153065,102.9854421005083,102.98765058895887,102.9898159964209,102.99200123780012,102.99420721217218,102.99639461358507,102.998601740873,103.00079511462016,103.00298872033655,103.00518633304414,103.0074065849949,103.00961409712868,103.01183436681507,103.01402620093513,103.01625123252475,103.01846766523822,103.02068258050569,103.02292977261546,103.02514114934391,103.0273833863645,103.02960760999474,103.03183672058609,103.0340840619244,103.03631310875747,103.03856716294449,103.04082170308523,103.0430530608088,103.04532241846236,103.0475655379591,103.0498091228421,103.05205904193289,103.05435223497355,103.05659269770528,103.05884087534221,103.06112168523501,103.06339998648403,103.06567669245476,103.06796896485307,103.07020154669688,103.07249363253511,103.07479043084126,103.07704524667818,103.07934899962618],[103.28618606823663,103.28823024293203,103.29022039641147,103.29224340611017,103.29424955414117,103.29628878803214,103.29830601845194,103.30033888957391,103.30236336272658,103.30439253088616,103.3064261810345,103.30849273196559,103.31049008829225,103.31256132904973,103.31461227108619,103.3166758789115,103.31870750010937,103.32075472121619,103.32282807204474,103.32489941737053,103.32694591779526,103.32902152054331,103.33108705075549,103.33316846837504,103.33522012620654,103.33728632028449,103.33936399691702,103.34144800162089,103.34353028645697,103.3456029963346,103.34769996837272,103.34979387107123,103.35190150364869,103.35399201336686,103.35611201999828,103.35818982619874,103.36029745672195,103.3624083935268,103.36451389999328,103.36663860419044,103.36873385874682,103.37084601013999,103.37295621276269,103.375063743939,103.37720020546817,103.37932218390112,103.38145008652778,103.38357926741858,103.38573276101799,103.38785157335255,103.38997962200435,103.39215381940596,103.39427157111591,103.39640832384138,103.39857665924278,103.40072681720471,103.40288369685815,103.4050349453549,103.40718852989099,103.40935714169238,103.41150688765072,103.41364789771987,103.41583679828777,103.41800867450686,103.42016710898307,103.42235714777325,103.42451520567536,103.4267046341627,103.42890001434792,103.43107706756832,103.43325698251985,103.43545239465371,103.43766248932563,103.43983869949963,103.44204734223665,103.44423099296068,103.4464536789275,103.44863586667677,103.45087924783843,103.4530899078197,103.4552683087438,103.45747199804718,103.45970415526179,103.4619387169437,103.46416190409514,103.46637778089166,103.46858591557225,103.47085122788569,103.473064162501,103.47530690517158,103.47755446970719,103.47979411630634,103.48201664675044,103.48426960729816,103.48653131001818,103.4887587371283,103.49103466155381,103.49328884406529,103.49554074235436,103.4977746985522],[103.70654750402903,103.70854427505114,103.71052106749494,103.71251297709493,103.71451126924435,103.71652545591265,103.7185404511664,103.7205383095433,103.72253643405273,103.72455895143268,103.72656472331694,103.72857101708082,103.73059067231529,103.73263698240439,103.73466147028417,103.73665655304697,103.73870541925885,103.74073877850708,103.74275623648786,103.74478646365726,103.74683533571317,103.74888159159698,103.75091105520144,103.7529563034421,103.75500749607436,103.75704979646032,103.75911296005052,103.76116460529872,103.76322245317513,103.76527898672275,103.76735133215291,103.76940755697697,103.77149413969148,103.7735552053626,103.77563194822991,103.77770733252108,103.77978264729362,103.78186465395979,103.78393966828828,103.78602002945472,103.78811451535549,103.79020983632105,103.79230010061488,103.79437240930528,103.79648817554876,103.79857637703745,103.80067519752615,103.80279540936131,103.80489360612782,103.80702214138398,103.80911684105327,103.81123023775665,103.81333843710013,103.81547024113715,103.81760079733708,103.81967595810265,103.8218283501765,103.82395570602549,103.82610026769278,103.82823891451798,103.83036788310092,103.8325088505236,103.83463787166279,103.83678360304025,103.83892567617445,103.84109191608202,103.84323798211372,103.84538577920993,103.84753752313381,103.8497008399537,103.85186569770926,103.85402311426344,103.85618869156633,103.85834429347206,103.86051198002284,103.8626857865067,103.86486907009069,103.86703606055092,103.86923226654343,103.87141156356401,103.87357495299523,103.87576517550924,103.87796346319922,103.8801645161628,103.88237629958405,103.88454159560021,103.88676401197475,103.88894967040558,103.8911540096343,103.89337133980175,103.89558015543246,103.89776463504832,103.89998673893474,103.90218408307666,103.90441628663766,103.90664385296618,103.90885842794417,103.91108938920327,103.9133162371218,103.91554312518],[104.12600033137119,104.127957181473,104.12994582489996,104.13190597980892,104.13386948996114,104.13587412929328,104.137833113232,104.13982041934742,104.14181231580199,104.14381064103296,104.14575564403071,104.14775967636504,104.14978286789024,104.15175040960905,104.15375369344115,104.15574718491946,104.15775676911369,104.15976503352826,104.16177150877368,104.16378267637022,104.16577619779252,104.16781381362505,104.16983900948352,104.17185424970651,104.17385542663037,104.17590314174922,104.17793261813154,104.17995279181812,104.18199597086439,104.18400089659501,104.18607075683215,104.18809127664053,104.19014835228977,104.19215962681297,104.19423812354553,104.19628469115506,104.1983115774669,104.20038646543597,104.20244379436546,104.20448708135163,104.20656866291748,104.20862765372085,104.21068740279149,104.21275205604827,104.21480780460449,104.21689500502384,104.21896501693239,104.22103763813195,104.22311331302788,104.22519956249641,104.22727975134985,104.22936096660972,104.23146097405208,104.23356079801496,104.23565265566367,104.23774947143602,104.23983850033827,104.241948317945,104.24406016841965,104.24615509493383,104.24824238671047,104.25038197037631,104.25249523235667,104.25460791817648,104.25670602221749,104.25885445540118,104.26093918210017,104.26309005064516,104.26522917708375,104.26734395987498,104.2694719033636,104.2716033333489,104.27375118440668,104.27587782059754,104.27802671027602,104.28019672189609,104.28231627953706,104.28443788090597,104.28659492189058,104.28875193152757,104.29093323088935,104.2930675776316,104.29523378446011,104.2973750241867,104.2995448506902,104.30170455320535,104.30387440638853,104.30605724292153,104.30823403280597,104.31041233115506,104.31259546521832,104.31476082464246,104.31695412363447,104.31914062408846,104.32130825111999,104.32351287935792,104.32570682540651,104.32791128475921,104.3301172668826,104.33230144066219],[104.54422636756517,104.54615127678228,104.54813248071063,104.55006264608373,104.55201066818634,104.55396810277118,104.55592585438967,104.55786795848546,104.55981743775885,104.56179605364457,104.56376695188487,104.5657182010838,104.56767816196998,104.5696527028515,104.57162923752772,104.57361338998825,104.57559107997047,104.57757087575756,104.57955037009489,104.58151581354298,104.58351163277582,104.58549605805679,104.5875137918523,104.58948069147523,104.59150068982137,104.59349034401184,104.59548645506013,104.5974838786232,104.59947182064647,104.60149543112531,104.60350577813706,104.60553137673594,104.60754341437864,104.60953382995274,104.6115800150869,104.61358523752729,104.61561567406068,104.61763359075928,104.61966945846095,104.62168889245194,104.62373738630427,104.62576340364603,104.6278089915666,104.629840859736,104.63190020185557,104.6339479373253,104.63598781277108,104.63804115261284,104.64007806185336,104.64214239766939,104.64420901538308,104.64624973451025,104.64832383913225,104.65039045197982,104.65244308305114,104.65452733026714,104.65658623129055,104.65867218530707,104.66074249540861,104.66281416989564,104.6648737360991,104.66698008434423,104.6690364423594,104.67114004234011,104.67320597342191,104.6753144437362,104.67740650204269,104.6794999115095,104.68159440108191,104.68368902508226,104.68579496030335,104.68790128809152,104.6900077946804,104.69211082020482,104.69423477115556,104.69635455140546,104.69844822074579,104.70058045088142,104.70271191959151,104.70481994962469,104.70695511312033,104.70908008199578,104.71121760264961,104.71333955421798,104.71547972151932,104.71762034620035,104.71973501476255,104.72188254555336,104.72404109618921,104.72617738311347,104.72834683065962,104.73049322748008,104.73263109416105,104.73477393383139,104.73692034327146,104.73909532742096,104.74125331980443,104.74342359491443,104.7455934812584,104.74777105574992],[104.96095281141076,104.96284428990563,104.96478322865921,104.96671463545488,104.96865469018485,104.9705766169554,104.97248993466857,104.97441077280266,104.97633096778134,104.97830815081363,104.98021959173934,104.98217041804988,104.98412107120419,104.98607905436938,104.98799203345777,104.98994634376542,104.99189889270431,104.9938546258898,104.99582117883934,104.99776396929492,104.9997300144643,105.00170216122015,105.00363387424468,105.00561290531691,105.00757362745537,105.00958308451047,105.01155044219823,105.01352929735496,105.01549647002102,105.01746620951721,105.01947827793083,105.02145257578164,105.02344417927694,105.0254285220226,105.0274179871903,105.0294028446468,105.03142896654713,105.03338904220854,105.03539421393975,105.03739806865137,105.03940914186967,105.04142611685427,105.04343849621009,105.04545178163471,105.04743815873842,105.04949764444306,105.05148754416662,105.0535250471012,105.05554452001088,105.05757532932277,105.05960256914321,105.06160145435881,105.06365776467207,105.06568546583944,105.0677146556649,105.06976471579962,105.07179043007461,105.07383944857285,105.07589892183344,105.07792852604041,105.07996917461598,105.08202658306489,105.0840735416676,105.08615120418263,105.08817784351454,105.09025402170803,105.0923110514885,105.09439818280455,105.09646518259675,105.09851892907659,105.10059447601793,105.10267310358886,105.10475259148708,105.10681754325655,105.10892253367778,105.11100540193267,105.11309166158057,105.11514284704576,105.11724151477033,105.11937476512803,105.12142271003104,105.12353393456237,105.12563349003787,105.1277314465658,105.12984636671152,105.13195087170531,105.13406945231256,105.13617242936895,105.138299649548,105.14041708717414,105.14251574511805,105.1446388909205,105.1467350936543,105.14888984194674,105.15099862350101,105.15313966746778,105.15527068295201,105.15741670295094,105.15953704464009,105.1616639532086],[105.3759551675236,105.3778477710533,105.37974648612189,105.38162992849473,105.38351583080762,105.38544272944982,105.38733718207982,105.38922772319638,105.39114527120962,105.39305085291508,105.39496591042663,105.39686976971976,105.39878502954794,105.40069447485887,105.40261577448652,105.40452151340034,105.40646801548107,105.40838781925251,105.410324492061,105.41225037966426,105.41418715238278,105.4161193053927,105.41805079102267,105.42001470087624,105.4219370877021,105.42388487778649,105.42583587160443,105.42776905541322,105.42972490692837,105.43169217066047,105.43363649901319,105.43561175757331,105.43756222930458,105.43951940348691,105.44150438929175,105.44345022958785,105.44541832670484,105.44736286167263,105.44935597914919,105.45133838844008,105.453301204447,105.45529350356601,105.45726980521056,105.45924431349313,105.4612555659505,105.46323187697843,105.46521518039681,105.46720153471904,105.46918837633598,105.47117763555423,105.47317696872717,105.4751857150394,105.47719994923867,105.47919257275296,105.48120344815409,105.48319766079626,105.48520886686833,105.48723600066583,105.4892449018474,105.49125279309631,105.49327718224808,105.49531998098544,105.49732829290485,105.49936246636125,105.50139963144836,105.50341136551079,105.50547834678211,105.5074936212424,105.50954223435201,105.51157608007279,105.51360849595301,105.51566786116469,105.5177196184416,105.51975206482727,105.52180674505499,105.52386599214833,105.5259193431514,105.52797489410462,105.53003346218281,105.53210181172255,105.53415005360458,105.53621252856877,105.53830154992347,105.54036651608901,105.54243203012686,105.54451489368334,105.54657679722645,105.54867474315354,105.5507556022432,105.55285035893284,105.55492981616115,105.55702579760353,105.55909127375158,105.56121197927307,105.56327135318588,105.56537670047751,105.56746156851662,105.56958131302125,105.57169308255497,105.57378049119227],[105.78897912213768,105.79084428038962,105.79273427244281,105.79457462997759,105.79646147421644,105.7983243133273,105.80020436323848,105.80209396017685,105.80396466884574,105.80584746133204,105.80774060334063,105.80960114036978,105.81150055078486,105.81338551437348,105.81527117794084,105.81719391459228,105.81907345448342,105.82098785890346,105.82286358779338,105.82476381379718,105.8266827597234,105.82858338172889,105.83049828693834,105.83240829737501,105.83431569515304,105.83622829155124,105.83816461561682,105.8400716555238,105.841995664321,105.8439337633351,105.84584518744484,105.847774602399,105.84971365438041,105.85164554995436,105.85358198385593,105.85550681434651,105.85744775787857,105.85938073292337,105.86132648263504,105.86326430262959,105.86523307462161,105.8671734010168,105.8691215456895,105.87109238384323,105.87303087602467,105.87499736686827,105.8769421934469,105.87890749164642,105.88089570505574,105.88284708267179,105.88481681247174,105.88678995037105,105.88876376727816,105.8907455274439,105.89271232343579,105.89469278176072,105.89667415538474,105.89865241601515,105.90064717553487,105.90262729026168,105.90460762711746,105.90661066400426,105.9086289652759,105.91060670216332,105.91261113860041,105.91460546636392,105.91661657895789,105.91862991894286,105.92061393787408,105.9226295497228,105.92465797104997,105.92666478277742,105.92869217654292,105.93069624435427,105.93272191234325,105.93474516400879,105.93677788996612,105.93879552062303,105.9408285689075,105.94283224485409,105.9448700056156,105.94693311779113,105.94895020145805,105.95101672555579,105.95303491701615,105.95507280477239,105.9571233282782,105.95918649625143,105.96121666534324,105.96326665535769,105.96533450216775,105.96738019599881,105.9694361533708,105.97151197576974,105.97356632505266,105.97562302603585,105.97766686818584,105.97975889435877,105.98181816423161,105.98387864339813],[106.19988467471853,106.201719365089,106.20355370478649,106.20540467412596,106.20722562296085,106.20908458274832,106.21090070782869,106.21276986483693,106.21460538004996,106.21646312528075,106.21832697772811,106.2201709022052,106.22203914381859,106.22389691012972,106.22579713183954,106.2276258459483,106.22950058692443,106.23137948069969,106.23324023955908,106.23512046721657,106.23700173011962,106.23888884131256,106.2407570180914,106.24263700477972,106.24450547602605,106.24641057149347,106.24831682825288,106.25019013961507,106.25209006482946,106.25398509224499,106.25586967131032,106.25777113190972,106.25968734860746,106.26158289163405,106.26348571928943,106.26540483119929,106.26730854177103,106.26921862401684,106.27112608160932,106.27306741470298,106.27495705851013,106.27688220663508,106.27880882166892,106.28074575209484,106.2826499295691,106.28460245575688,106.28650851698085,106.28845823069962,106.29041257327773,106.29231649974432,106.29426510161099,106.29620142156216,106.29816894720666,106.30007742330221,106.30206991957868,106.30401352470797,106.30593354197967,106.30791517793486,106.3098553775445,106.3118068845949,106.31377694908736,106.31574516158301,106.31770483541928,106.31965800798014,106.32163369723511,106.32361193684525,106.32557969905722,106.32755143497631,106.32952351521931,106.33149553610228,106.33347867561915,106.33545672641476,106.33744954507274,106.33945311452923,106.34144624961077,106.34341278010031,106.34540560125292,106.3474057466985,106.3494132315057,106.35139695352397,106.35340476019583,106.35541804631484,106.35740511441875,106.35941657525822,106.3614403366561,106.36344801685081,106.3654595855611,106.36746987930674,106.36950311132168,106.37150730846574,106.3735503580737,106.37556534697053,106.37757385164352,106.37962840227098,106.38162492240774,106.38368755793142,106.3857026514755,106.38775372117614,106.38978654389196,106.39184208084848],[106.60839913909683,106.61021949526973,106.61203506327831,106.61385064453793,106.61566273317469,106.61746091361022,106.61928877580405,106.62110873399074,106.62294619919669,106.62475769980554,106.62659112068692,106.62843923121655,106.63026179123767,106.63210582418681,106.63393379706899,106.63575574386944,106.63760290382011,106.63943821934501,106.64127644501318,106.64312424865189,106.6449914329177,106.64682643123281,106.64869100130359,106.65055834165341,106.6524039099905,106.65424710067668,106.6561224374373,106.65797170769193,106.65983701542325,106.66171426673779,106.66357453279605,106.66545121025516,106.66733471756042,106.66919792268709,106.67108432936004,106.6729404595394,106.67483742732875,106.67670474608687,106.67860598782738,106.68049776196096,106.68238284324744,106.68426387576605,106.68617350073319,106.6880450702068,106.68996165200308,106.69185668481039,106.69375417114745,106.69566325822147,106.6975703212266,106.69948452519456,106.70137403987151,106.70330179193525,106.70522048619264,106.70710749052219,106.7090267186492,106.71094890708991,106.71286914363172,106.71481105683105,106.71672231409354,106.71862567939407,106.72057656322632,106.72249919062392,106.72442655620497,106.72637423468325,106.7283224790809,106.73025579151117,106.7321863959954,106.73413235942738,106.73607010154049,106.73802811715302,106.73996667645415,106.74193874444488,106.74388538888851,106.74584761944777,106.74779812610322,106.74977749896568,106.75173277745598,106.75369403237059,106.75564848325924,106.75761888223849,106.75958312718683,106.76156546759918,106.7635225049515,106.76551195237016,106.767479296439,106.76945125098693,106.77144539657884,106.7734210968307,106.77542039489126,106.77739004246833,106.77938407690559,106.7813876374305,106.78336144704743,106.78536806637688,106.78736345908912,106.78939029286953,106.79137475785322,106.7933627410991,106.79537946602427,106.79737464242369],[107.01445956829647,107.01623709380688,107.01802824449196,107.01980767525541,107.02159596848801,107.02339309801957,107.02516379987074,107.02698318094312,107.02874732701574,107.03057228398829,107.03236792795542,107.03416444038855,107.03597123408767,107.03777615732642,107.0395848395506,107.04140295393434,107.04322462196907,107.04501787010156,107.04683446517845,107.04864802130513,107.05048351710764,107.05230089111835,107.05412243874032,107.05594734983215,107.05778328261754,107.05960445911356,107.06142751493766,107.06327557540003,107.06510865466664,107.06695650423376,107.06876874814665,107.07063265983297,107.07248148323728,107.07430935450154,107.0761782333698,107.07803876599868,107.07986711371593,107.08172041330488,107.08353877783725,107.08543804649044,107.08728306654866,107.08913120715113,107.0910278311336,107.09286397494006,107.09475301890397,107.09660944739933,107.09849865371075,107.10035560291676,107.10223598769994,107.10408636079508,107.1059796370262,107.1078556245202,107.10973211066407,107.11163918355453,107.11350718453964,107.11539443355198,107.11729070349664,107.11917708607476,107.12108895100747,107.12295471011387,107.12487882454191,107.12677478412722,107.12865995073503,107.1305889709026,107.13249895902257,107.13438641959752,107.13630908956527,107.13822562233653,107.14012587328898,107.14203808625186,107.14394932471373,107.14588484085016,107.1478124534229,107.14974620180396,107.15166322123439,107.1535865836319,107.15551407440255,107.15747254301652,107.15938431421628,107.1613340045712,107.1632604226194,107.16520886405279,107.16716484138492,107.16909004389277,107.17103258996511,107.17297918860945,107.17495082854768,107.17687591659919,107.17882361555175,107.18078291769552,107.18273308290327,107.18471433448005,107.18666673222694,107.18862091009134,107.19058484614418,107.1925652077002,107.19453223271375,107.1965072488415,107.198445641007,107.20042447807023],[107.41786573120127,107.4196407882351,107.42138592885301,107.42314964736552,107.42491111561108,107.4266727128971,107.42844223077839,107.43018888357423,107.4319594940816,107.43372461302083,107.43550652067272,107.43728421224432,107.4390636510587,107.44081219584572,107.44261530274794,107.44439523004128,107.446167821452,107.44796923009207,107.44975659986031,107.45155346056086,107.45333898257431,107.45513781093837,107.456912906739,107.45872526568037,107.46052527961092,107.46232163229281,107.46412441563261,107.46594284931741,107.46772806493907,107.46954574339354,107.4713513985791,107.47314636590207,107.4749763712274,107.47679961925294,107.47861319661733,107.48041483823417,107.48225572416204,107.48406184927148,107.48589381102492,107.48771784025936,107.48956457436884,107.49139452102676,107.49323185392424,107.49505732202051,107.49689129608342,107.49873028175702,107.50058708774834,107.50241517059297,107.50425702902842,107.50612786707158,107.50796298559862,107.50982751725792,107.51166620025633,107.51352955991925,107.51539077018359,107.51723381859657,107.51910357536767,107.52098786202991,107.52283669158173,107.52470127469378,107.52658217740183,107.52843489645963,107.5302995161201,107.53219220826838,107.53406061929391,107.53592472412997,107.53782583196248,107.53967647817869,107.54157381643861,107.54346013175635,107.54534245807417,107.5472239571526,107.54910389677556,107.55100750519807,107.5528995525727,107.55480544687896,107.5567097990992,107.55859619773457,107.56051737737519,107.56240813565742,107.56430302314322,107.56620597146525,107.56813575815056,107.57004171781489,107.57195918384782,107.57388873166322,107.57579155655442,107.57773016456618,107.57962218742526,107.58155064470972,107.58349797629589,107.58541886347548,107.58734885841822,107.5892685285874,107.59120100608372,107.59314456566156,107.59506463207256,107.59701072177424,107.59895626936516,107.6008906125411],[107.81855743985548,107.82029920430026,107.8220027484233,107.82374603673732,107.8254635376733,107.82722007280593,107.82895226662075,107.83069020966896,107.832438446825,107.83417372066614,107.8359185320445,107.83766636063338,107.83940696198188,107.84115225497904,107.84291477707788,107.84466784645713,107.84642208537302,107.84818705530236,107.84993478403081,107.85168216192622,107.85345889182221,107.85521373309436,107.85698110121209,107.8587538464645,107.86051279941137,107.86229606857485,107.86403863057447,107.86583474150052,107.86763053325657,107.86942907351049,107.87118084036513,107.87296679733102,107.87475553718612,107.87653249698523,107.87832177297807,107.8801118979759,107.88191954530475,107.88370432316745,107.88549413103132,107.88731664884737,107.88909187399577,107.89089325591124,107.89270874271695,107.89450177963037,107.89633122213543,107.89812927703608,107.89995279731951,107.9017488802809,107.9035725669592,107.9053891554488,107.9072241422605,107.90901845894771,107.91085374491954,107.91266681666104,107.91449550769366,107.9163328362019,107.91816747547242,107.91998226105159,107.9218148187362,107.92365296771266,107.92548805752214,107.92732882779444,107.9291744479128,107.93101561194749,107.932862310957,107.93470258127437,107.93655066265406,107.93839043896853,107.94025608114767,107.94211314481736,107.94396456497154,107.94583292624193,107.94769765826852,107.94956266008153,107.95141779888108,107.95330225767687,107.95513679063659,107.95699917640127,107.9588623954191,107.9607688688254,107.9626293736166,107.96450771374847,107.96637550377939,107.9682507088866,107.97013324208217,107.97204330229813,107.97391402219958,107.97581844177175,107.977704465444,107.97959409287151,107.98146180973046,107.98336173425439,107.98526580624541,107.98715232424733,107.98906585497097,107.99096265834139,107.99288416913289,107.99478009345637,107.99668150421716,107.99860469028894],[108.21641684942207,108.21810762030108,108.21981265771016,108.22149627485325,108.22321682418564,108.22492074427025,108.22664223245734,108.22834533248867,108.2300553723667,108.23177349303744,108.23346875912367,108.23521272564366,108.23691216764249,108.2386282197134,108.2403465874226,108.24209046513631,108.24380247904783,108.24553581609504,108.24727307163668,108.2490090655333,108.25072937104876,108.2524684770552,108.25422070892687,108.2559471385975,108.25769054252335,108.2594485220473,108.26118969392371,108.26291773106291,108.26466896642367,108.26642881642972,108.26817973398268,108.26993255766615,108.27167886565924,108.27344933009722,108.27520788434003,108.27695091693847,108.27872406705733,108.2805021907405,108.28225125497477,108.28403827652566,108.28578907511073,108.28756853983339,108.2893320813442,108.2911061731406,108.2928929565938,108.29469044079642,108.29646188261374,108.29821998032756,108.30001206425372,108.30181751489026,108.30360707988584,108.30539482600697,108.30718506555044,108.30897513955483,108.31076406748862,108.31258973792873,108.31438344259793,108.31619106809589,108.3179839813361,108.31977406569294,108.32159080031586,108.32340374584601,108.32521051256894,108.32699714737089,108.32882338707702,108.33065300335815,108.33245131788154,108.33428763074039,108.33611400708234,108.33794812890487,108.33975967511051,108.34158587825357,108.34340712288478,108.34525448624167,108.34707579012982,108.34890893728682,108.3507427115263,108.35258696375658,108.35442303819282,108.35626227032131,108.35809394698506,108.35993964038444,108.36180525982456,108.36364019688817,108.36548626787115,108.3673459036579,108.36918103535746,108.37105695132759,108.3728888388683,108.3747668975772,108.37662407386445,108.37849276277147,108.38035152443422,108.38220015440156,108.38408841401956,108.385942792564,108.38784711124939,108.3896824871151,108.39158584005546,108.39345464064733],[108.61134307709276,108.61301811321296,108.61469504542409,108.61637365152872,108.61806178747622,108.61971204378956,108.62140389825436,108.62308128596776,108.62476368873543,108.62643363764343,108.6281328342616,108.62983971579415,108.63150086617625,108.63320912047979,108.63490178210586,108.63658231349116,108.6383062007279,108.63998138482677,108.64169281656305,108.64341649127554,108.64510389940313,108.64679826373893,108.6485320515214,108.6502304596639,108.65195788194141,108.65366468911671,108.65538118930985,108.65711135111368,108.65882957121627,108.66051692033417,108.66225665425495,108.66400101340608,108.66571477824887,108.66743978750512,108.66917377963607,108.6708962951476,108.67263549059332,108.67436969741755,108.67612048591415,108.67785271963135,108.6795875185272,108.68132501029609,108.68309758440516,108.68483663361428,108.68657752320394,108.68832255491812,108.69007095274188,108.69183006022122,108.69359026974323,108.6953405969168,108.69709663756437,108.69884264463008,108.70059625016613,108.70237606269022,108.70412740983784,108.70591993159624,108.70770381441696,108.70947034175533,108.71125946646097,108.71299753550605,108.71475768253292,108.7165586220196,108.7183297813363,108.72011021984454,108.72190450007977,108.7236848726238,108.72548224620971,108.72726588318275,108.72905220130042,108.73084279064224,108.73263640735163,108.73444174554488,108.73623034835643,108.73804156202019,108.7398246687424,108.74162390575987,108.7434433868826,108.74525122185574,108.74705301172223,108.74889196323629,108.7506835747934,108.75248887399523,108.75430670288253,108.75611784772914,108.7579473759495,108.75975283608673,108.76156529507178,108.76339135269373,108.76521357531524,108.76702627316203,108.76887709945363,108.77070205411295,108.77252437926502,108.77437351524698,108.77620638304347,108.77803706561613,108.77989530693294,108.78172101451374,108.78359317298614,108.78542031353113],[109.00325989711523,109.00489213255987,109.00652459841396,109.0081749364723,109.0098275797646,109.01148248623262,109.01312015467877,109.0147799027682,109.01644506178634,109.01811124211106,109.0197702035347,109.02143693915305,109.02309511818513,109.02476067977189,109.02643994976609,109.02809923007297,109.0297727600522,109.03143118573792,109.0331044795219,109.03479563351664,109.03646516410575,109.03813355996424,109.03981764417806,109.04149307544773,109.04320580553079,109.04485719373181,109.04654667476507,109.0482493771165,109.04992537366715,109.05163013395898,109.05332969044608,109.05503937648025,109.0567156524271,109.0584259825234,109.0601120160929,109.0618360067665,109.06354549449395,109.06524663636533,109.06694915406638,109.068644240022,109.0703703232632,109.07208039957156,109.07378200453145,109.07550272093901,109.07724567831454,109.07896004774838,109.08069567424528,109.08241371194481,109.08413146248202,109.08585744845179,109.08760209515215,109.08931594572755,109.09105696790422,109.09277830410467,109.09451244204176,109.09625382652004,109.09799765214056,109.0997299150849,109.10147378508675,109.10321609137274,109.1049693689472,109.10671581543855,109.10847080355157,109.11021578822263,109.11196230364904,109.11372984129511,109.11548023361897,109.1172309286151,109.11901592188443,109.12076799416181,109.12252135538222,109.12428056125233,109.12606604968377,109.12782609215273,109.12960543884383,109.13136617804886,109.133129261169,109.13490614259027,109.13669817281198,109.1384652831899,109.14024425471182,109.1420121288883,109.1438080364599,109.14560804044352,109.14740253438336,109.14917472161326,109.15097133984345,109.15277479397415,109.15453080919178,109.15634976661208,109.15815132555034,109.15995020992872,109.1617523792166,109.16355226370933,109.16534390103257,109.16716709934003,109.1689694000531,109.1707744078755,109.1725884518881,109.1743870261848],[109.39209033211867,109.39370671140082,109.39532064642724,109.39696608585113,109.39857889708053,109.40022159458026,109.40180856959424,109.4034388067683,109.405075809333,109.40672551964,109.40831710445909,109.40999163571064,109.4116173994378,109.41324459699815,109.41488766107643,109.41651990651599,109.41817476653982,109.41982477820139,109.42147386838283,109.42310432372385,109.42476517388161,109.42640791782321,109.4280560949464,109.42971258610726,109.43137463241692,109.43301556676076,109.43467938087126,109.43636025805708,109.43800992562504,109.4396787002222,109.44135110671341,109.44300638136201,109.44467425135443,109.44634129387865,109.44802550596515,109.44968082231944,109.45136904011943,109.45304901521585,109.45473106392924,109.4564170502152,109.4581003904899,109.45978143457714,109.46147112111107,109.46314782905245,109.46482467565355,109.46654218216096,109.46822079687249,109.46992561872696,109.47160845582214,109.47331198710867,109.47501904496467,109.47672445125276,109.4784307109583,109.4801035279723,109.48182305924206,109.48355531760838,109.48522846413012,109.4869475105179,109.48867561160603,109.49037946582057,109.4921046583207,109.49382041307345,109.4955168727043,109.49725507437373,109.49897455647074,109.50072361822538,109.50242541096024,109.5041726801685,109.50589216449585,109.50762387159075,109.50937136575001,109.51108701058051,109.51282222486493,109.51453819351055,109.51628516667472,109.5180273915787,109.51978545925098,109.5215147883408,109.52326132246,109.52503283103663,109.52678857647189,109.52853816307497,109.53027997790969,109.53203465019158,109.53380966554735,109.53555636335852,109.53731833174507,109.53904763095002,109.54085183804003,109.54260508972816,109.5443590511635,109.54613369866824,109.54790376597091,109.54968343476665,109.55144298629793,109.55322016908778,109.55501119696984,109.55678428007175,109.55856056344449,109.56033951500174],[109.77785093499661,109.77941069876447,109.78101647712788,109.78261840575256,109.7841980655439,109.78579644745177,109.78738364110063,109.78899647836772,109.79061200808842,109.79219566572196,109.7937950724565,109.7954151107233,109.79701841412168,109.798625090374,109.80023474281748,109.80185151536152,109.80346706988034,109.80509426481285,109.8066881492849,109.80830670151013,109.80992468625224,109.81156521128526,109.81320334930194,109.81482141020555,109.81644819989954,109.81807964222787,109.81970565956996,109.82134387711142,109.82295988338726,109.82459278722817,109.82623448895711,109.82788240933375,109.8295186967201,109.83117568707306,109.83280390839384,109.83445301350665,109.8360940190365,109.83775119111513,109.83939851665511,109.84105738081348,109.84270509801783,109.84438261725393,109.84603903800921,109.847695805264,109.84933339529145,109.85099915337696,109.85266214784897,109.85432275042038,109.85599313167486,109.85768332845984,109.85934503289643,109.8610138068744,109.86268308387994,109.86436777460327,109.86602811488694,109.86772527148291,109.86939630025726,109.87108047737225,109.87276589982439,109.87444668253049,109.8761400965074,109.87782982994545,109.87951611464584,109.88119840711161,109.88288714031953,109.88459708100444,109.88630081128872,109.88796404736163,109.88969309617728,109.89138192207773,109.89308695117806,109.89479069375334,109.89650310540833,109.898216361808,109.89991971412235,109.90162713169914,109.90334702428306,109.90506149911002,109.9067605163893,109.90849864050918,109.91020994408082,109.91193663479358,109.91366560078582,109.91538589838417,109.91709378650617,109.9188350877383,109.92055965830984,109.92231011412066,109.9240347968534,109.92574155703889,109.927483540199,109.9292214716307,109.93095006473138,109.93271046131386,109.93445770181688,109.9362043861161,109.93793033234257,109.93968048553192,109.94143614414429,109.94317638158255],[110.16039927964998,110.16197232342776,110.16353978939631,110.16509773152377,110.16666957671137,110.16823794117822,110.16982324511892,110.17137748069015,110.17297544850994,110.17454693535494,110.17610223245254,110.17769885183657,110.17926067903409,110.18085840007163,110.1824315045964,110.18403688554247,110.18562111706572,110.18720545056999,110.18878465882199,110.19038859581535,110.19196914091314,110.19357139280423,110.19517277708266,110.19677017036061,110.19836465497717,110.1999441046371,110.20156207460987,110.20317195266789,110.20477400988975,110.20638925996597,110.20801277578012,110.20960476380455,110.21121320068445,110.21285787533103,110.2144625952199,110.21607542671495,110.21770657476468,110.21930547359311,110.22093835575212,110.22255042576842,110.22418260741765,110.22581758368179,110.22742944047472,110.22907089694392,110.2306898898493,110.23232271272559,110.23395255535925,110.23560340199485,110.23724205655978,110.23888840616539,110.240541668683,110.24216256261494,110.24381144186687,110.24545914454556,110.24710369238846,110.24874999177689,110.2503964221592,110.25207109026425,110.253733296968,110.25538577515599,110.25705511620436,110.25870266628071,110.26034828452126,110.26202912054968,110.26368702639108,110.26534033537696,110.26700952664528,110.2686937576594,110.27035458217992,110.27202912429068,110.27370125836956,110.27537159558287,110.27705562117524,110.2787247270434,110.28040593942919,110.28208946227028,110.28377813038921,110.28545710870381,110.2871571420973,110.28881971487779,110.29052236490672,110.29220729854983,110.29389679973774,110.29558260836968,110.29729029674226,110.29897978492997,110.30069552687185,110.30239959629202,110.30407465864201,110.30578230535022,110.30750807531334,110.30921495273651,110.31092618117994,110.31262844341586,110.31432974739839,110.31604921873205,110.31778141484669,110.31946925661946,110.32119496889791,110.32290992850537],[110.53978527165707,110.54135432981086,110.54288200175833,110.54441833078079,110.54595337594836,110.54751278911858,110.5490452356803,110.55060634790433,110.55214031682037,110.55370568238928,110.55524902505886,110.55679480842748,110.55833176329539,110.55989659552976,110.56144801585208,110.56302558265179,110.5645683167389,110.56612743135508,110.5676722350768,110.56925452231212,110.57083617316854,110.57239844429591,110.57398328150202,110.57553224826646,110.5771181133722,110.5787013511025,110.58028150146008,110.58184549857349,110.58342041047506,110.5850079844491,110.58659653110064,110.58817263779993,110.58976184238443,110.59134474576987,110.59294506016576,110.59450384779174,110.59611486598536,110.59772058731058,110.59930511823025,110.60089275738885,110.60250275317935,110.60409867287248,110.60569369606917,110.60728983869156,110.60889792172338,110.61051708986608,110.61211468560484,110.61371421563578,110.61534044449452,110.61694229025052,110.61855434446315,110.6201690949623,110.62178045217206,110.62340206523811,110.6250171575467,110.62664727981061,110.62826848416435,110.62992225157475,110.63154381191484,110.63313204533146,110.6347931019241,110.63643850417,110.63805404096797,110.63967158105247,110.64131479934126,110.64293980115399,110.64458557341595,110.64622655119543,110.6478663059075,110.64952741945044,110.65115902178832,110.65278217834324,110.65445361893603,110.65610204961509,110.65775499093029,110.65939106781919,110.66103860397516,110.66271604231869,110.66437466978792,110.6660353577528,110.66767749231698,110.66932080491647,110.67097270188049,110.6726431211583,110.67432242512288,110.6759793663202,110.67764004814839,110.67932979167945,110.68101500920757,110.68266676844192,110.68434962689314,110.68603069845517,110.68769422160804,110.68940097676575,110.69108161885079,110.69275490667209,110.6944478018905,110.69610899254614,110.69779855995958,110.69949106834761],[110.91599099165785,110.91750420823624,110.91900737977997,110.92051735542995,110.92204547104663,110.92355450554223,110.92508002912041,110.92660513035268,110.92810531955433,110.9296347456991,110.93116262432332,110.93268206725172,110.93421545845763,110.93573534290253,110.93726413592518,110.93880359002833,110.94033092618311,110.9418526327814,110.94341456222257,110.94494062619836,110.94646288933146,110.94801337462732,110.94957343088247,110.95110689501118,110.95267826788177,110.95420903461908,110.9557353781247,110.95731654745146,110.95886343831725,110.96040849186222,110.96194296202086,110.96352401757918,110.96507419938409,110.96662743706665,110.96820623778606,110.96976609420085,110.97133189639837,110.97289534924396,110.97445882492795,110.97602852734553,110.97758294294276,110.9791565477996,110.9807326543166,110.98231274128185,110.98389647813254,110.98548101529809,110.98704317934441,110.98862633633061,110.99020387751382,110.99179741637651,110.99337186110127,110.99495974631789,110.99656125442591,110.99814241343272,110.99972618531584,111.00131115297332,111.0029192280551,111.00450911146197,111.00610792262346,111.00770397424878,111.00931440786731,111.01092577944546,111.01252543345065,111.01414498249605,111.0157318405322,111.01735449218668,111.01895057897578,111.02056130949968,111.02216987245042,111.02378441213375,111.02541543975954,111.02703053488592,111.02864416636751,111.0302687429418,111.03190061779924,111.0334998345716,111.03513538042223,111.03674999061786,111.03839448698314,111.04001406884495,111.04165269405038,111.04329089735623,111.044907320828,111.0465546872661,111.04819837617757,111.049822138564,111.05147171244323,111.0531031710043,111.05474927846016,111.05640119855498,111.05802549996149,111.05969272141806,111.06133230513231,111.06299096687246,111.06464548909523,111.06629656647696,111.06795789546791,111.06958138004559,111.07125606036341,111.07291525643957],[111.28890264227303,111.29040198747472,111.29186364472184,111.29337656124605,111.29487065021401,111.29636216921313,111.29786126571541,111.29933325848697,111.30084355759311,111.30233793713913,111.30384087016242,111.30532947532397,111.30683982401767,111.30833931169397,111.3098415926014,111.31133668177556,111.31286339987498,111.31436740785603,111.31585931882664,111.31738681297261,111.31891408210709,111.32042651493222,111.32192599835555,111.32345894386802,111.3249839919566,111.32648386302995,111.32801584555541,111.3295168325063,111.33104047236877,111.33258969259263,111.33409514895955,111.33562791755026,111.33718465238894,111.33870245264374,111.34023786808083,111.34177825607375,111.34332573092749,111.34483619327482,111.34639399976113,111.34793032773655,111.34946845680545,111.3510288789947,111.35257091246346,111.35412462469579,111.35564918733522,111.35721014875317,111.35875267541618,111.36031543514336,111.36185689986004,111.36343966451766,111.36498225029223,111.36655241172566,111.36811936833851,111.36967617057728,111.37121084673822,111.3727921952114,111.37436707862146,111.3759160408727,111.37753214409227,111.37907806942344,111.38065562278567,111.3822498580021,111.38379447457942,111.38537853340168,111.38696723179802,111.38853055897081,111.39011798385093,111.391701154042,111.39327367115652,111.39487589722678,111.39646312116597,111.39803841607144,111.39962433216556,111.40124336735559,111.40280408187796,111.40441810059762,111.40600488924812,111.40760292274281,111.40922245915041,111.41081591021789,111.41241660478677,111.41401255253336,111.41563957883209,111.41723575675894,111.41884163352003,111.42047002629825,111.422068851847,111.42368182445307,111.42529431300827,111.42690012234675,111.42851829849386,111.43014571291788,111.43176859606785,111.43337201870983,111.43502245755913,111.43661634278764,111.43826355805432,111.43989526114157,111.44150192172467,111.44313210824723],[111.6586033316099,111.66007113578905,111.66154055439802,111.66298391490332,111.66446281333833,111.66592464038058,111.66739219875997,111.66886677919965,111.6703381966291,111.6717987596152,111.67326856811269,111.67475569703716,111.67621343637163,111.67770282046243,111.67919284794372,111.68066942159426,111.6821430236982,111.68362692407868,111.68512462750668,111.68659050975327,111.68809266896042,111.68957238639408,111.69107678890705,111.69256074615916,111.69406607259491,111.69555090454944,111.69704962577255,111.69854243445346,111.70004943736322,111.70154280943868,111.70304029329866,111.70454560516623,111.70603802582498,111.70755167107097,111.70906280484614,111.71057072395345,111.71207715373677,111.71359424791896,111.71510890765111,111.71660511628541,111.71815557152232,111.71966190859189,111.72118080129019,111.72270105597644,111.72421445713016,111.72574803430629,111.72724944569231,111.72879911981174,111.73033544673096,111.73185694479191,111.73338757455215,111.73491987091612,111.73645434628767,111.73798128726085,111.73953875153413,111.74107104701075,111.74260554039623,111.74413945304624,111.74567732480918,111.74723897161967,111.74878694897093,111.75032854737185,111.75186247786374,111.75344543923458,111.75498371734363,111.75653340172914,111.75807561660581,111.75961528780894,111.76118593812421,111.76275376821704,111.76430347676421,111.76587356798184,111.76744330622948,111.76902622635126,111.77055944098329,111.77212768431359,111.77369410867819,111.77526553628033,111.77684671330883,111.77840399562645,111.77998348075975,111.78156242397043,111.78313870842655,111.78472065359578,111.78630749853764,111.78786357683805,111.78947091547855,111.79103678405184,111.79263422010919,111.7942216891995,111.79581474904072,111.79741663786953,111.79900748834515,111.80057657180282,111.80218386400188,111.80376401373096,111.80537008343194,111.80696989246076,111.80857228278754,111.81019447508008],[112.02505866429688,112.02648295861609,112.02791457274937,112.02937553245162,112.03082296276503,112.03224551025671,112.03368674317478,112.03513831909649,112.03658396328444,112.03803265434094,112.03946890992229,112.04092148703417,112.04237507388329,112.04381451402756,112.04526606079881,112.04675374989131,112.0481850708097,112.04964178272076,112.05112029165316,112.05257656421391,112.05402403586977,112.05550011547723,112.05698443324295,112.05842401147098,112.0598837304394,112.06136557799923,112.0628175963781,112.06430395841123,112.06577178934526,112.0672401268937,112.06872552895814,112.07021125753184,112.07166027175163,112.07317633691916,112.07465629753467,112.07613771824808,112.07761324141566,112.07913069859868,112.0805789657309,112.0820915645359,112.08355402354987,112.08506435301749,112.08656007916409,112.08806070758096,112.08954872201609,112.0910470650548,112.0925499056269,112.09401820269564,112.09554671280246,112.09703700320574,112.09854505101612,112.10007256911828,112.10155725344968,112.10309206110564,112.10458023601919,112.10611170936549,112.10759767280766,112.10914055814905,112.11065296841954,112.11216563612602,112.11366880711527,112.11520076467514,112.11672007590778,112.1182326719663,112.11976755690827,112.12127608564529,112.12282033834097,112.12435983497676,112.12588579418806,112.12741092827018,112.12894405997807,112.13048483330769,112.13201288389766,112.13354500068158,112.135092665207,112.13663431924934,112.13816281007094,112.1397159127365,112.14126960853972,112.14281145922332,112.14435170374198,112.14590447594227,112.14744961031995,112.14899098833664,112.150555912455,112.15210317195674,112.15366956628263,112.15522938934612,112.15678226040225,112.15833953463694,112.15989732430842,112.16145428780662,112.16302000978183,112.16458993847093,112.16615709700811,112.16772286454822,112.1692971357163,112.17085845436824,112.17243208232019,112.17400310013507],[112.38827627959324,112.38967390806575,112.39108919800955,112.39248433381263,112.3939148207669,112.39533032769478,112.39674932069076,112.39817004542303,112.3995853966574,112.40100764021713,112.40243822761988,112.40385748245542,112.40528689473392,112.4067277779224,112.40816009748929,112.40956127338947,112.41101602238359,112.4124417753383,112.41388718267558,112.4153101634067,112.41675518549718,112.41818873230409,112.41965059645922,112.4210562032006,112.42251232327847,112.42394336354414,112.4254078471209,112.42683462797591,112.42826853246547,112.42975019248907,112.43120066226575,112.43264873988487,112.43409988996305,112.43556851040827,112.43701126217161,112.43848285898221,112.43991794726745,112.44140174228707,112.44286441995675,112.44433316739196,112.44578831126258,112.4472659521999,112.44873453933535,112.45019611907449,112.45165960185264,112.45313640860998,112.45461595233272,112.45606691358338,112.45757816140508,112.45901476161187,112.46052645931937,112.46199714107267,112.46346725521376,112.46496910637248,112.46644745570316,112.46793523786292,112.4694126024398,112.47088874155418,112.47239497213756,112.47389641706852,112.47538797163747,112.47686931472708,112.4783742136741,112.47985993384569,112.48136827002766,112.48286910442815,112.48434695339668,112.48586432740224,112.48737657564263,112.48887543178557,112.49037117947994,112.49187315629392,112.49338842882567,112.4949135646863,112.49642473839667,112.49793384171687,112.49944159359134,112.50097099693501,112.50247444496108,112.50399396008463,112.50549985223465,112.50702954476432,112.50857620438903,112.51009246994711,112.51160504182569,112.5131360611535,112.51465247467232,112.51618596747684,112.51773390564892,112.51924045041865,112.52081634194087,112.52234069024853,112.52386764623293,112.5253912816842,112.52694778669986,112.52849213210928,112.53004005743358,112.53156372047663,112.53309874435152,112.5346706953596],[112.74822849288492,112.7495963229658,112.75100236584538,112.75238019214707,112.75378266220189,112.75516210636931,112.75658261191798,112.75796584110238,112.75935210873067,112.76074670075745,112.76215713022539,112.7635384686192,112.76495605024613,112.76637373335875,112.76776400971774,112.7691731894159,112.77057963975264,112.77199244462017,112.77340545892244,112.77479015704878,112.7762305358132,112.77763349010245,112.77905681640877,112.7804596893008,112.78188893645354,112.78330745044063,112.78474786150198,112.78614707112317,112.78757570943094,112.78901641380762,112.79042492972879,112.79187274839323,112.79327889708752,112.79472657110463,112.79616455115942,112.79757425476998,112.79901516060845,112.80045177352875,112.80189357471197,112.80333843524639,112.80477029570332,112.80621682063907,112.80765065232632,112.80910924351205,112.81055376949071,112.81198441913243,112.81344215189606,112.81489382445639,112.81634021286598,112.81779028939214,112.8192397236347,112.82068902246343,112.82215572377429,112.82358910531327,112.82506530434947,112.82653422398512,112.82797901835447,112.82946538062933,112.83090700113951,112.83238757743204,112.83384735783302,112.83532452829404,112.83679281527188,112.83824574353628,112.83972508963775,112.84121276879846,112.84266054969052,112.84415540837168,112.84564596539903,112.84712168329402,112.84860272218455,112.8500699808277,112.85155771122484,112.85303945935944,112.8545150925953,112.85600534776947,112.85749357337349,112.85899652991391,112.86049592926986,112.86198040407695,112.86345684293289,112.86494376301584,112.86647104605467,112.86796238983125,112.8694739427533,112.87095195522309,112.87244768269795,112.87395997215943,112.87547554841235,112.87697705116315,112.87848525251877,112.8799924245402,112.88150342865761,112.88301730650377,112.88453036379374,112.88603890560826,112.88756190969995,112.88907062726317,112.89060236245118,112.89211025117564],[113.10494042716202,113.1063007755096,113.10767380857756,113.109055169933,113.1103989433843,113.11179269931343,113.11312415476077,113.114520287094,113.11589630025705,113.11726817637836,113.11862152952628,113.12001801869181,113.12139403835076,113.12278323943447,113.12413888667997,113.12554227398871,113.12691468920757,113.12831104546467,113.12971639530706,113.13107496194095,113.13248008544466,113.13385008668948,113.13525236929975,113.13663454724804,113.1380400619889,113.1394471166085,113.14083920581905,113.14224189739222,113.14362687233161,113.1450142985594,113.1464397366718,113.14784294864157,113.14923198312358,113.15066007341815,113.15206695622499,113.153461896059,113.1548803777675,113.15631400429083,113.15768055443175,113.15909725609193,113.16055016454223,113.16194353798372,113.163361588315,113.164791246813,113.16622808852057,113.16762961489697,113.16906080054063,113.17047699477928,113.17189947241431,113.17334849977267,113.17476739972535,113.17620763804436,113.17762636653185,113.17905821349527,113.18047271870219,113.18192386565015,113.18337158180591,113.1847901799193,113.18621362640349,113.18766559928349,113.18913753554364,113.19056690307187,113.19201312222215,113.19346175034343,113.19490475426429,113.19636206064858,113.19778743362026,113.1992591631496,113.20069245859163,113.20214775896629,113.20362782979359,113.20506876153313,113.20652590151546,113.20798577567663,113.20945985981227,113.2109201468292,113.21238425130457,113.21382768412737,113.21529178571264,113.2167622146681,113.21824615189828,113.21971053475461,113.22118703752474,113.22262750774458,113.22412355032316,113.22560532345074,113.22709288399176,113.22855199971941,113.23003235486706,113.23152648346709,113.23299723772352,113.23447953080158,113.23595517460933,113.23744039519576,113.23892056113955,113.2404277260608,113.24192465120333,113.24339417844052,113.24489225744131,113.24639007798513],[113.458418509227,113.4597738274836,113.46111600853457,113.46246343191724,113.46381430348251,113.4651486994197,113.46650612274345,113.46785315235704,113.46920735228139,113.47056437179256,113.4719081901425,113.47326235628309,113.47462105348811,113.4759783907087,113.47732361841467,113.47869145733827,113.48004456250456,113.48140783435842,113.48278386166638,113.48412582676795,113.48550596539147,113.48686953434841,113.48824132973894,113.48961198364104,113.49099690695785,113.49236853651485,113.4937312605288,113.49510379722328,113.49649348838398,113.4978664273724,113.49922698124301,113.50061120444673,113.50199831263137,113.50337607572683,113.50476426475741,113.50615473983532,113.50753418045585,113.50894811204611,113.5103125768153,113.51170284834352,113.51311617534759,113.51448866783016,113.51588490831071,113.51727316393797,113.51866280575766,113.52007419609183,113.52148430565987,113.52288685539591,113.5242805349704,113.5256666974265,113.52709379849027,113.52848636292143,113.52988914098933,113.53129471734721,113.53273621901583,113.5341528520117,113.5355449317085,113.53695258587956,113.53837757175654,113.53978529809771,113.54121674088015,113.54264682843089,113.54406000696049,113.54547262697497,113.54689464168572,113.54831782421175,113.5497591104747,113.5511646923613,113.55261684614035,113.55402285267103,113.55545473567247,113.55688460747135,113.55831148805308,113.55975476439502,113.56118238489145,113.56264056086903,113.5640571147026,113.56549915631567,113.56694366002816,113.56838945995901,113.56983651313695,113.57127462467709,113.572731334884,113.57415851676642,113.57562453707376,113.57706587893213,113.57850830266663,113.57996974326988,113.58141915864516,113.58287274786535,113.58432553579003,113.5858047443329,113.5872480625903,113.58870726819862,113.5901836944416,113.59164225557231,113.5930900773543,113.5945584462085,113.59604025712193,113.59749676917826],[113.80872579948543,113.81003288040779,113.81136591696364,113.81268785089719,113.81401529855577,113.81532986503007,113.81664953854451,113.81799810718078,113.81931970806684,113.82063884842651,113.82195097535632,113.82331439476192,113.8246488427061,113.82596777714798,113.82729846181344,113.82864783115164,113.82999098997576,113.83131496950875,113.83265075076979,113.83400607838,113.83533441632979,113.83668564581657,113.83803844242414,113.83938550719913,113.8407214772827,113.84208482228519,113.84342305244611,113.84478748291538,113.84614122532905,113.84747880690108,113.84883581082461,113.8502003513915,113.85155185662909,113.85292418653528,113.854292233203,113.85563111298666,113.8570176289422,113.85837016810633,113.85973127194544,113.86110009911515,113.86248142011266,113.86384599940777,113.86521179159692,113.8665924383059,113.86796797688802,113.8693504219414,113.87072074447897,113.87209199766808,113.87348003386376,113.87486933859438,113.87623889392334,113.87763139635415,113.87898745539992,113.88040023772105,113.8817791568633,113.88316251721524,113.88457007825147,113.88595856843453,113.88732935580069,113.88873514228302,113.89011305349504,113.8915128219709,113.89292449624995,113.8943051386922,113.89571519746399,113.8971061400589,113.89847835758076,113.89991280720028,113.90129780837307,113.90270661258221,113.90411935484344,113.90553603833419,113.90691688933899,113.90835124891036,113.90975357254388,113.91116755149994,113.91259067657798,113.91400161421356,113.91541531015889,113.91682620088045,113.91826669032427,113.91966250853326,113.92109173529488,113.92251687203816,113.92394307109467,113.9253555859635,113.92680975326682,113.9282277352781,113.92965800536936,113.93109561291094,113.93252388026474,113.9339410012066,113.93538054692957,113.93681973903931,113.938248527264,113.93967327005166,113.94112524849675,113.9425876983355,113.94404048361928,113.94544510448722],[114.15580217331046,114.15711886373285,114.15840442856397,114.15970754099101,114.16101498205876,114.16230509224003,114.16360658902461,114.16491972864863,114.16622261680259,114.16753136588093,114.16883776955338,114.17015024108896,114.17147098121958,114.17277892872005,114.17409665200007,114.1753993761115,114.17674029143696,114.17804437724087,114.17934745329255,114.18066485576063,114.18200364021281,114.18332940022988,114.1846515670206,114.18597656491276,114.18730932604373,114.18863121240956,114.18994349562482,114.19130655758218,114.19261883559534,114.19396110832903,114.19529227308865,114.19661366387363,114.19793752382732,114.19929230722414,114.2006202448051,114.20197037559078,114.20329149265824,114.20466379294672,114.20599423276073,114.20735892156586,114.2086883459503,114.210053882065,114.21139041566373,114.2127280226196,114.21408428943184,114.21544201027118,114.21680760297122,114.21815274936162,114.21948413376428,114.22086491353159,114.22222444453641,114.22356794676958,114.22494018332718,114.22630941832226,114.22766601210087,114.22904299746502,114.23040809585598,114.23175379521388,114.23310301178432,114.23451149522175,114.2358704537822,114.23723919642767,114.23861740198554,114.23999104605586,114.24135728358165,114.24276059847546,114.24412148284395,114.24550473910344,114.24688322084596,114.24826541256309,114.24964860101196,114.2510268879167,114.2524246876396,114.25381208437939,114.25518374488036,114.25657137195608,114.25797622145005,114.25933641021511,114.26074609256656,114.26215260349493,114.26352827590627,114.26493031463706,114.26632691943041,114.26773498848304,114.26911823618279,114.2705246090552,114.27192680722598,114.27332497622749,114.27474836407774,114.27615261011006,114.2775490560754,114.278955458072,114.28036704081305,114.28178736469636,114.28318738605489,114.28461508799796,114.28600795294896,114.28744047417808,114.28885368563176,114.29028558289838],[114.49971628598325,114.50099134817094,114.50227778678182,114.50353275204546,114.50484044581613,114.50611849040288,114.50738148592384,114.50867499861798,114.50996664843342,114.51126200935198,114.51255081003994,114.51384022222915,114.51512149644122,114.51641062592073,114.51771229863944,114.51901152873211,114.52029404182115,114.52158561223696,114.52288990692254,114.5241809196837,114.5254748059842,114.52678987209131,114.52809437895912,114.52939636196683,114.53069916167836,114.5320025324296,114.53331062368758,114.53461289208613,114.53592900115174,114.53724842251343,114.53857813655402,114.53987971420524,114.5411755254635,114.54249285735769,114.54381849090069,114.54514418728316,114.54645777308102,114.54776476443087,114.54907798841593,114.55042835796276,114.55175078894858,114.55306769392749,114.55438907937915,114.5557116690961,114.55704342906861,114.55837300173054,114.55970738373624,114.5610468610839,114.56237946973015,114.56370016249475,114.56503783069316,114.56638424490211,114.5677236606991,114.56908202764677,114.57041305869377,114.57174887596378,114.57309640908568,114.57443835665433,114.5757750220798,114.5771281869198,114.57847135069335,114.57982497163172,114.58118694599902,114.58252579693018,114.58388170636583,114.58524100748427,114.58660091778215,114.58794282287879,114.58928876070206,114.59065834898522,114.59200713309494,114.59338959965949,114.59474157913152,114.59611119926501,114.59745445610773,114.59884383687134,114.60019336857536,114.60156639619325,114.6029325139214,114.60430870705939,114.60567582833035,114.60705196059075,114.60843754875232,114.60981951853496,114.61119571889985,114.61254587228848,114.61394395677969,114.61531908520377,114.6166878785605,114.61808464640274,114.61944855066312,114.62084403738334,114.62222232881356,114.62362335963334,114.62502121655503,114.62641970597099,114.62778789648101,114.62918402792248,114.63059039360137,114.63198194158295],[114.84045780493625,114.84172294521382,114.8429840081269,114.8442428760878,114.84550488989923,114.84676554397132,114.84803616050522,114.84930363774092,114.85055899104445,114.85183654859482,114.85307323131656,114.85436386193017,114.85562142737615,114.85688977119352,114.8581624782511,114.85944245294995,114.86072088707374,114.86199538278416,114.86326163679402,114.86455270757725,114.86581858277967,114.86710057937121,114.86840440567148,114.86967643247044,114.87094442587893,114.87224676884216,114.87352631854915,114.87480367980677,114.87610930664911,114.87739599956524,114.8786877451605,114.87996856621507,114.88126083512785,114.88255595808548,114.883856500259,114.88513201167811,114.88644728909567,114.88776147672891,114.88904254283705,114.89033963882605,114.8916497341291,114.89296162772548,114.89426344568949,114.89556836547982,114.89689346422101,114.89818889414464,114.89947811912904,114.90080116599961,114.90210686079706,114.90343111401498,114.90473261214875,114.906065115394,114.90738842678726,114.90871255213492,114.91002468871594,114.91134478325257,114.91265392425798,114.91399317933833,114.91529687455231,114.91663519595616,114.91792516068317,114.91928496998476,114.92061082001851,114.92192677057656,114.9232738066102,114.92460390265558,114.9259503943659,114.92726390248758,114.92861393030941,114.9299460526734,114.93127364771685,114.93262966503248,114.93396693170898,114.9353035122028,114.9366441260418,114.93800136729723,114.93932466079397,114.94067328497215,114.9420208501969,114.94336027245795,114.94471413609736,114.94606149244503,114.94741788583781,114.94878562827996,114.95014790680375,114.95150117061482,114.95284165180144,114.95420736470393,114.95556503363545,114.95691895602695,114.95828790317928,114.95964919170453,114.96102121397546,114.96238821707364,114.96373201808788,114.96510238914266,114.96647913975042,114.96785163351164,114.96920997899561,114.97058289880924],[115.17809370427021,115.17933848037974,115.18057251341072,115.18181094348904,115.18301604942144,115.18427161587383,115.18553095814916,115.18676479342166,115.18803244071492,115.1892785096808,115.19049727319437,115.191752121858,115.19301852419305,115.19426578100654,115.19550266631362,115.19675827316522,115.1980207160371,115.19927100863053,115.20051019288368,115.20179109933686,115.20304015531163,115.20429002277838,115.20556698033684,115.20683953236338,115.20809396364136,115.20936162514552,115.21061034031636,115.21187502804928,115.21316158565052,115.21442026974655,115.21568611984712,115.21697373790212,115.2182313032769,115.2195205059935,115.22076917435236,115.22208552627744,115.22332942488556,115.22462523197605,115.22590490415345,115.22720731531759,115.22846615331794,115.2297468163708,115.2310359248057,115.23232110480085,115.23360072522652,115.23488742254037,115.23618414589441,115.23748148037312,115.2387578726597,115.24005088559063,115.24135164609743,115.242624343035,115.24394514893575,115.24522437781384,115.2465333690058,115.24783171292395,115.24913360626059,115.25043954597065,115.25174011640362,115.25304777013586,115.25433747178155,115.2556317917929,115.25695506244104,115.25824182498702,115.25958019064399,115.26088921981525,115.26219727571295,115.26351675695321,115.26480694911565,115.26615752559512,115.2674634187373,115.2687673638736,115.27007720456326,115.27142575124626,115.27273588178441,115.27405699784973,115.27536521559284,115.27670612295026,115.27801638605479,115.27935213094045,115.28069338336078,115.2819966969702,115.28332627017524,115.28466693814543,115.28598182457947,115.28732365447681,115.28866458744554,115.29000034882753,115.29133205177307,115.2926729324574,115.29400292487347,115.2953647147486,115.29669407124022,115.29803933553926,115.29938851540078,115.3007280743761,115.30207917726493,115.30342738747181,115.3047777478619,115.30612042757926],[115.5125913268635,115.51380236037957,115.51502773685559,115.51625871178233,115.51746524907783,115.51869502082795,115.51992741410717,115.52112998518275,115.52235940399962,115.52358144607419,115.52482695766271,115.52604019738752,115.5272781026263,115.52850283824235,115.5297292301644,115.5309803656389,115.5322104579466,115.533464729829,115.53469043497194,115.53591040312187,115.5371717904048,115.53839946285181,115.53964077298826,115.5408824590123,115.54211537413285,115.54338069497958,115.54460912695303,115.54588279190723,115.547127702992,115.54836457918718,115.54960298587062,115.55086837308264,115.5521070979069,115.55335830844015,115.55462941124651,115.55587972755772,115.55713599707948,115.55837820479772,115.55965820799995,115.56091722732303,115.56217133633666,115.56343252297901,115.56470950576951,115.56598095121538,115.56722868849246,115.56850992176142,115.56977663199716,115.57104345363496,115.5723249449675,115.5735921907332,115.57486555203647,115.57612375741853,115.57739905900897,115.5786885814828,115.57996415195778,115.58124855685723,115.5825119109127,115.58381388804648,115.58507371690703,115.58637800697743,115.58767632490635,115.58893627594364,115.59021438015975,115.5915035737482,115.5927782213056,115.59409668007989,115.59536524266898,115.59667170578436,115.5979633468093,115.59924049485019,115.60056539653253,115.60184277996095,115.60314658020677,115.60444974682005,115.60574859805104,115.60704132400181,115.60834857476482,115.60964378137912,115.61095524220124,115.61226731602964,115.61358276969926,115.61487663159585,115.61616790512285,115.61749272188308,115.61882494142226,115.62012454317667,115.62143650266671,115.62274162598439,115.62406414122472,115.62537373631497,115.6266848192648,115.62802605312956,115.62934016342513,115.63068617800063,115.63200128243219,115.63329841369728,115.63463309545764,115.63595747080765,115.63728544869889,115.63862466743156],[115.84398807029103,115.84521705375445,115.8464199118002,115.84762295213515,115.84883095037958,115.85001844861961,115.85121748361732,115.85243748695314,115.85365640213395,115.85485032359813,115.85605275525128,115.85724388360993,115.85849041990267,115.85968017174605,115.86091964191675,115.86213348605524,115.86333726655691,115.86454726013741,115.86577172940686,115.86697828590832,115.86821831791426,115.86942799220076,115.87065696228858,115.87187298427634,115.87307524919979,115.87432492585113,115.87555568758111,115.87678466619755,115.87800538916233,115.87923528603044,115.88047823223728,115.88170190759767,115.88292748979309,115.88417397379251,115.88542162778845,115.88664306416388,115.88786468988874,115.88910537184645,115.89035755259547,115.8916047290036,115.89285589847047,115.89409785253208,115.89534967098068,115.89658790073034,115.89782294563229,115.89907227953827,115.90032089971979,115.9015548680746,115.90282938527896,115.90408371293856,115.90531697510714,115.9065926615763,115.90784307972726,115.90908471193958,115.91033911857468,115.9116098191304,115.91287302373482,115.91412553784184,115.91537189890126,115.91665502300764,115.91790270432045,115.91919626195616,115.92045332371319,115.92171875189547,115.9229660339942,115.92424586621716,115.92552957114492,115.92679299850636,115.92808960574834,115.92933637369349,115.93063602546754,115.93189927736069,115.93316684696329,115.93446331261919,115.93572617519203,115.93702900736449,115.9383077578455,115.93957702558467,115.94087154008102,115.94214970420676,115.94344359812678,115.94471652950946,115.9460065906022,115.94729976951389,115.94858352512668,115.94988858572137,115.95117255264158,115.9524533355474,115.95376357167466,115.9550607594355,115.95634452931203,115.95766038507,115.95895028996624,115.96024389697854,115.96156721986105,115.9628565605371,115.96415798568694,115.96548111040242,115.96678059238016,115.96806528385926],[116.17237460325478,116.17356484462611,116.1747417299762,116.17592430721668,116.17710729787746,116.1783160332036,116.17946814113725,116.18068154246846,116.18185814378884,116.18304897958558,116.18424732266308,116.18544357140165,116.18660379805131,116.1878386139042,116.18900788457464,116.1902085621504,116.19140281987845,116.19260729123364,116.19378811120916,116.19500288350483,116.19621047868914,116.19738787760068,116.19861909129072,116.19981902708362,116.20104038239467,116.20222805924769,116.20345077803184,116.20464857357031,116.20587273593173,116.20707078289088,116.2082905679122,116.20949647120783,116.2107131079288,116.21193025173166,116.21314371953704,116.21437087366853,116.21558606276042,116.2168042987031,116.21802388246631,116.219240408599,116.22047292254896,116.22169534805826,116.22289047207978,116.2241302566077,116.22535888711047,116.22659740613842,116.2278296477235,116.22905629368191,116.23028171116498,116.23151948776058,116.23274267995319,116.23398909528183,116.23521989500045,116.2364783346444,116.23770594563787,116.23892581138053,116.24019072357582,116.24143879912268,116.2426782241279,116.24392520737388,116.24515917693256,116.24641300815662,116.24765363486897,116.24890810485888,116.25016085562291,116.25139541242031,116.25264697892382,116.2539064537146,116.25514985084219,116.25640393697071,116.25768547088853,116.25893534940653,116.26016607451918,116.26142394690001,116.26270267347002,116.2639610258447,116.26521510898229,116.26649208514445,116.26774132659261,116.26900415326024,116.27028398543447,116.27153998647432,116.27283260769391,116.27409305382284,116.27536218316068,116.27661789568211,116.27790834492112,116.27917225099614,116.28044506112933,116.28173311522212,116.28299191354981,116.28428042154162,116.28556706325324,116.28683376098009,116.28812246035804,116.289408966386,116.29069544453755,116.29197544261652,116.29326239656943,116.29454085559424],[116.49770180205505,116.4988726162363,116.50005260503053,116.50119806056753,116.50237303244558,116.50353093010747,116.5047102102997,116.50585262498662,116.50703616064568,116.50819082120233,116.50937734568409,116.51054186077158,116.51173771294239,116.51292138279636,116.51410020257406,116.51525797410545,116.51644475428729,116.51761526021983,116.51882221058531,116.52001009680501,116.521163365018,116.52235335985691,116.52353979356633,116.52473357878769,116.52595338201475,116.52712590798498,116.52829994935124,116.52948956590849,116.53068947357826,116.53185342669647,116.53307161715858,116.53427922602354,116.53546370452179,116.53667255354682,116.53785884201322,116.53908551223961,116.54024845045016,116.5414588847664,116.54267627461233,116.54386542861259,116.54509462832534,116.5463056763494,116.54749758121804,116.54871459539238,116.5498810451905,116.55109138053449,116.55232610266958,116.55352569623183,116.55475897978735,116.55597368076107,116.55717823116393,116.5584029739158,116.55963470165557,116.56082676343576,116.5620657125143,116.56328638490245,116.56447738623167,116.56572606290688,116.56695960507122,116.56816410123592,116.5693959241402,116.57063120151815,116.5718610375533,116.57308665214316,116.57431283793778,116.57552097393356,116.5767825005363,116.57798752448507,116.57922903926203,116.58048133195807,116.58170027367721,116.58295547289097,116.58419092895845,116.58542057678929,116.58665083459702,116.58792277353606,116.58916309294887,116.59042015673319,116.59162707037402,116.59289136891402,116.59415869813037,116.59539338079158,116.59663062956494,116.59787912926194,116.59915995361348,116.60039274308083,116.60164355693428,116.60289803954463,116.60416398587783,116.60541303808529,116.60666423875014,116.60794473124261,116.60920244614002,116.61045094724277,116.61169539254793,116.6129685929945,116.61423849916187,116.61551687415947,116.61675809151127,116.61803858803486],[116.82005285046569,116.82121380594421,116.82232247304023,116.82346742052104,116.82458917288068,116.82575874532708,116.82688430450305,116.82805865584866,116.82925519508562,116.83033539826798,116.83157037188809,116.8326642791942,116.83386605314524,116.83497703293877,116.83613384512833,116.83733249680043,116.8384935637152,116.83962929218879,116.84080941350514,116.84200766402785,116.84312456235364,116.84434411664901,116.84548991581849,116.84662471085858,116.84784489269745,116.8490312339131,116.85018038994477,116.85136587431944,116.85255025542233,116.85369425006984,116.85487332030974,116.85602744005891,116.85725381765378,116.85842273933147,116.85958614967387,116.86077951777743,116.86195707237762,116.86316152616625,116.86430446229208,116.86553514347013,116.86668454525086,116.86786148045194,116.86902273778078,116.87025486804494,116.87146256473814,116.87264180515277,116.87386271694115,116.87505581330288,116.87623328702568,116.87743862712371,116.87858863933957,116.87985475306373,116.88101574515308,116.88223131562638,116.88341851297926,116.88459777019084,116.88584459028027,116.88703017175499,116.88820777642486,116.88945423860366,116.89066965116709,116.89188789125747,116.8930736206476,116.89430238309642,116.89553682704275,116.89672967150527,116.8979073838118,116.89917117707469,116.9003741451356,116.90158726367959,116.90276269769387,116.90401036938196,116.90524660200613,116.90646967893136,116.90767581868674,116.90892519737565,116.91009527004323,116.91133951127183,116.91263686989691,116.9138194445826,116.91499709837785,116.91624042201249,116.9174740590192,116.91868029422281,116.9199850816683,116.92118747738641,116.92244015554277,116.92369158525764,116.92491403272213,116.92615642971764,116.92736223962342,116.92864340203236,116.92988567116372,116.93106422860967,116.93232121329386,116.93362675490917,116.93484614923769,116.93603908564887,116.93733562841048,116.9386150504732],[117.13932209551004,117.14043719505666,117.14170596691258,117.14274490677785,117.14394320055192,117.14510823791834,117.14623439981224,117.14733195831784,117.14839138805564,117.14961662205614,117.15080539662924,117.1519539566073,117.15307417385415,117.15415286008098,117.1551910345781,117.15641615876977,117.15759141239494,117.15874090809614,117.15987201780051,117.16094950498193,117.16220151323091,117.16323426357766,117.16441833671597,117.16556697811131,117.16668897586314,117.16798500819039,117.1690604807284,117.17029999805382,117.17148723251007,117.17247577390079,117.17381133525643,117.17492607339959,117.17602048927938,117.17727235169373,117.17830787403193,117.17952624074663,117.18067119864364,117.18181384304212,117.18293821418374,117.18423250670499,117.18531414703571,117.18653117784768,117.18774864287998,117.18894409633319,117.19008667657008,117.19122419688058,117.1923324113952,117.19362348595155,117.19467184288483,117.19589756664672,117.19711495332515,117.19830247372431,117.19946694412961,117.20058768199571,117.20192375126064,117.20302225906653,117.20428354741068,117.20532832937315,117.20655206909882,117.20776609612365,117.20893632002701,117.21010719383716,117.21144285990435,117.21254760321335,117.2138640568237,117.21492772921381,117.21618228145073,117.21741780329485,117.21864224141373,117.2198132872898,117.22101377818005,117.22216055186331,117.22329412939628,117.22463339425637,117.22573644948754,117.22702286571764,117.22808860866897,117.2293344013364,117.23055272283473,117.23178039641599,117.23299659103695,117.23417311913533,117.23555849951512,117.23668221242765,117.23781215571549,117.23914908472571,117.24025187000295,117.24154309841035,117.24282357505683,117.24386841529535,117.24511214015658,117.24635973509957,117.24757023238348,117.24878466040136,117.24997618229767,117.25137454340424,117.25253055539966,117.25367447186451,117.25503164648413,117.25615541480526],[117.45584608916042,117.45701068584137,117.45792374951104,117.45917726939975,117.46019682752964,117.46156970908555,117.46272260850444,117.46361261355244,117.46487316949727,117.46588881450491,117.4666848741803,117.46782138798058,117.46930837633053,117.47058716032738,117.47161157668695,117.4723909347772,117.47355560198352,117.47504240527412,117.4757359183285,117.47737118732209,117.47815445781502,117.47932607761527,117.48025229761853,117.4815377145211,117.48259797328205,117.48401440654877,117.48519107901984,117.48614635700099,117.48746460043915,117.48853335428547,117.48937370301901,117.49061130461709,117.4921859023788,117.49293232177601,117.49405583579983,117.49553203414776,117.49678489196135,117.49779772895454,117.49857986766622,117.49972234522272,117.5012446589803,117.50252469136744,117.50360351853051,117.5044215856207,117.505607021326,117.5071993610682,117.50789989455231,117.50902199536532,117.51051056133456,117.51175951427572,117.51278557599255,117.51419077225187,117.51533780105169,117.516273536676,117.51757225431137,117.51868953242618,117.51948643774206,117.52073265996515,117.52234511591519,117.52311089698541,117.52426613815285,117.52579990207876,117.5264783611851,117.52815927646964,117.52900450812201,117.53022360485872,117.53119609120206,117.53259298656299,117.53373546030323,117.53526668219499,117.53595751586106,117.53765644743683,117.53851268279793,117.53974910507343,117.54074741708094,117.54214691308357,117.54330808424201,117.54423684717638,117.54556032056601,117.5466534211009,117.548165348871,117.54942656845007,117.55045003934056,117.55189333938088,117.55309885662976,117.55407199047958,117.55543617186372,117.55656722892611,117.55749544813314,117.55878138084763,117.55986166749827,117.56134200233969,117.56259137612184,117.56361475290801,117.56505340298796,117.56624610455079,117.5672164665023,117.56860299139706,117.56973562274507,117.57063018081098],[117.76934134141273,117.77099246820788,117.77066672017233,117.7718334617967,117.77275081072678,117.77519301857089,117.77562566633671,117.77761228028972,117.77757951183295,117.7790491567662,117.78031689771448,117.7812994811236,117.7821028893878,117.7843943987468,117.7846934126757,117.78649509358134,117.78631059764078,117.7876576109069,117.78878387314998,117.78964107023418,117.7920327393739,117.79242781069631,117.7943662872436,117.7942831454748,117.79574736459715,117.79698762719106,117.79794200238612,117.79868448315713,117.80099753337899,117.80128418808302,117.80308909447444,117.8028873240653,117.80422899712146,117.80534764233899,117.80800468228699,117.80863529448507,117.80903255080656,117.8110124657602,117.81091055861714,117.81242256235006,117.81365720883687,117.81469084461075,117.8154834677579,117.81783615207367,117.81813063036586,117.82000539479506,117.82166444057171,117.8212309272106,117.82242196539872,117.82336578889411,117.82590820889865,117.82636527461948,117.82841736487975,117.82840851760837,117.82999144291178,117.83136321176578,117.83246164088402,117.83333349915566,117.83396291364174,117.83622714845417,117.83639432939223,117.8381710328238,117.83971138288693,117.84100765286004,117.84206874052047,117.84290010264684,117.84351461542663,117.84574558954633,117.84583361864716,117.84758094593398,117.84909995217103,117.85037805815246,117.8514141106886,117.85224056771821,117.85280104547287,117.85501277935498,117.8550931504897,117.85684438236198,117.85832716445461,117.8596053706264,117.86063994470517,117.86143025201973,117.861967739136,117.86418054915748,117.86423472493126,117.86601714175552,117.86751023919639,117.86879189304473,117.8698223355365,117.87060311840176,117.87116482419833,117.87342419321405,117.87540837107107,117.87526857999057,117.87677157070627,117.87808513736582,117.87913743448004,117.87993984493406,117.8824681744934,117.88282147559191],[118.08045008970205,118.07925335249789,118.08290286065005,118.08122575768462,118.08441801783594,118.08734759149795,118.08495756364792,118.0874462469264,118.0896869906621,118.09168143449624,118.08832102232573,118.08985611167523,118.09115453700414,118.09220300396369,118.09302130287558,118.0936172695028,118.09914446364071,118.09924941401032,118.09911699402251,118.09874676420259,118.1033570873085,118.10250140178698,118.10141289473776,118.10531663444867,118.10374520963353,118.10717235389465,118.11036616748656,118.10809025288113,118.11080313799535,118.11330245331331,118.11029573159897,118.11230573266093,118.11408492676317,118.11564433373799,118.11694945794518,118.11801480757174,118.11884904037247,118.11944294340776,118.1197975729468,118.12524470685496,118.12511205238414,118.12475818000362,118.12415876735747,118.12867798410771,118.12759121842991,118.13164244720545,118.13009993750775,118.13367658512152,118.13163180755585,118.13471858718022,118.13758893150955,118.13483275868255,118.13724839483102,118.13941256631028,118.14132203385307,118.14301106069186,118.14448194625223,118.14570817413323,118.14666699282762,118.14742311080529,118.14792884845494,118.14818591919166,118.14821771515403,118.14800196287888,118.1530287104159,118.15235167180222,118.15141509517437,118.15574507827367,118.15432970697582,118.15819908622726,118.15630201327204,118.159700184129,118.16284504877834,118.1602432475244,118.16292055208324,118.16538318670123,118.16758863404262,118.16400332664269,118.1657448610753,118.16725577481512,118.16850596006427,118.169540351616,118.17032998698865,118.17088632416774,118.17681028618529,118.17689500508952,118.1767306030606,118.17632608091166,118.1813080628694,118.18043950533779,118.17930910729584,118.18362873626681,118.18202618448886,118.1858367469262,118.1837680878928,118.18711635726686,118.19023295747562,118.18741361324494,118.1900677661624,118.19248027010504],[118.38899376673609,118.38678953612293,118.38436385368539,118.39667635977324,118.39376978345419,118.39062036241373,118.38722549320183,118.39864675532351,118.39473944062766,118.39062502815969,118.40137255465406,118.39675821682007,118.40704488350386,118.40195702848644,118.39661043359138,118.40621428690747,118.40039880589491,118.40956895913526,118.40322877330932,118.41193901538603,118.40511876837836,118.41335689537372,118.4060683856756,118.41385690778043,118.40604847185887,118.4133833974186,118.42050541861533,118.41195021137032,118.41859388408989,118.4250041410116,118.41573180490835,118.42167276608572,118.4273958290026,118.41734953381592,118.42260416325124,118.42762284838086,118.43241342948436,118.42137809097035,118.42570223431127,118.42979948319348,118.43364487319403,118.43730086218932,118.44067817820368,118.42813635316966,118.43104485201084,118.43371754382886,118.43617485322793,118.43839251494758,118.44036656521205,118.4421169095551,118.44361794855251,118.4448898758748,118.44592197604425,118.44672096810817,118.44727255206513,118.44760724828375,118.44769778869973,118.44751486980661,118.44714025463176,118.44648733636245,118.4456120851831,118.46052783450766,118.45918613318129,118.45761115699163,118.45575417490004,118.45369025089511,118.46752385435107,118.46497874549205,118.46216828819038,118.45913150628571,118.47205812825715,118.4685584521845,118.46477856623952,118.46078046852647,118.47281450627106,118.46831798725421,118.46357105768604,118.47492234282754,118.46971268866949,118.48062411136587,118.47490381685853,118.48536221421651,118.4791578374681,118.47270990358561,118.48248348690917,118.475533025047,118.48484900080965,118.47743149332891,118.48627818377611,118.47835409518427,118.48673655717644,118.49493876022845,118.48626761297578,118.49399286642665,118.48482292772132,118.49208277501904,118.49910261174384,118.48918246826085,118.49574309961068,118.50210307952912],[118.67252867418385,118.70371304186979,118.69060531442935,118.67723434424775,118.70779987148569,118.69391002756515,118.679778631377,118.70972924603845,118.69509645602173,118.68020984009524,118.70954020387134,118.69414353920733,118.72308049091889,118.70717998223589,118.69100732204899,118.71933091625651,118.70264235632301,118.73058338621816,118.71339138913731,118.69593012468924,118.72321131708729,118.7052400172118,118.7321177987424,118.71362573635292,118.74011460989591,118.72111714096425,118.70182978990564,118.7276784376528,118.70788688913731,118.73329282486614,118.7129746161502,118.73799244755837,118.71715976763421,118.74173905258485,118.7203589818261,118.74454564067427,118.72266380176077,118.74641277625881,118.72399054782139,118.74729929785272,118.72435529875168,118.74726216441582,118.72379630533123,118.74625603639583,118.7222433478559,118.74429042779536,118.71973073207513,118.74135386832009,118.76276944852403,118.73741956579204,118.75841228639074,118.73252922976614,118.75308387308954,118.72665253571161,118.74675555678428,118.76667479943028,118.73946867890905,118.75893901391846,118.77821949537181,118.75018965597476,118.76902490676346,118.74045314675193,118.75883013068972,118.77700717382076,118.74762815378048,118.76536562647645,118.78291183317715,118.75271480531224,118.76979343708413,118.78669152449523,118.75565261376296,118.77205860650524,118.78830116558174,118.75644665796467,118.77220572242554,118.78777495648069,118.75509020194275,118.77018789396024,118.78507222887632,118.79978004896095,118.7659924094904,118.7802077970586,118.7942216321436,118.7595892316745,118.77314270332656,118.7864702499536,118.79960825678575,118.76385282606125,118.77650279751315,118.78894976968377,118.80117270727237,118.81316982991564,118.77604231306994,118.78757287256494,118.79888551082463,118.80997826693724,118.82089983096725,118.78233754562218,118.79274198936625,118.80293006573338],[118.9886068227876,118.93676561582046,119.01433202850599,118.96190298814363,119.03920763793147,118.98620538193325,119.0632250156646,119.00965929028098,118.95571373725136,119.03223914732719,118.97773498428906,119.05400089571677,118.99888992659308,118.9434378995534,119.01920968782352,118.96316249384009,119.0386375906287,118.98198226696472,119.05720037653711,118.99997447395431,119.07490982721431,119.01708259257478,118.95888809503575,119.03329235317347,118.97452584464641,119.0486319046565,118.98924742113593,119.06307652037722,119.0030845063961,119.07663539503622,119.01602509876406,119.08929410870594,119.0281014009422,118.96652080213562,119.03923023427201,118.97704719659157,119.04947765798947,118.98667020464973,119.0587896012498,118.99539220298743,119.06719862774189,119.00317611950614,119.07467018361585,119.01003137621842,119.08124305481174,119.01596342570124,119.08686737190105,119.02096887883712,119.09156244281118,119.02505825270968,119.09531901648522,119.02816792803021,119.09813286777955,119.03034822963271,119.09999771543771,119.03158764707125,119.10091084812379,119.03184682099217,119.10085410783844,119.0311889847211,119.09985761403979,119.02952158032602,119.09788123240824,119.02690220657288,119.09496300556206,119.02331553322259,119.09102228397326,119.0187635104708,119.08613661712218,119.0132184901062,119.08025521504612,119.00669007435661,119.07339659313831,119.14003664420747,119.06553460379776,119.13183808771998,119.0566800322903,119.12264233000198,119.04684504948004,119.11246632022983,119.03599787801122,119.10124375875175,119.02411257998142,119.08902987832137,119.15388127325738,119.07579714228582,119.14030007218051,119.06156077564518,119.1257013213071,119.04625655854838,119.11007258811487,119.02995996912878,119.09339892651602,119.15679503835634,119.0757196142097,119.13871976484033,119.05697430763675,119.11962662092867,119.0371868921383,119.09947458607095],[119.15061574981246,119.3578442702815,119.18347328492825,119.39075025261847,119.21549637590292,119.4228532078481,119.24673406672716,119.45415910801007,119.27715170861195,119.48464165081172,119.30674212918265,119.12839521357171,119.33554928944159,119.15630061499914,119.36352534858706,119.18338255377849,119.39063847666553,119.20962453013453,119.41694316371964,119.23504215134669,119.44242123766188,119.25960588360651,119.46703870490414,119.28333864252144,119.49082939274106,119.30624244216474,119.5137681620093,119.32826234135962,119.14229582717027,119.34943572824457,119.16255292618446,119.36974569245709,119.18196854570331,119.38921385703338,119.20049877840613,119.40776863416139,119.21816772244736,119.425487991366,119.23497352529671,119.4423123541059,119.25088410739002,119.45825678376184,119.26589428189364,119.47331439880858,119.28004963965809,119.48750631616163,119.2932961905033,119.50076653538758,119.30564010114537,119.51314141968665,119.31710968356592,119.52461297808804,119.32764149173822,119.53517034302884,119.3372635644985,119.54483115660778,119.34597391320483,119.55356264943525,119.35377752172403,119.15350191709618,119.36063785524391,119.15943957429015,119.36658792893449,119.16444597351355,119.37159318368883,119.16850898941455,119.3756737112355,119.17163136876063,119.3787926987424,119.17383106246498,119.38098649757822,119.17503743309017,119.38219590081208,119.17533869182118,119.38247157943745,119.17466095902026,119.38179238807274,119.17302282146986,119.38016700717606,119.17041034325041,119.37753817442861,119.58514658024538,119.37396088989954,119.58154607754982,119.3694009244773,119.57696467572411,119.36384097226696,119.5714187414787,119.35732504988266,119.56486643429135,119.34978671311698,119.55731811815266,119.34129387676796,119.54878936632849,119.33177609338706,119.53925116095567,119.3212485468019,119.52870248149338,119.30973260140433,119.51714731293957],[120.12161747154293,119.20692077252852,119.4135617385172,119.620679093799,119.82828012231175,120.03634585300611,119.11554406661946,119.32196527519561,119.52886129337512,119.73623403065805,119.94408247619506,120.15241868430284,119.22334751524454,119.43001001649523,119.63715195305426,119.84477303277433,120.05286669293919,119.11768508571986,119.32407035070199,119.53097090982018,119.73834197647298,119.94618841261452,120.15450904911522,119.21100440439322,119.41762045864076,119.62468874198149,119.83227571057311,120.0403293774431,119.09069771683308,119.29701993441975,119.503827135703,119.71110824053332,119.91886673334713,120.12712192943005,119.16911604661638,119.37562309889788,119.58260667139295,119.79004411755709,119.99800433635446,120.20641463278996,119.24002519336128,119.4467059090706,119.65382389585481,119.86143521414022,120.06951183936346,119.09699653005896,119.30330996777236,119.51009886340532,119.71736882912505,119.92513102537823,120.13337393286194,119.1523997173144,119.35885089346475,119.56575626660916,119.77314746913635,119.98101562510263,120.18937388951652,119.19996481313335,119.4065234391991,119.61351918142923,119.82102424048585,120.02898049356524,120.23744275817731,119.23957134705458,119.44618345520522,119.65328409909235,119.86086713518095,120.06890695575865,119.06490022676505,119.27107225576444,119.47775865716828,119.68492166843525,119.89255430804621,120.10067890506778,119.08814620359983,119.29438451030941,119.50111398083138,119.70831544426464,119.91599110826499,120.12416131589816,119.10311025390692,119.30937808951812,119.51612118525807,119.7233546461706,119.93106324193484,120.13924088837209,119.10964550904055,119.31589938676734,119.52267225412295,119.7299104793326,119.93762872865155,120.14581250012839,119.10764239793825,119.31389237077026,119.52063887504755,119.72785049761126,119.935560346435,120.14374513966864,119.09699981434312,119.30322011553044],[119.1653347142081,119.3711753243739,119.57749442301053,119.78429975004539,119.9915751895226,120.19934188999714,120.407588426893,120.61627540480508,120.82547956222615,121.03513429013023,121.24528286791212,121.45586531543688,118.32130643487365,118.52508651181464,118.72937376434606,118.93414482937435,119.13940187726287,119.3451480588873,119.55138298856727,119.7581129089502,119.96529308511496,120.17297939581249,120.38115055109381,120.58976474490494,120.79886941653756,121.0084522893472,121.21849615426194,121.42900012137125,118.2335088887719,118.43705498426566,118.6410832878486,118.84562114569478,119.05063819430207,119.2561565479427,119.46214469529824,119.66863332387607,119.87561325014599,120.08305979678805,120.29097257139344,120.49938231972578,120.70825784497113,120.91758356238896,121.12741434333489,121.33769838025178,121.54844522675876,118.28444110684488,118.4880801957346,118.69221416945334,118.89684760890236,119.10195344768246,119.30757441018939,119.5136633254759,119.72022762546024,119.92728828310446,120.13483701679122,120.34286281554402,120.55135305785775,120.76031207527474,120.96976280640895,121.17964392979687,121.39003378275306,121.6008641297021,118.26817060261367,118.47174078232358,118.67580315656319,118.88036081146831,119.08541310882042,119.29095802087747,119.49696716633916,119.70349999619107,119.91048072369213,120.1179757972388,120.32591448619719,120.53433428258536,120.74324248465363,120.9526214051441,121.16246221168043,121.3727815331496,121.58354582070338,118.18206469543225,118.38539703262333,118.58921865690209,118.79353682853105,118.99835157766526,119.20365538479496,119.4094444256657,119.61572663307174,119.82247222572828,120.02971684971058,120.23744120365237,120.44563715741768,120.65429364369353,120.86345368160168,121.07306434327515,121.28315810966212,121.49371148220686,121.70471078055536,118.22640313147633,118.42979763267442,118.63368423240202],[116.08254182081832,116.27987550023684,116.47772745639406,116.67610245177084,116.87499674079747,117.07439149123316,117.27432268937787,117.4747651160745,117.67571416477224,117.87715211143006,118.07912161390045,118.28157309749301,118.4845368075321,118.68800752234736,118.89196106177629,119.09640889619308,119.30136074291526,119.50675739385433,119.7126825907516,119.91909975987767,120.12597091759964,120.33335135202208,120.54120064065341,120.74951467042736,120.95831767266898,121.16758169710968,121.3773252904823,121.58751941095913,121.79819576700943,122.00932667311272,122.22091333487643,122.43298067483029,122.64549413502831,122.85844503135816,123.07185054267741,123.28571621965247,123.50003166763649,123.71480387562687,123.93000009894304,124.14563982334205,124.36173986893496,124.57823901817316,124.79521386326614,125.01259956655858,125.23042988028962,115.2403539318811,115.43529784564357,115.63079236310163,115.82682009642909,116.02335298482251,116.22043677959485,116.41802568308901,116.61614450675431,116.81480685543563,117.0139621741321,117.21363628486662,117.41383439873422,117.61452126277948,117.81575352132882,118.0174630531241,118.21968371766397,118.42241047628731,118.62563242010977,118.8293615872135,119.03358556001604,119.23828899701638,119.44350270158775,119.64918290992848,119.85535690346612,120.06201564978566,120.26916095659313,120.47677693716082,120.68486533749085,120.89344622303622,121.10248619167564,121.31201926965807,121.5219877252495,121.73244862631562,121.94335887428238,122.1547349271586,122.3665824955389,122.57889623310363,122.79164428463073,123.00484960367935,123.2184916348987,123.43260048730902,123.64716779413558,123.86215661201695,124.07759744042873,124.2934901885745,124.50981278236493,124.72653703545572,124.94375727659644,125.16136896972496,125.37941693115324,125.59791125407605,114.9923977783865,115.18657467912149,115.3812699785143,115.5765029728196],[113.14598680132238,113.33415478853692,113.52288804675848,113.71217473062363,113.9020104588659,114.09240790216293,114.28335513008048,114.47486431976628,114.66692141584572,114.85952115673217,115.05265423310166,115.24635203696968,115.44057369960744,115.6353425321754,115.83064983138115,116.02646332601178,116.22282982518031,116.41974326216663,116.61714481404763,116.81508919711537,117.01355381507514,117.21254280541575,117.41203484372042,117.61203621629879,117.81255604963694,118.01360623872029,118.21511858162125,118.41717272914863,118.61971178164463,118.82275066301868,119.02631473626056,119.23035243116131,119.4348764057518,119.63990699567242,119.84542466256849,120.05140908655594,120.25790966443356,120.46486859677084,120.67231705372042,120.88024489222248,121.08864478441767,121.29751927584485,121.5068779071369,121.7166923351335,121.92698542079192,122.13772314360733,122.3489377247297,122.56061983084109,122.77273462720208,122.98532308099323,123.19835817795808,123.41185867464726,123.62580276525114,123.8401904202785,124.05501096556195,124.27029351633962,124.48603509663533,124.70217024606973,124.91877511506316,125.13581281606591,125.35327501600145,125.57116543182528,125.78949464020559,126.00824951388105,126.22740955819356,126.44700015651247,126.66703523349163,126.88748203381496,127.10831900543478,127.32960603368751,127.55129180773827,127.77338178800937,127.99589757283636,128.2188044990457,128.44211572124496,128.6658340982377,128.8899622892571,129.11447301129311,129.33937692787555,129.56467793774738,129.79039125901278,130.01647955816304,130.2429594158227,130.4698377344136,130.69708856044448,130.92473751161032,131.15274541865207,131.38113059366347,131.6099165278343,131.83906293135368,132.0685824534918,132.29848409362307,132.52875694776736,132.75938204264952,132.99038930076966,133.22173869329356,133.4534642877209,133.68554737510468,133.9180063545587,134.15081046977394],[110.36715403938749,110.54545427837418,110.72435574248087,110.90386052634403,111.0839635782385,111.26467707999163,111.4459778832096,111.62785382504569,111.81035049861278,111.9934116371622,112.17706979612058,112.36132364251925,112.5461340122558,112.73153320858128,112.91750503343947,113.10405579744456,113.29117424165493,113.4788554026297,113.66711622174508,113.85593013228667,114.04529403705526,114.23525167993844,114.42574439197374,114.61680096600637,114.80839027158306,115.00054415330003,115.19324045966387,115.38646816846344,115.58023572340207,115.77457904647493,115.96943167286221,116.16482240007936,116.36075153529355,116.55718804893986,116.7541700395875,116.95169312265821,117.14971230627698,117.34825978999626,117.54731933373405,117.7469044403875,117.94699263476518,118.14761577947272,118.3487318376206,118.55036443406308,118.75250046689652,118.95512533550902,119.15826161560176,119.36188859200861,119.56599519268732,119.77061009258054,119.97572922943425,120.18133901738322,120.38739889486783,120.59398852519492,120.80102350330067,121.00856495547195,121.21653838947107,121.42503493501617,121.63398473947761,121.84342147296177,122.05331588785585,122.26366507291263,122.47450203952253,122.68577667596632,122.89754189231947,123.10974816493403,123.32240202539785,123.5355201962523,123.74909461180019,123.96311171318594,124.17757298220226,124.39248718240307,124.6078356967095,124.82363746951994,125.03987868856254,125.25653934159659,125.47365472746398,125.69120161820126,125.90915544465346,126.12755293178535,126.34637608838491,126.5656182486313,126.78530519534938,127.00538714065524,127.22589770808865,127.44682081443054,127.66816411781244,127.88992314885236,128.11208387851605,128.33465003242287,128.5576417967079,128.7810141223042,129.00479739849834,129.2289722028183,129.45356499502046,129.6785628548999,129.9039437569242,130.12968781643448,130.35585265949624,130.5824098916221],[191.10363556910792,191.3782184218715,191.65285122365083,191.92756627403574,192.20231047042873,192.47711183615726,192.75198782099432,193.02690535334813,193.30187208456294,193.5769238818935,193.85199245350174,194.1271372521909,194.40231601701112,194.6775428865653,194.9528200775071,195.22814868698197,195.50352590453866,195.77895165693062,196.05443734969958,196.32992565573403,196.60549450392242,196.88108039129085,197.1567289692344,197.43238706471766,197.70811366366826,197.98387432372124,198.25966900573803,198.53548185448977,198.81136343304087,199.08727135698544,199.36320049640915,199.63919511129376,199.91518279859127,200.19123389815974,200.4672808010229,200.74339713455646,201.01951795761678,201.2956797286194,201.57186205906285,201.8480672902556,202.12433314121273,202.40059207846645,202.67686927879637,202.95318881351116,203.22952359749144,203.50587209336527,203.78223472024774,204.0586412873791,204.33506001242645,204.61149190747676,204.88795992839476,205.16444322990264,205.44092936630517,205.71743279009837,205.9939565033846,206.27049032695498,206.54703639328145,206.82359708182594,207.10017419749505,207.37676230492534,207.6533688149538,207.92996037514936,208.20656343959723,208.48319781160336,208.75983660048797,209.03644950205154,209.3130949622801,209.5897457851626,209.86639939446087,210.1430445073147,210.41970511745598,210.69636963821827,210.973026676078,211.24969174055144,211.52635565301094,211.80301560194806,212.0796789826316,212.35632312373136,212.63297645214675,212.909621005523,213.18627620323386,213.46291278496392,213.73954085517553,214.0161541938743,214.29279656820154,214.56940512212773,214.84601517626226,215.12261005639144,215.39918513755612,215.6757635266575,215.95231901390216,216.22887778638264,216.5054093600168,216.78193525747685,217.0584592847943,217.33494344066656,217.61142157416356,217.8878930741114,218.1643519231456,218.4407629274969],[569.5938614920881,569.5948196206821,569.595776023062,569.5967205370482,569.5976814480318,569.5986534845231,569.5996084366823,569.60056071954,569.6015390146079,569.6025025869887,569.6034616503387,569.6044396687826,569.6054010512727,569.6063612576254,569.6073258384677,569.6083079622678,569.6092640858711,569.6102512263743,569.6112223901937,569.6121729278618,569.6131750639822,569.6141258589884,569.6151130911711,569.6160912402332,569.6170598940452,569.6180357524015,569.6190236580778,569.6200026600475,569.6209977511945,569.6219612972992,569.622953598709,569.6239022107413,569.6248939570647,569.6258747108726,569.626868790974,569.6278397357275,569.6288237079024,569.6298373705339,569.6307913020904,569.631807981744,569.6327952199136,569.6337766493477,569.6347651487531,569.6357389039114,569.636753919031,569.6377392192842,569.63872432058,569.639718234546,569.6407248355529,569.6417172901749,569.6427156400232,569.6437186607776,569.6447092687774,569.6457156307125,569.6467051946768,569.6477091362185,569.6487159030219,569.6497134447817,569.6507095384499,569.6517179413054,569.6527291023788,569.6537297821319,569.6547286429917,569.6557397300529,569.6567457876024,569.6577546220603,569.6587455729101,569.6597628411998,569.6607833911143,569.6617904350485,569.6627976755307,569.6638251225432,569.6648256888409,569.665837189643,569.6668504155256,569.6678666806977,569.6689112202171,569.6699049507278,569.670933881719,569.6719435006742,569.6729749376143,569.6740080450627,569.6750150617265,569.6760329572057,569.6770816761368,569.6780803591683,569.6791017855674,569.680137415747,569.6811526436651,569.6821974549656,569.6832135524498,569.684250670715,569.6852795015386,569.6862983329753,569.6873242912748,569.6883654512169,569.6893858880422,569.6904163718459,569.6914587849616,569.6924881738121],[569.8717453604831,569.8727033876473,569.8736552242324,569.8745960861422,569.8755565567878,569.8765100353014,569.8774559663007,569.8784161003935,569.8793595389332,569.8803136775688,569.881292877614,569.8822372576127,569.8831790165079,569.8841588982465,569.8851214239796,569.8860752975786,569.8870309818358,569.8880022180931,569.8889684746676,569.8899211472893,569.8908610868277,569.8918364012708,569.8928069537963,569.8937754108767,569.8947323916403,569.8957054059185,569.8966699413662,569.8976436494762,569.8986239082986,569.8995723328479,569.9005641594977,569.9015463469638,569.9025019332868,569.903489669585,569.9044620972138,569.9054466680395,569.9063960324692,569.9073998009794,569.908369008603,569.9093300417269,569.9103222296062,569.9112997874298,569.9122811465152,569.9132521300792,569.9142532861795,569.9152254274002,569.9162132539044,569.9171768719452,569.9181898240539,569.9191731492899,569.9201614534625,569.921151431223,569.922141075742,569.9231418198638,569.9241138912582,569.9251128356948,569.9260891868836,569.9270928458084,569.9280705463101,569.9290630961239,569.9300734481214,569.9310610545922,569.9320591935748,569.9330546760546,569.9340412894765,569.9350427265309,569.9360452590241,569.9370687677286,569.9380418307309,569.9390694019855,569.9400625066625,569.9410649681873,569.9420772599192,569.9430719133222,569.9440898408144,569.9450891540113,569.9460971717219,569.9470912341365,569.9481013769595,569.9491313480926,569.9501212655165,569.951148028873,569.9521536769219,569.9531843903814,569.9541927903534,569.9552098376114,569.956222784879,569.9572292119881,569.9582426160293,569.9592646576968,569.9602863564448,569.9612984104363,569.9623094488452,569.9633369298168,569.9643520654964,569.9653777380885,569.9664023543236,569.9674278720561,569.9684320403815,569.9694628268801],[570.1471063654542,570.148042144591,570.1489889646947,570.1499342637269,570.150882359478,570.1518226615763,570.1527757274408,570.1537089483406,570.1546726712282,570.1556032366163,570.1565531246919,570.1574936565082,570.1584489538516,570.1593929204123,570.1603536460791,570.1613046805239,570.162246474456,570.1631952597937,570.1641663459468,570.1651092364868,570.1660680229663,570.167033102166,570.1679708077556,570.1689345943383,570.1698938300966,570.1708403099642,570.1718325110886,570.1727789363277,570.1737360429717,570.1746998806249,570.1756600500157,570.1766091105777,570.1775881897995,570.1785538928254,570.1795296517685,570.1804926385701,570.181474354971,570.1824398094373,570.1834063434064,570.1843802175476,570.185343346395,570.1863116370166,570.1872778470762,570.1882595758518,570.1892371209622,570.1902024922557,570.1911840097175,570.1921562505122,570.1931298910679,570.1941178845063,570.1950878831577,570.1960543229659,570.1970449572002,570.1980314444556,570.1990038353294,570.1999873927616,570.2009755442853,570.201963325675,570.2029373092006,570.2039368734329,570.204919607147,570.205895829494,570.2068919673137,570.2078783106035,570.2088621903913,570.2098391800561,570.2108375862025,570.2118381806415,570.2128382690361,570.2138129698278,570.2148022001912,570.2158023859894,570.2168076247424,570.2177714155551,570.2188030422238,570.2197827652835,570.2207780079119,570.2217757324465,570.2227863511586,570.2237787003398,570.2247713793015,570.2257818410101,570.2267973698997,570.2278086130642,570.2287820143749,570.2297827148507,570.2307938022566,570.2318190977969,570.2328260584454,570.2338325900716,570.2348347122944,570.2358451773403,570.2368554765771,570.2378534698805,570.2388808812102,570.2398869081401,570.2408961422286,570.2419205592216,570.2429135656446,570.2439317826486]],"type":"surface"},{"marker":{"color":"#27B629","size":7},"mode":"markers","name":"Optimal point","showlegend":false,"x":[1e-05],"y":[1.0606139393939396],"z":[94.82335779870405],"type":"scatter3d"}],                        {"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}},"title":{"text":"Loss vs parameters (alpha, beta) for (radial kernel)","x":0.5,"y":0.925},"scene":{"xaxis":{"title":{"text":"Alpha"}},"yaxis":{"title":{"text":"Beta"}},"zaxis":{"title":{"text":"Loss"}}},"width":500,"height":450},                        {"responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('36279417-96d8-4a8e-9937-fe73b3fe3b7a');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };                });            </script>        </div>
</div>
</div>
<p>We evaluate the performance of the method on the testing data using MSE and MAPE.</p>
<div id="2cfc2b44" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_absolute_percentage_error</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>y_pred1 <span class="op">=</span> gc1_fit.predict(X_test1)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mean_absolute_percentage_error(y_test1, y_pred1))</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mean_squared_error(y_test1, y_pred1))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.15700687272806574
55.368558733036295</code></pre>
</div>
</div>
<p>Let’s look at <code>qq-plot</code> of the predictions and the actual response values using <code>draw_learning_curve()</code> method.</p>
<div id="3557668b" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>gc1_fit.draw_learning_curve(y_test<span class="op">=</span>y_test1, fig_type<span class="op">=</span><span class="st">'qq'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>                            <div id="644eaab5-9cf6-49b4-850b-9d5f31186fc8" class="plotly-graph-div" style="height:450px; width:500px;"></div>            <script type="text/javascript">                require(["plotly"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("644eaab5-9cf6-49b4-850b-9d5f31186fc8")) {                    Plotly.newPlot(                        "644eaab5-9cf6-49b4-850b-9d5f31186fc8",                        [{"hovertemplate":"y_test=%{y}<extra></extra>","legendgroup":"","line":{"color":"red","dash":"solid"},"marker":{"symbol":"circle"},"mode":"lines","name":"","orientation":"v","showlegend":false,"x":[107.12908749668411,82.07729820341567,250.68582410503322,-228.20850045088835,-193.60755325508376,151.25473152208022,25.156734317388604,161.78057073873572,26.1031081041485,-128.4305534178685,27.90866808562813,-44.44116020741867,-138.93840475334991,-222.16681537868476,-192.19645427097396,0.9739650548381744,120.66403004876267,84.01493807657121,229.22301842153715,-65.01672019723868,3.5566914863945716,2.5011089169083967,-75.28038724279148,-51.17106492509048,63.9968795674746,-26.858243562563406,-88.62347922757598,125.3897181575711,159.45283298188983,-171.08163655117602,7.167740354736653,169.9866305208371,-45.476216321052725,196.64418560918458,6.916057547879813,-44.9209106885849,123.29161348759706,-237.05627320839048,4.793227605388368,-87.75386811360924,-204.7547493029273,300.5340481865176,36.6923441324542,223.1260158640755,37.57236489689603,-135.1432154129502,-22.09541283219769,-19.38279454211906,129.0570647553141,-131.32815842579072,422.6071726637826,71.56184791930542,117.97216683218622,71.21094747981446,-71.29424209716659,45.42212756418835,-142.2554807700287,240.68718226715367,45.496919732973716,-48.518054418620885,-248.65784662270624,11.069509335539475,72.05254229256354,-286.46158602249164,100.20919875515544,-263.20440044800785,75.54044381008978,-236.9865925366403,105.9176903979468,-134.89918697795054,-114.09922634996403,195.16438655741743,243.78235672220447,88.76976759082784,274.8524100729351,-7.340463168661583,94.42130245825987,129.61495960951078,219.86857083576825,-239.18599334930218,110.97942524958862,-12.68016776339869,-114.54869084590477,176.46149967380933,29.570182914896833,-50.97935587732554,-45.28967086237738,161.93634504078221,103.50214379224467,25.88535522075014,-33.8894128012218,-242.412557476674,-124.26093105060144,53.63679354263188,-43.3246525052849,-107.73746334414028,121.03273399140014,32.712898595689765,-100.75445110417151,58.67157625605954,-7.5825159865063645,76.6688495574999,13.023195942366515,39.90868904854326,-143.19719258661473,-13.71348176850614,60.61226850721811,-148.92705189944328,164.38182521163475,39.83948082067931,-86.61384134539973,120.35300376200641,-45.220565743218586,-104.6998236678622,-18.168293341880986,224.39055775799608,21.351714206857167,-166.77683714386322,-18.661455614473834,180.041691675834,-96.39307795038825,-33.99774184134089,96.04950261192579,18.87728379020152,-74.46124422252004,-21.456455525633885,-0.5333585972357191,-292.1727368917409,-95.19414501049333,17.940734995718827,-146.74593778483134,-151.00119220601815,62.09397266035934,-33.01234848388809,-25.855903663125307,-65.9126992584748,-8.839918780845649,-171.47171556758286,91.32353005610662,-240.08178210488447,219.3848875267175,19.62192020121106,25.88926237217787,1.9749052668889713,-18.538512569557994,-9.315419891495038,58.232711239576645,-119.70655249853377,80.46302077808511,-82.57388667481422,-255.60025925203018,-67.80947386301447,121.4794212995063,13.859804040726456,202.10891958905597,289.33699561903865,-53.84026788510968,147.75853654057175,30.709841161470898,-58.77980031762141,183.16604659565084,50.94542565632875,-36.02360824141309,184.5201050760169,-194.4973680663153,88.09606416062502,121.32323667682479,105.50454975796093,225.55853185642846,-91.78580216896597,-141.88424494072322,-201.60517536543819,-148.28651750873246,203.18360324017928,-195.80732271269335,-17.550815118335144,89.93641158461833,-65.46712045313103,82.92183773273398,-147.73268717843496,22.048591539069932,122.27445002412495,-55.39748189656167,-76.05201303998004,11.380731583762161,-31.744944384425988,-59.96965302532895,67.34534528686478,-19.045494372635954,215.36455175565462,-295.94662032883775,-103.98671227646881,60.23526349529168,76.56216887038755,-125.8529606820959,-52.89758037421899,-82.16104292148653,68.27941549262121,-227.58479803516835,-5.207533381235832],"xaxis":"x","y":[107.12908749668411,82.07729820341567,250.68582410503322,-228.20850045088835,-193.60755325508376,151.25473152208022,25.156734317388604,161.78057073873572,26.1031081041485,-128.4305534178685,27.90866808562813,-44.44116020741867,-138.93840475334991,-222.16681537868476,-192.19645427097396,0.9739650548381744,120.66403004876267,84.01493807657121,229.22301842153715,-65.01672019723868,3.5566914863945716,2.5011089169083967,-75.28038724279148,-51.17106492509048,63.9968795674746,-26.858243562563406,-88.62347922757598,125.3897181575711,159.45283298188983,-171.08163655117602,7.167740354736653,169.9866305208371,-45.476216321052725,196.64418560918458,6.916057547879813,-44.9209106885849,123.29161348759706,-237.05627320839048,4.793227605388368,-87.75386811360924,-204.7547493029273,300.5340481865176,36.6923441324542,223.1260158640755,37.57236489689603,-135.1432154129502,-22.09541283219769,-19.38279454211906,129.0570647553141,-131.32815842579072,422.6071726637826,71.56184791930542,117.97216683218622,71.21094747981446,-71.29424209716659,45.42212756418835,-142.2554807700287,240.68718226715367,45.496919732973716,-48.518054418620885,-248.65784662270624,11.069509335539475,72.05254229256354,-286.46158602249164,100.20919875515544,-263.20440044800785,75.54044381008978,-236.9865925366403,105.9176903979468,-134.89918697795054,-114.09922634996403,195.16438655741743,243.78235672220447,88.76976759082784,274.8524100729351,-7.340463168661583,94.42130245825987,129.61495960951078,219.86857083576825,-239.18599334930218,110.97942524958862,-12.68016776339869,-114.54869084590477,176.46149967380933,29.570182914896833,-50.97935587732554,-45.28967086237738,161.93634504078221,103.50214379224467,25.88535522075014,-33.8894128012218,-242.412557476674,-124.26093105060144,53.63679354263188,-43.3246525052849,-107.73746334414028,121.03273399140014,32.712898595689765,-100.75445110417151,58.67157625605954,-7.5825159865063645,76.6688495574999,13.023195942366515,39.90868904854326,-143.19719258661473,-13.71348176850614,60.61226850721811,-148.92705189944328,164.38182521163475,39.83948082067931,-86.61384134539973,120.35300376200641,-45.220565743218586,-104.6998236678622,-18.168293341880986,224.39055775799608,21.351714206857167,-166.77683714386322,-18.661455614473834,180.041691675834,-96.39307795038825,-33.99774184134089,96.04950261192579,18.87728379020152,-74.46124422252004,-21.456455525633885,-0.5333585972357191,-292.1727368917409,-95.19414501049333,17.940734995718827,-146.74593778483134,-151.00119220601815,62.09397266035934,-33.01234848388809,-25.855903663125307,-65.9126992584748,-8.839918780845649,-171.47171556758286,91.32353005610662,-240.08178210488447,219.3848875267175,19.62192020121106,25.88926237217787,1.9749052668889713,-18.538512569557994,-9.315419891495038,58.232711239576645,-119.70655249853377,80.46302077808511,-82.57388667481422,-255.60025925203018,-67.80947386301447,121.4794212995063,13.859804040726456,202.10891958905597,289.33699561903865,-53.84026788510968,147.75853654057175,30.709841161470898,-58.77980031762141,183.16604659565084,50.94542565632875,-36.02360824141309,184.5201050760169,-194.4973680663153,88.09606416062502,121.32323667682479,105.50454975796093,225.55853185642846,-91.78580216896597,-141.88424494072322,-201.60517536543819,-148.28651750873246,203.18360324017928,-195.80732271269335,-17.550815118335144,89.93641158461833,-65.46712045313103,82.92183773273398,-147.73268717843496,22.048591539069932,122.27445002412495,-55.39748189656167,-76.05201303998004,11.380731583762161,-31.744944384425988,-59.96965302532895,67.34534528686478,-19.045494372635954,215.36455175565462,-295.94662032883775,-103.98671227646881,60.23526349529168,76.56216887038755,-125.8529606820959,-52.89758037421899,-82.16104292148653,68.27941549262121,-227.58479803516835,-5.207533381235832],"yaxis":"y","type":"scatter"},{"hovertemplate":"y_pred=%{x}<br>y_test=%{y}<extra></extra>","legendgroup":"","marker":{"color":"#636efa","symbol":"circle"},"mode":"markers","name":"","orientation":"v","showlegend":false,"x":[96.80135021678248,74.67340277275937,217.98549929485097,-223.77478297662842,-193.07921110432386,139.5907066410183,28.101557200478666,163.49134610645558,27.942737496508617,-119.96664278124821,28.904835582570684,-46.27274576373267,-134.28987314346438,-222.75304738321407,-201.35278950410486,3.294638906610426,119.53934931249415,81.36806868493233,217.24609329198935,-70.66770737414704,-30.511250062908694,4.284719920087223,-70.44132152266226,-46.840451368373934,69.33314694054037,-27.933965884926078,-83.37780046271801,123.5312319144991,161.0401779487584,-168.6150706637695,4.606535161229291,169.73228194745082,-47.02679021337868,198.23032022500288,10.805312934326897,-38.55796150305142,119.90695090634999,-235.56202972777345,8.097245731318703,-84.56706458139318,-206.39477474374644,291.30237176608296,35.06133277452847,223.78942916263077,29.880520478850062,-93.84758358723478,-27.200331732101066,-17.927714186190858,128.9204529871585,-123.0763960796451,437.24469922578703,70.91079473998978,117.07361213319643,72.49299588299104,-74.4789493183462,47.27398271787378,-139.39222817162508,234.1025913376689,48.55528632844371,-48.30959780504603,-253.6232924900411,14.952086973902334,69.29113179081703,-271.6953558705031,97.5377058634382,-258.9037223995335,86.70566716172968,-232.579426316135,109.05555588968454,-134.47738473129013,-111.04194921670074,195.2406946294832,229.62698948081675,77.86300953997835,271.8184033914378,-7.698601013530555,90.11745798836466,129.53701604609785,200.45381805632488,-233.62812881251395,111.3379612883025,-13.891582171388706,-114.90902022739108,174.37302308709124,35.84901287364937,-51.10590889361271,-40.64073958107127,149.4048234800131,105.72961484295026,27.070328587022566,-40.6093556463722,-243.22617497445265,-121.28225171060338,45.83987135165421,-38.581147162352615,-104.04982951651616,126.03800332367369,34.4796272198233,-100.9744600536651,61.384880965659136,-5.907405373646098,72.16995256764707,10.714375610119276,42.31892501011579,-133.74710883248005,-14.720801839162002,61.725014643688105,-144.6820967625441,164.0201659134869,40.69673991262077,-81.09492176654675,118.5243142807807,-48.87916866244858,-105.04171015760639,-19.468553666129157,216.3278385733629,21.46167369062165,-162.32165517711906,-20.389281146183187,179.65665068528037,-86.49572798501501,-33.537744977142175,92.73259763609735,25.416449572832537,-70.69998529886682,-18.360210521155903,-0.5325698809294459,-277.66127110848316,-89.17623246358612,6.824988548822677,-142.70183506693238,-144.05588014759192,51.931043618082754,-30.064157263985482,-25.126463265769498,-60.68969226457817,-8.784181328872233,-175.66944000516528,88.76273616406287,-235.5383046768222,201.7388545147738,20.168651421447667,22.653882090634966,-5.012443775940745,-19.464401031019058,-8.700829920171616,67.07861477948573,-116.36414693587363,81.84414048531978,-85.94374767999598,-252.84167859669722,-59.135810727454206,119.9156257824608,15.320370473436585,194.00802539227521,290.71062564557536,-56.28127874380184,135.823890559488,27.85767006194371,-65.64765825608457,185.34226158841082,52.63212082141564,-13.691061519955007,188.9566477638274,-191.10275373533992,90.40039617047452,130.1665499001935,104.38007454700234,206.08778804991672,-96.06558485125959,-133.35454456380572,-204.0475115852023,-144.1373316555005,196.6039532305479,-195.62999546590947,-18.737309818173323,92.70171693882125,-64.16315434352276,86.8347430196498,-143.09142520889873,16.155755389604852,119.91136365769037,-47.108421683711875,-84.56949030370062,2.928185508014869,-34.89998615850671,-55.60526924391607,57.88455719551099,-26.741419766341707,202.48690489365427,-279.63403595038847,-103.01599117306954,59.41185594589966,72.05464326424321,-125.35042175006764,-55.671287585367445,-84.05346344231339,73.52977197232157,-224.66118235694717,-7.238449749769362],"xaxis":"x","y":[107.12908749668411,82.07729820341567,250.68582410503322,-228.20850045088835,-193.60755325508376,151.25473152208022,25.156734317388604,161.78057073873572,26.1031081041485,-128.4305534178685,27.90866808562813,-44.44116020741867,-138.93840475334991,-222.16681537868476,-192.19645427097396,0.9739650548381744,120.66403004876267,84.01493807657121,229.22301842153715,-65.01672019723868,3.5566914863945716,2.5011089169083967,-75.28038724279148,-51.17106492509048,63.9968795674746,-26.858243562563406,-88.62347922757598,125.3897181575711,159.45283298188983,-171.08163655117602,7.167740354736653,169.9866305208371,-45.476216321052725,196.64418560918458,6.916057547879813,-44.9209106885849,123.29161348759706,-237.05627320839048,4.793227605388368,-87.75386811360924,-204.7547493029273,300.5340481865176,36.6923441324542,223.1260158640755,37.57236489689603,-135.1432154129502,-22.09541283219769,-19.38279454211906,129.0570647553141,-131.32815842579072,422.6071726637826,71.56184791930542,117.97216683218622,71.21094747981446,-71.29424209716659,45.42212756418835,-142.2554807700287,240.68718226715367,45.496919732973716,-48.518054418620885,-248.65784662270624,11.069509335539475,72.05254229256354,-286.46158602249164,100.20919875515544,-263.20440044800785,75.54044381008978,-236.9865925366403,105.9176903979468,-134.89918697795054,-114.09922634996403,195.16438655741743,243.78235672220447,88.76976759082784,274.8524100729351,-7.340463168661583,94.42130245825987,129.61495960951078,219.86857083576825,-239.18599334930218,110.97942524958862,-12.68016776339869,-114.54869084590477,176.46149967380933,29.570182914896833,-50.97935587732554,-45.28967086237738,161.93634504078221,103.50214379224467,25.88535522075014,-33.8894128012218,-242.412557476674,-124.26093105060144,53.63679354263188,-43.3246525052849,-107.73746334414028,121.03273399140014,32.712898595689765,-100.75445110417151,58.67157625605954,-7.5825159865063645,76.6688495574999,13.023195942366515,39.90868904854326,-143.19719258661473,-13.71348176850614,60.61226850721811,-148.92705189944328,164.38182521163475,39.83948082067931,-86.61384134539973,120.35300376200641,-45.220565743218586,-104.6998236678622,-18.168293341880986,224.39055775799608,21.351714206857167,-166.77683714386322,-18.661455614473834,180.041691675834,-96.39307795038825,-33.99774184134089,96.04950261192579,18.87728379020152,-74.46124422252004,-21.456455525633885,-0.5333585972357191,-292.1727368917409,-95.19414501049333,17.940734995718827,-146.74593778483134,-151.00119220601815,62.09397266035934,-33.01234848388809,-25.855903663125307,-65.9126992584748,-8.839918780845649,-171.47171556758286,91.32353005610662,-240.08178210488447,219.3848875267175,19.62192020121106,25.88926237217787,1.9749052668889713,-18.538512569557994,-9.315419891495038,58.232711239576645,-119.70655249853377,80.46302077808511,-82.57388667481422,-255.60025925203018,-67.80947386301447,121.4794212995063,13.859804040726456,202.10891958905597,289.33699561903865,-53.84026788510968,147.75853654057175,30.709841161470898,-58.77980031762141,183.16604659565084,50.94542565632875,-36.02360824141309,184.5201050760169,-194.4973680663153,88.09606416062502,121.32323667682479,105.50454975796093,225.55853185642846,-91.78580216896597,-141.88424494072322,-201.60517536543819,-148.28651750873246,203.18360324017928,-195.80732271269335,-17.550815118335144,89.93641158461833,-65.46712045313103,82.92183773273398,-147.73268717843496,22.048591539069932,122.27445002412495,-55.39748189656167,-76.05201303998004,11.380731583762161,-31.744944384425988,-59.96965302532895,67.34534528686478,-19.045494372635954,215.36455175565462,-295.94662032883775,-103.98671227646881,60.23526349529168,76.56216887038755,-125.8529606820959,-52.89758037421899,-82.16104292148653,68.27941549262121,-227.58479803516835,-5.207533381235832],"yaxis":"y","type":"scatter"}],                        {"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}},"title":{"text":"QQplot of predicted and actual values","x":0.5,"y":0.925},"width":500,"height":450,"xaxis":{"title":{"text":"Prediction"}},"yaxis":{"title":{"text":"Actual target"}}},                        {"responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('644eaab5-9cf6-49b4-850b-9d5f31186fc8');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };                });            </script>        </div>
</div>
</div>
<section id="use-one-bandwidth-parameter-instead-of-alpha-beta" class="level4">
<h4 class="anchored" data-anchor-id="use-one-bandwidth-parameter-instead-of-alpha-beta">Use one bandwidth parameter instead of (<span class="math inline">\(\alpha, \beta\)</span>)</h4>
<p>You can also try to implement <code>MixCOBRARegressor</code> using only one bandwidth parameter. To do so, just set <code>one_parameter = True</code> when fitting the method. We create another <code>MixCOBRARegressor</code> object with gradient descent optimization method, then fit it on the same data as in the previous case using only one bandwidth parameter as follow.</p>
<div id="1d1da0b5" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># MixCOBRA with one parameter</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>gc2 <span class="op">=</span> MixCOBRARegressor(opt_method<span class="op">=</span><span class="st">"grad"</span>)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>gc2_fit <span class="op">=</span> gc2.fit(X_train1, y_train1, one_parameter<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    * Gradient descent of one parameter with radial kernel is implemented...
        ~ Initial t = 0:        ~ bandwidth: 2.507  ~ gradient: 6.117    ~ threshold: 1e-05
        ~     Iteration: 1  ~ bandwidth: 2.498  ~ gradient: 6.117   ~ stopping criterion: 3.060     ~     Iteration: 2  ~ bandwidth: 2.498  ~ gradient: 6.117   ~ stopping criterion: 3.060     ~     Iteration: 3  ~ bandwidth: 2.498  ~ gradient: 6.117   ~ stopping criterion: 3.060     ~     Iteration: 4  ~ bandwidth: 2.498  ~ gradient: 6.117   ~ stopping criterion: 3.060     ~     Iteration: 5  ~ bandwidth: 2.498  ~ gradient: 6.666   ~ stopping criterion: 3.058     ~     Iteration: 6  ~ bandwidth: 2.487  ~ gradient: 7.136   ~ stopping criterion: 3.333     ~     Iteration: 7  ~ bandwidth: 2.475  ~ gradient: 6.684   ~ stopping criterion: 3.568     ~     Iteration: 8  ~ bandwidth: 2.464  ~ gradient: 6.398   ~ stopping criterion: 3.342     ~     Iteration: 9  ~ bandwidth: 2.454  ~ gradient: 6.699   ~ stopping criterion: 3.199     ~     Iteration: 10     ~ bandwidth: 2.443  ~ gradient: 6.703   ~ stopping criterion: 3.349     ~     Iteration: 11     ~ bandwidth: 2.432  ~ gradient: 6.657   ~ stopping criterion: 3.352     ~     Iteration: 12     ~ bandwidth: 2.421  ~ gradient: 6.178   ~ stopping criterion: 3.328     ~     Iteration: 13     ~ bandwidth: 2.411  ~ gradient: 6.739   ~ stopping criterion: 3.089     ~     Iteration: 14     ~ bandwidth: 2.400  ~ gradient: 6.744   ~ stopping criterion: 3.370     ~     Iteration: 15     ~ bandwidth: 2.389  ~ gradient: 6.658   ~ stopping criterion: 3.372     ~     Iteration: 16     ~ bandwidth: 2.378  ~ gradient: 6.470   ~ stopping criterion: 3.329     ~     Iteration: 17     ~ bandwidth: 2.367  ~ gradient: 6.406   ~ stopping criterion: 3.235     ~     Iteration: 18     ~ bandwidth: 2.357  ~ gradient: 6.787   ~ stopping criterion: 3.203     ~     Iteration: 19     ~ bandwidth: 2.346  ~ gradient: 6.454   ~ stopping criterion: 3.394     ~     Iteration: 20     ~ bandwidth: 2.335  ~ gradient: 7.072   ~ stopping criterion: 3.227     ~     Iteration: 21     ~ bandwidth: 2.323  ~ gradient: 6.891   ~ stopping criterion: 3.536     ~     Iteration: 22     ~ bandwidth: 2.312  ~ gradient: 6.917   ~ stopping criterion: 3.445     ~     Iteration: 23     ~ bandwidth: 2.301  ~ gradient: 6.099   ~ stopping criterion: 3.459     ~     Iteration: 24     ~ bandwidth: 2.291  ~ gradient: 7.145   ~ stopping criterion: 3.049     ~     Iteration: 25     ~ bandwidth: 2.279  ~ gradient: 6.331   ~ stopping criterion: 3.572     ~     Iteration: 26     ~ bandwidth: 2.269  ~ gradient: 6.813   ~ stopping criterion: 3.165     ~     Iteration: 27     ~ bandwidth: 2.258  ~ gradient: 6.747   ~ stopping criterion: 3.406     ~     Iteration: 28     ~ bandwidth: 2.247  ~ gradient: 6.444   ~ stopping criterion: 3.374     ~     Iteration: 29     ~ bandwidth: 2.236  ~ gradient: 6.308   ~ stopping criterion: 3.222     ~     Iteration: 30     ~ bandwidth: 2.226  ~ gradient: 6.187   ~ stopping criterion: 3.154     ~     Iteration: 31     ~ bandwidth: 2.216  ~ gradient: 6.289   ~ stopping criterion: 3.094     ~     Iteration: 32     ~ bandwidth: 2.205  ~ gradient: 6.423   ~ stopping criterion: 3.144     ~     Iteration: 33     ~ bandwidth: 2.195  ~ gradient: 6.672   ~ stopping criterion: 3.212     ~     Iteration: 34     ~ bandwidth: 2.184  ~ gradient: 6.116   ~ stopping criterion: 3.336     ~     Iteration: 35     ~ bandwidth: 2.174  ~ gradient: 6.321   ~ stopping criterion: 3.058     ~     Iteration: 36     ~ bandwidth: 2.164  ~ gradient: 6.790   ~ stopping criterion: 3.160     ~     Iteration: 37     ~ bandwidth: 2.153  ~ gradient: 6.388   ~ stopping criterion: 3.395     ~     Iteration: 38     ~ bandwidth: 2.142  ~ gradient: 6.484   ~ stopping criterion: 3.194     ~     Iteration: 39     ~ bandwidth: 2.132  ~ gradient: 6.444   ~ stopping criterion: 3.242     ~     Iteration: 40     ~ bandwidth: 2.121  ~ gradient: 6.225   ~ stopping criterion: 3.222     ~     Iteration: 41     ~ bandwidth: 2.111  ~ gradient: 6.765   ~ stopping criterion: 3.113     ~     Iteration: 42     ~ bandwidth: 2.100  ~ gradient: 6.115   ~ stopping criterion: 3.382     ~     Iteration: 43     ~ bandwidth: 2.090  ~ gradient: 6.316   ~ stopping criterion: 3.058     ~     Iteration: 44     ~ bandwidth: 2.080  ~ gradient: 6.215   ~ stopping criterion: 3.158     ~     Iteration: 45     ~ bandwidth: 2.069  ~ gradient: 6.300   ~ stopping criterion: 3.108     ~     Iteration: 46     ~ bandwidth: 2.059  ~ gradient: 6.589   ~ stopping criterion: 3.150     ~     Iteration: 47     ~ bandwidth: 2.048  ~ gradient: 6.077   ~ stopping criterion: 3.295     ~     Iteration: 48     ~ bandwidth: 2.038  ~ gradient: 6.110   ~ stopping criterion: 3.038     ~     Iteration: 49     ~ bandwidth: 2.028  ~ gradient: 6.271   ~ stopping criterion: 3.055     ~     Iteration: 50     ~ bandwidth: 2.018  ~ gradient: 6.072   ~ stopping criterion: 3.135     ~     Iteration: 51     ~ bandwidth: 2.008  ~ gradient: 6.016   ~ stopping criterion: 3.036     ~     Iteration: 52     ~ bandwidth: 1.998  ~ gradient: 5.809   ~ stopping criterion: 3.008     ~     Iteration: 53     ~ bandwidth: 1.989  ~ gradient: 5.658   ~ stopping criterion: 2.905     ~     Iteration: 54     ~ bandwidth: 1.980  ~ gradient: 6.551   ~ stopping criterion: 2.829     ~     Iteration: 55     ~ bandwidth: 1.969  ~ gradient: 5.610   ~ stopping criterion: 3.275     ~     Iteration: 56     ~ bandwidth: 1.960  ~ gradient: 5.777   ~ stopping criterion: 2.805     ~     Iteration: 57     ~ bandwidth: 1.950  ~ gradient: 5.640   ~ stopping criterion: 2.889     ~     Iteration: 58     ~ bandwidth: 1.941  ~ gradient: 6.215   ~ stopping criterion: 2.820     ~     Iteration: 59     ~ bandwidth: 1.931  ~ gradient: 6.092   ~ stopping criterion: 3.108     ~     Iteration: 60     ~ bandwidth: 1.921  ~ gradient: 5.885   ~ stopping criterion: 3.046     ~     Iteration: 61     ~ bandwidth: 1.911  ~ gradient: 5.472   ~ stopping criterion: 2.942     ~     Iteration: 62     ~ bandwidth: 1.902  ~ gradient: 6.246   ~ stopping criterion: 2.736     ~     Iteration: 63     ~ bandwidth: 1.892  ~ gradient: 5.362   ~ stopping criterion: 3.123     ~     Iteration: 64     ~ bandwidth: 1.883  ~ gradient: 5.546   ~ stopping criterion: 2.681     ~     Iteration: 65     ~ bandwidth: 1.874  ~ gradient: 5.478   ~ stopping criterion: 2.773     ~     Iteration: 66     ~ bandwidth: 1.865  ~ gradient: 5.728   ~ stopping criterion: 2.739     ~     Iteration: 67     ~ bandwidth: 1.856  ~ gradient: 5.390   ~ stopping criterion: 2.864     ~     Iteration: 68     ~ bandwidth: 1.847  ~ gradient: 5.313   ~ stopping criterion: 2.695     ~     Iteration: 69     ~ bandwidth: 1.839  ~ gradient: 5.677   ~ stopping criterion: 2.656     ~     Iteration: 70     ~ bandwidth: 1.829  ~ gradient: 5.440   ~ stopping criterion: 2.839     ~     Iteration: 71     ~ bandwidth: 1.820  ~ gradient: 5.255   ~ stopping criterion: 2.720     ~     Iteration: 72     ~ bandwidth: 1.812  ~ gradient: 5.381   ~ stopping criterion: 2.627     ~     Iteration: 73     ~ bandwidth: 1.803  ~ gradient: 5.469   ~ stopping criterion: 2.691     ~     Iteration: 74     ~ bandwidth: 1.794  ~ gradient: 5.388   ~ stopping criterion: 2.734     ~     Iteration: 75     ~ bandwidth: 1.785  ~ gradient: 5.371   ~ stopping criterion: 2.694     ~     Iteration: 76     ~ bandwidth: 1.776  ~ gradient: 4.746   ~ stopping criterion: 2.685     ~     Iteration: 77     ~ bandwidth: 1.769  ~ gradient: 5.168   ~ stopping criterion: 2.373     ~     Iteration: 78     ~ bandwidth: 1.760  ~ gradient: 5.064   ~ stopping criterion: 2.584     ~     Iteration: 79     ~ bandwidth: 1.752  ~ gradient: 4.672   ~ stopping criterion: 2.532     ~     Iteration: 80     ~ bandwidth: 1.744  ~ gradient: 4.995   ~ stopping criterion: 2.336     ~     Iteration: 81     ~ bandwidth: 1.736  ~ gradient: 4.971   ~ stopping criterion: 2.498     ~     Iteration: 82     ~ bandwidth: 1.728  ~ gradient: 4.612   ~ stopping criterion: 2.485     ~     Iteration: 83     ~ bandwidth: 1.720  ~ gradient: 4.821   ~ stopping criterion: 2.306     ~     Iteration: 84     ~ bandwidth: 1.713  ~ gradient: 4.481   ~ stopping criterion: 2.410     ~     Iteration: 85     ~ bandwidth: 1.705  ~ gradient: 4.203   ~ stopping criterion: 2.240     ~     Iteration: 86     ~ bandwidth: 1.698  ~ gradient: 4.971   ~ stopping criterion: 2.101     ~     Iteration: 87     ~ bandwidth: 1.690  ~ gradient: 4.953   ~ stopping criterion: 2.485     ~     Iteration: 88     ~ bandwidth: 1.682  ~ gradient: 4.125   ~ stopping criterion: 2.476     ~     Iteration: 89     ~ bandwidth: 1.675  ~ gradient: 4.568   ~ stopping criterion: 2.063     ~     Iteration: 90     ~ bandwidth: 1.668  ~ gradient: 4.570   ~ stopping criterion: 2.284     ~     Iteration: 91     ~ bandwidth: 1.660  ~ gradient: 4.685   ~ stopping criterion: 2.285     ~     Iteration: 92     ~ bandwidth: 1.653  ~ gradient: 4.392   ~ stopping criterion: 2.343     ~     Iteration: 93     ~ bandwidth: 1.646  ~ gradient: 3.955   ~ stopping criterion: 2.196     ~     Iteration: 94     ~ bandwidth: 1.639  ~ gradient: 4.312   ~ stopping criterion: 1.977     ~     Iteration: 95     ~ bandwidth: 1.632  ~ gradient: 4.327   ~ stopping criterion: 2.156     ~     Iteration: 96     ~ bandwidth: 1.625  ~ gradient: 3.906   ~ stopping criterion: 2.163     ~     Iteration: 97     ~ bandwidth: 1.619  ~ gradient: 4.109   ~ stopping criterion: 1.953     ~     Iteration: 98     ~ bandwidth: 1.612  ~ gradient: 3.847   ~ stopping criterion: 2.054     ~     Iteration: 99     ~ bandwidth: 1.606  ~ gradient: 3.394   ~ stopping criterion: 1.924     ~     Iteration: 100    ~ bandwidth: 1.600  ~ gradient: 3.975   ~ stopping criterion: 1.697     ~     Iteration: 101    ~ bandwidth: 1.594  ~ gradient: 3.474   ~ stopping criterion: 1.987     ~     Iteration: 102    ~ bandwidth: 1.588  ~ gradient: 3.515   ~ stopping criterion: 1.737     ~     Iteration: 103    ~ bandwidth: 1.582  ~ gradient: 3.229   ~ stopping criterion: 1.758     ~     Iteration: 104    ~ bandwidth: 1.577  ~ gradient: 3.108   ~ stopping criterion: 1.614     ~     Iteration: 105    ~ bandwidth: 1.572  ~ gradient: 3.302   ~ stopping criterion: 1.554     ~     Iteration: 106    ~ bandwidth: 1.566  ~ gradient: 3.382   ~ stopping criterion: 1.651     ~     Iteration: 107    ~ bandwidth: 1.561  ~ gradient: 3.088   ~ stopping criterion: 1.691     ~     Iteration: 108    ~ bandwidth: 1.556  ~ gradient: 3.160   ~ stopping criterion: 1.544     ~     Iteration: 109    ~ bandwidth: 1.551  ~ gradient: 3.247   ~ stopping criterion: 1.580     ~     Iteration: 110    ~ bandwidth: 1.545  ~ gradient: 3.975   ~ stopping criterion: 1.623     ~     Iteration: 111    ~ bandwidth: 1.539  ~ gradient: 2.808   ~ stopping criterion: 1.988     ~     Iteration: 112    ~ bandwidth: 1.534  ~ gradient: 2.843   ~ stopping criterion: 1.404     ~     Iteration: 113    ~ bandwidth: 1.530  ~ gradient: 3.011   ~ stopping criterion: 1.422     ~     Iteration: 114    ~ bandwidth: 1.525  ~ gradient: 2.800   ~ stopping criterion: 1.505     ~     Iteration: 115    ~ bandwidth: 1.520  ~ gradient: 2.647   ~ stopping criterion: 1.400     ~     Iteration: 116    ~ bandwidth: 1.516  ~ gradient: 2.943   ~ stopping criterion: 1.323     ~     Iteration: 117    ~ bandwidth: 1.511  ~ gradient: 2.445   ~ stopping criterion: 1.471     ~     Iteration: 118    ~ bandwidth: 1.507  ~ gradient: 3.009   ~ stopping criterion: 1.223     ~     Iteration: 119    ~ bandwidth: 1.502  ~ gradient: 2.592   ~ stopping criterion: 1.505     ~     Iteration: 120    ~ bandwidth: 1.498  ~ gradient: 3.087   ~ stopping criterion: 1.296     ~     Iteration: 121    ~ bandwidth: 1.493  ~ gradient: 2.257   ~ stopping criterion: 1.543     ~     Iteration: 122    ~ bandwidth: 1.489  ~ gradient: 3.097   ~ stopping criterion: 1.129     ~     Iteration: 123    ~ bandwidth: 1.484  ~ gradient: 1.627   ~ stopping criterion: 1.548     ~     Iteration: 124    ~ bandwidth: 1.481  ~ gradient: 2.062   ~ stopping criterion: 0.813     ~     Iteration: 125    ~ bandwidth: 1.478  ~ gradient: 2.432   ~ stopping criterion: 1.031     ~     Iteration: 126    ~ bandwidth: 1.474  ~ gradient: 2.252   ~ stopping criterion: 1.216     ~     Iteration: 127    ~ bandwidth: 1.470  ~ gradient: 2.166   ~ stopping criterion: 1.126     ~     Iteration: 128    ~ bandwidth: 1.467  ~ gradient: 2.277   ~ stopping criterion: 1.083     ~     Iteration: 129    ~ bandwidth: 1.463  ~ gradient: 2.395   ~ stopping criterion: 1.138     ~     Iteration: 130    ~ bandwidth: 1.459  ~ gradient: 1.990   ~ stopping criterion: 1.198     ~     Iteration: 131    ~ bandwidth: 1.456  ~ gradient: 1.705   ~ stopping criterion: 0.995     ~     Iteration: 132    ~ bandwidth: 1.453  ~ gradient: 2.333   ~ stopping criterion: 0.853     ~     Iteration: 133    ~ bandwidth: 1.449  ~ gradient: 2.190   ~ stopping criterion: 1.166     ~     Iteration: 134    ~ bandwidth: 1.446  ~ gradient: 1.763   ~ stopping criterion: 1.095     ~     Iteration: 135    ~ bandwidth: 1.443  ~ gradient: 1.548   ~ stopping criterion: 0.881     ~     Iteration: 136    ~ bandwidth: 1.440  ~ gradient: 1.964   ~ stopping criterion: 0.774     ~     Iteration: 137    ~ bandwidth: 1.437  ~ gradient: 1.697   ~ stopping criterion: 0.982     ~     Iteration: 138    ~ bandwidth: 1.434  ~ gradient: 1.688   ~ stopping criterion: 0.849     ~     Iteration: 139    ~ bandwidth: 1.432  ~ gradient: 1.876   ~ stopping criterion: 0.844     ~     Iteration: 140    ~ bandwidth: 1.429  ~ gradient: 1.161   ~ stopping criterion: 0.938     ~     Iteration: 141    ~ bandwidth: 1.427  ~ gradient: 1.228   ~ stopping criterion: 0.580     ~     Iteration: 142    ~ bandwidth: 1.425  ~ gradient: 1.587   ~ stopping criterion: 0.614     ~     Iteration: 143    ~ bandwidth: 1.422  ~ gradient: 1.463   ~ stopping criterion: 0.793     ~     Iteration: 144    ~ bandwidth: 1.420  ~ gradient: 1.594   ~ stopping criterion: 0.731     ~     Iteration: 145    ~ bandwidth: 1.417  ~ gradient: 1.441   ~ stopping criterion: 0.797     ~     Iteration: 146    ~ bandwidth: 1.415  ~ gradient: 0.771   ~ stopping criterion: 0.720     ~     Iteration: 147    ~ bandwidth: 1.413  ~ gradient: 1.290   ~ stopping criterion: 0.385     ~     Iteration: 148    ~ bandwidth: 1.411  ~ gradient: 1.131   ~ stopping criterion: 0.645     ~     Iteration: 149    ~ bandwidth: 1.409  ~ gradient: 0.936   ~ stopping criterion: 0.565     ~     Iteration: 150    ~ bandwidth: 1.408  ~ gradient: 0.573   ~ stopping criterion: 0.468     ~     Iteration: 151    ~ bandwidth: 1.407  ~ gradient: 1.453   ~ stopping criterion: 0.286     ~     Iteration: 152    ~ bandwidth: 1.405  ~ gradient: 0.936   ~ stopping criterion: 0.726     ~     Iteration: 153    ~ bandwidth: 1.403  ~ gradient: 1.253   ~ stopping criterion: 0.468     ~     Iteration: 154    ~ bandwidth: 1.401  ~ gradient: 1.224   ~ stopping criterion: 0.626     ~     Iteration: 155    ~ bandwidth: 1.399  ~ gradient: 0.830   ~ stopping criterion: 0.612     ~     Iteration: 156    ~ bandwidth: 1.398  ~ gradient: 0.916   ~ stopping criterion: 0.415     ~     Iteration: 157    ~ bandwidth: 1.396  ~ gradient: 1.214   ~ stopping criterion: 0.458     ~     Iteration: 158    ~ bandwidth: 1.394  ~ gradient: 0.808   ~ stopping criterion: 0.607     ~     Iteration: 159    ~ bandwidth: 1.393  ~ gradient: 1.391   ~ stopping criterion: 0.404     ~     Iteration: 160    ~ bandwidth: 1.391  ~ gradient: 0.413   ~ stopping criterion: 0.696     ~     Iteration: 161    ~ bandwidth: 1.390  ~ gradient: 0.945   ~ stopping criterion: 0.206     ~     Iteration: 162    ~ bandwidth: 1.388  ~ gradient: 1.313   ~ stopping criterion: 0.473     ~     Iteration: 163    ~ bandwidth: 1.386  ~ gradient: 0.947   ~ stopping criterion: 0.656     ~     Iteration: 164    ~ bandwidth: 1.385  ~ gradient: 1.670   ~ stopping criterion: 0.473     ~     Iteration: 165    ~ bandwidth: 1.382  ~ gradient: 0.398   ~ stopping criterion: 0.835     ~     Iteration: 166    ~ bandwidth: 1.381  ~ gradient: 0.848   ~ stopping criterion: 0.199     ~     Iteration: 167    ~ bandwidth: 1.380  ~ gradient: 0.249   ~ stopping criterion: 0.424     ~     Iteration: 168    ~ bandwidth: 1.380  ~ gradient: 0.390   ~ stopping criterion: 0.124     ~     Iteration: 169    ~ bandwidth: 1.379  ~ gradient: 0.909   ~ stopping criterion: 0.195     ~     Iteration: 170    ~ bandwidth: 1.377  ~ gradient: -0.084  ~ stopping criterion: 0.454     ~     Iteration: 171    ~ bandwidth: 1.378  ~ gradient: 0.368   ~ stopping criterion: 0.042     ~     Iteration: 172    ~ bandwidth: 1.377  ~ gradient: 0.925   ~ stopping criterion: 0.184     ~     Iteration: 173    ~ bandwidth: 1.376  ~ gradient: 0.271   ~ stopping criterion: 0.463     ~     Iteration: 174    ~ bandwidth: 1.376  ~ gradient: 0.795   ~ stopping criterion: 0.136     ~     Iteration: 175    ~ bandwidth: 1.375  ~ gradient: 0.549   ~ stopping criterion: 0.398     ~     Iteration: 176    ~ bandwidth: 1.374  ~ gradient: 0.424   ~ stopping criterion: 0.274     ~     Iteration: 177    ~ bandwidth: 1.374  ~ gradient: 0.561   ~ stopping criterion: 0.212     ~     Iteration: 178    ~ bandwidth: 1.373  ~ gradient: 0.322   ~ stopping criterion: 0.281     ~     Iteration: 179    ~ bandwidth: 1.373  ~ gradient: 0.635   ~ stopping criterion: 0.161     ~     Iteration: 180    ~ bandwidth: 1.372  ~ gradient: 1.085   ~ stopping criterion: 0.317     ~     Iteration: 181    ~ bandwidth: 1.371  ~ gradient: 0.681   ~ stopping criterion: 0.543     ~     Iteration: 182    ~ bandwidth: 1.371  ~ gradient: 0.938   ~ stopping criterion: 0.341     ~     Iteration: 183    ~ bandwidth: 1.370  ~ gradient: 0.132   ~ stopping criterion: 0.469     ~     Iteration: 184    ~ bandwidth: 1.369  ~ gradient: 0.551   ~ stopping criterion: 0.066     ~     Iteration: 185    ~ bandwidth: 1.369  ~ gradient: 0.253   ~ stopping criterion: 0.276     ~     Iteration: 186    ~ bandwidth: 1.369  ~ gradient: 0.471   ~ stopping criterion: 0.127     ~     Iteration: 187    ~ bandwidth: 1.368  ~ gradient: 0.502   ~ stopping criterion: 0.236     ~     Iteration: 188    ~ bandwidth: 1.368  ~ gradient: -0.305  ~ stopping criterion: 0.251     ~     Iteration: 189    ~ bandwidth: 1.368  ~ gradient: 0.683   ~ stopping criterion: 0.153     ~     Iteration: 190    ~ bandwidth: 1.367  ~ gradient: 0.343   ~ stopping criterion: 0.342     ~     Iteration: 191    ~ bandwidth: 1.367  ~ gradient: 1.250   ~ stopping criterion: 0.172     ~     Iteration: 192    ~ bandwidth: 1.366  ~ gradient: 0.239   ~ stopping criterion: 0.625     ~     Iteration: 193    ~ bandwidth: 1.366  ~ gradient: -0.036  ~ stopping criterion: 0.120     ~     Iteration: 194    ~ bandwidth: 1.366  ~ gradient: 0.914   ~ stopping criterion: 0.018     ~     Iteration: 195    ~ bandwidth: 1.366  ~ gradient: 0.330   ~ stopping criterion: 0.457     ~     Iteration: 196    ~ bandwidth: 1.365  ~ gradient: 0.433   ~ stopping criterion: 0.165     ~     Iteration: 197    ~ bandwidth: 1.365  ~ gradient: 0.359   ~ stopping criterion: 0.216     ~     Iteration: 198    ~ bandwidth: 1.365  ~ gradient: 0.439   ~ stopping criterion: 0.180     ~     Iteration: 199    ~ bandwidth: 1.365  ~ gradient: -0.019  ~ stopping criterion: 0.220     ~     Iteration: 200    ~ bandwidth: 1.365  ~ gradient: 0.730   ~ stopping criterion: 0.010     ~     Iteration: 201    ~ bandwidth: 1.365  ~ gradient: 0.690   ~ stopping criterion: 0.365     ~     Iteration: 202    ~ bandwidth: 1.364  ~ gradient: 0.937   ~ stopping criterion: 0.345     ~     Iteration: 203    ~ bandwidth: 1.364  ~ gradient: 0.764   ~ stopping criterion: 0.468     ~     Iteration: 204    ~ bandwidth: 1.364  ~ gradient: 0.490   ~ stopping criterion: 0.382     ~     Iteration: 205    ~ bandwidth: 1.364  ~ gradient: 0.429   ~ stopping criterion: 0.245     ~     Iteration: 206    ~ bandwidth: 1.364  ~ gradient: 0.595   ~ stopping criterion: 0.214     ~     Iteration: 207    ~ bandwidth: 1.364  ~ gradient: 0.536   ~ stopping criterion: 0.297     ~     Iteration: 208    ~ bandwidth: 1.363  ~ gradient: 0.214   ~ stopping criterion: 0.268     ~     Iteration: 209    ~ bandwidth: 1.363  ~ gradient: 0.141   ~ stopping criterion: 0.107     ~     Iteration: 210    ~ bandwidth: 1.363  ~ gradient: -0.102  ~ stopping criterion: 0.070     ~     Iteration: 211    ~ bandwidth: 1.363  ~ gradient: 0.467   ~ stopping criterion: 0.051     ~     Iteration: 212    ~ bandwidth: 1.363  ~ gradient: 0.461   ~ stopping criterion: 0.234     ~     Iteration: 213    ~ bandwidth: 1.363  ~ gradient: 0.567   ~ stopping criterion: 0.231     ~     Iteration: 214    ~ bandwidth: 1.363  ~ gradient: 0.320   ~ stopping criterion: 0.284     ~     Iteration: 215    ~ bandwidth: 1.363  ~ gradient: 0.596   ~ stopping criterion: 0.160     ~     Iteration: 216    ~ bandwidth: 1.363  ~ gradient: 0.138   ~ stopping criterion: 0.298     ~     Iteration: 217    ~ bandwidth: 1.363  ~ gradient: 0.233   ~ stopping criterion: 0.069     ~     Iteration: 218    ~ bandwidth: 1.363  ~ gradient: 0.520   ~ stopping criterion: 0.117     ~     Iteration: 219    ~ bandwidth: 1.363  ~ gradient: 0.395   ~ stopping criterion: 0.260     ~     Iteration: 220    ~ bandwidth: 1.363  ~ gradient: -0.147  ~ stopping criterion: 0.198     ~     Iteration: 221    ~ bandwidth: 1.363  ~ gradient: 0.263   ~ stopping criterion: 0.074     ~     Iteration: 222    ~ bandwidth: 1.363  ~ gradient: -0.166  ~ stopping criterion: 0.131     ~     Iteration: 223    ~ bandwidth: 1.363  ~ gradient: 0.216   ~ stopping criterion: 0.083     ~     Iteration: 224    ~ bandwidth: 1.363  ~ gradient: -0.118  ~ stopping criterion: 0.108     ~     Iteration: 225    ~ bandwidth: 1.363  ~ gradient: -0.224  ~ stopping criterion: 0.059     ~     Iteration: 226    ~ bandwidth: 1.363  ~ gradient: 0.961   ~ stopping criterion: 0.112     ~     Iteration: 227    ~ bandwidth: 1.363  ~ gradient: 0.641   ~ stopping criterion: 0.481     ~     Iteration: 228    ~ bandwidth: 1.363  ~ gradient: 0.475   ~ stopping criterion: 0.321     ~     Iteration: 229    ~ bandwidth: 1.363  ~ gradient: -0.321  ~ stopping criterion: 0.238     ~     Iteration: 230    ~ bandwidth: 1.363  ~ gradient: 0.379   ~ stopping criterion: 0.161     ~     Iteration: 231    ~ bandwidth: 1.363  ~ gradient: 0.222   ~ stopping criterion: 0.189     ~     Iteration: 232    ~ bandwidth: 1.363  ~ gradient: 0.074   ~ stopping criterion: 0.111     ~     Iteration: 233    ~ bandwidth: 1.363  ~ gradient: -0.062  ~ stopping criterion: 0.037     ~     Iteration: 234    ~ bandwidth: 1.363  ~ gradient: 0.409   ~ stopping criterion: 0.031     ~     Iteration: 235    ~ bandwidth: 1.363  ~ gradient: 0.372   ~ stopping criterion: 0.204     ~     Iteration: 236    ~ bandwidth: 1.363  ~ gradient: 0.176   ~ stopping criterion: 0.186     ~     Iteration: 237    ~ bandwidth: 1.363  ~ gradient: 0.457   ~ stopping criterion: 0.088     ~     Iteration: 238    ~ bandwidth: 1.363  ~ gradient: 0.297   ~ stopping criterion: 0.228     ~     Iteration: 239    ~ bandwidth: 1.363  ~ gradient: 0.575   ~ stopping criterion: 0.148     ~     Iteration: 240    ~ bandwidth: 1.363  ~ gradient: 0.471   ~ stopping criterion: 0.287     ~     Iteration: 241    ~ bandwidth: 1.363  ~ gradient: -0.178  ~ stopping criterion: 0.235     ~     Iteration: 242    ~ bandwidth: 1.363  ~ gradient: -0.233  ~ stopping criterion: 0.089     ~     Iteration: 243    ~ bandwidth: 1.363  ~ gradient: -0.411  ~ stopping criterion: 0.117     ~     Iteration: 244    ~ bandwidth: 1.363  ~ gradient: 0.645   ~ stopping criterion: 0.206     ~     Iteration: 245    ~ bandwidth: 1.363  ~ gradient: -0.270  ~ stopping criterion: 0.323     ~     Iteration: 246    ~ bandwidth: 1.363  ~ gradient: 0.774   ~ stopping criterion: 0.135     ~     Iteration: 247    ~ bandwidth: 1.363  ~ gradient: 0.311   ~ stopping criterion: 0.387     ~     Iteration: 248    ~ bandwidth: 1.363  ~ gradient: -0.524  ~ stopping criterion: 0.156     ~     Iteration: 249    ~ bandwidth: 1.363  ~ gradient: -0.233  ~ stopping criterion: 0.262     ~     Iteration: 250    ~ bandwidth: 1.363  ~ gradient: 0.119   ~ stopping criterion: 0.116     ~     Iteration: 251    ~ bandwidth: 1.363  ~ gradient: 0.820   ~ stopping criterion: 0.060     ~     Iteration: 252    ~ bandwidth: 1.363  ~ gradient: 0.126   ~ stopping criterion: 0.410     ~     Iteration: 253    ~ bandwidth: 1.363  ~ gradient: -0.783  ~ stopping criterion: 0.063     ~     Iteration: 254    ~ bandwidth: 1.363  ~ gradient: -0.330  ~ stopping criterion: 0.392     ~     Iteration: 255    ~ bandwidth: 1.363  ~ gradient: 0.160   ~ stopping criterion: 0.165     ~     Iteration: 256    ~ bandwidth: 1.363  ~ gradient: 0.908   ~ stopping criterion: 0.080     ~     Iteration: 257    ~ bandwidth: 1.363  ~ gradient: -0.076  ~ stopping criterion: 0.454     ~     Iteration: 258    ~ bandwidth: 1.363  ~ gradient: 0.414   ~ stopping criterion: 0.038     ~     Iteration: 259    ~ bandwidth: 1.363  ~ gradient: 0.119   ~ stopping criterion: 0.207     ~     Iteration: 260    ~ bandwidth: 1.363  ~ gradient: -0.128  ~ stopping criterion: 0.059     ~     Iteration: 261    ~ bandwidth: 1.363  ~ gradient: 0.427   ~ stopping criterion: 0.064     ~     Iteration: 262    ~ bandwidth: 1.363  ~ gradient: 0.058   ~ stopping criterion: 0.213     ~     Iteration: 263    ~ bandwidth: 1.363  ~ gradient: -0.211  ~ stopping criterion: 0.029     ~     Iteration: 264    ~ bandwidth: 1.363  ~ gradient: -0.027  ~ stopping criterion: 0.106     ~     Iteration: 265    ~ bandwidth: 1.363  ~ gradient: -0.522  ~ stopping criterion: 0.014     ~     Iteration: 266    ~ bandwidth: 1.363  ~ gradient: 0.226   ~ stopping criterion: 0.261     ~     Iteration: 267    ~ bandwidth: 1.363  ~ gradient: 0.334   ~ stopping criterion: 0.113     ~     Iteration: 268    ~ bandwidth: 1.363  ~ gradient: 0.061   ~ stopping criterion: 0.167     ~     Iteration: 269    ~ bandwidth: 1.363  ~ gradient: -0.615  ~ stopping criterion: 0.031     ~     Iteration: 270    ~ bandwidth: 1.363  ~ gradient: 0.181   ~ stopping criterion: 0.307     ~     Iteration: 271    ~ bandwidth: 1.363  ~ gradient: 0.080   ~ stopping criterion: 0.090     ~     Iteration: 272    ~ bandwidth: 1.363  ~ gradient: 0.412   ~ stopping criterion: 0.040     ~     Iteration: 273    ~ bandwidth: 1.363  ~ gradient: -0.258  ~ stopping criterion: 0.206     ~     Iteration: 274    ~ bandwidth: 1.363  ~ gradient: -0.336  ~ stopping criterion: 0.129     ~     Iteration: 275    ~ bandwidth: 1.363  ~ gradient: -0.394  ~ stopping criterion: 0.168     ~     Iteration: 276    ~ bandwidth: 1.363  ~ gradient: 0.192   ~ stopping criterion: 0.197     ~     Iteration: 277    ~ bandwidth: 1.363  ~ gradient: 0.273   ~ stopping criterion: 0.096     ~     Iteration: 278    ~ bandwidth: 1.363  ~ gradient: -0.158  ~ stopping criterion: 0.137     ~     Iteration: 279    ~ bandwidth: 1.363  ~ gradient: -0.290  ~ stopping criterion: 0.079     ~     Iteration: 280    ~ bandwidth: 1.363  ~ gradient: 0.212   ~ stopping criterion: 0.145     ~     Iteration: 281    ~ bandwidth: 1.363  ~ gradient: -0.023  ~ stopping criterion: 0.106     ~     Iteration: 282    ~ bandwidth: 1.363  ~ gradient: -0.012  ~ stopping criterion: 0.012     ~     Iteration: 283    ~ bandwidth: 1.363  ~ gradient: 0.236   ~ stopping criterion: 0.006     ~     Iteration: 284    ~ bandwidth: 1.363  ~ gradient: 0.201   ~ stopping criterion: 0.118     ~     Iteration: 285    ~ bandwidth: 1.363  ~ gradient: 0.130   ~ stopping criterion: 0.100     ~     Iteration: 286    ~ bandwidth: 1.363  ~ gradient: 0.077   ~ stopping criterion: 0.065     ~     Iteration: 287    ~ bandwidth: 1.363  ~ gradient: -0.073  ~ stopping criterion: 0.038     ~     Iteration: 288    ~ bandwidth: 1.363  ~ gradient: 0.081   ~ stopping criterion: 0.036     ~     Iteration: 289    ~ bandwidth: 1.363  ~ gradient: -0.076  ~ stopping criterion: 0.040     ~     Iteration: 290    ~ bandwidth: 1.363  ~ gradient: 0.329   ~ stopping criterion: 0.038     ~     Iteration: 291    ~ bandwidth: 1.363  ~ gradient: 0.367   ~ stopping criterion: 0.164     ~     Iteration: 292    ~ bandwidth: 1.363  ~ gradient: 0.549   ~ stopping criterion: 0.183     ~     Iteration: 293    ~ bandwidth: 1.363  ~ gradient: -0.151  ~ stopping criterion: 0.274     ~     Iteration: 294    ~ bandwidth: 1.363  ~ gradient: 0.176   ~ stopping criterion: 0.076     ~     Iteration: 295    ~ bandwidth: 1.363  ~ gradient: -0.150  ~ stopping criterion: 0.088     ~     Iteration: 296    ~ bandwidth: 1.363  ~ gradient: 0.188   ~ stopping criterion: 0.075     ~     Iteration: 297    ~ bandwidth: 1.363  ~ gradient: -0.150  ~ stopping criterion: 0.094     ~     Iteration: 298    ~ bandwidth: 1.363  ~ gradient: 0.005   ~ stopping criterion: 0.075     ~     Iteration: 299    ~ bandwidth: 1.363  ~ gradient: 0.005   ~ stopping criterion: 0.003     ~     Iteration: 300    ~ bandwidth: 1.363  ~ gradient: 0.005   ~ stopping criterion: 0.003                                                                                                                                                                                 ~    Stopped at: 300    ~ bandwidth: 1.363  ~ gradient: 0.005   ~ stopping criterion: 0.003</code></pre>
</div>
</div>
<p>Let’s compare this to the previous case.</p>
<div id="dc6032dd" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># MixCOBRA with default parameter</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Estimated bandwidth = </span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(gc2_fit.optimization_outputs[<span class="st">'opt_bandwidth'</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Estimated bandwidth = 1.3625529396423106</code></pre>
</div>
</div>
<p>The learning curve.</p>
<div id="aeaa9e00" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>gc2_fit.draw_learning_curve()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>                            <div id="b515d47d-72b2-4b7c-a54d-6f261669c075" class="plotly-graph-div" style="height:450px; width:900px;"></div>            <script type="text/javascript">                require(["plotly"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("b515d47d-72b2-4b7c-a54d-6f261669c075")) {                    Plotly.newPlot(                        "b515d47d-72b2-4b7c-a54d-6f261669c075",                        [{"mode":"lines","showlegend":false,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299],"y":[2.4975,2.4975,2.4975,2.4975,2.4975,2.4866022369979177,2.4749368565263543,2.4640092734655483,2.453549958182692,2.442598427507193,2.431639637941631,2.420757108032217,2.410656541883395,2.3996392225886205,2.388614642376214,2.3777305928586743,2.36715285741992,2.35668077517647,2.345584636425707,2.3350336126173596,2.3234721502095277,2.3122073127000267,2.3008987669545578,2.29092825246671,2.279248269011237,2.268898398665427,2.257760759865769,2.246730561199673,2.236195729621733,2.2258831967987165,2.215768215931377,2.20548772840351,2.194986913220444,2.184079049765473,2.1740812919008246,2.1637484158565465,2.1526475614761504,2.142204562483515,2.1316039647045577,2.1210697135073717,2.1108930250398594,2.0998343580658854,2.0898370028017617,2.079511213447053,2.0693501679768604,2.0590504391124904,2.0482779815998566,2.03834360278874,2.0283555241153857,2.018104366260283,2.008177276113306,1.9983423810206937,1.9888452346598968,1.9795949481027366,1.968885968363771,1.959715166370301,1.950270209507612,1.9410497062533156,1.9308889634571922,1.920929075225311,1.9113088902483863,1.9023637682922663,1.8921522299630897,1.8833857410688655,1.874318708914594,1.8653634035529785,1.855999987293804,1.8471876574414856,1.8385021131116828,1.8292208660018507,1.8203280616163913,1.8117377240877386,1.8029402648805164,1.7939999294190492,1.7851908140274428,1.7764105294098713,1.7686512420392706,1.760202123222219,1.7519240996727081,1.7442856802048896,1.7361192827316925,1.7279927916439162,1.7204537558641835,1.71257251050323,1.7052475166741576,1.6983770550826536,1.6902508341807965,1.6821537884371183,1.675409900436343,1.6679418895952436,1.660470232075066,1.6528109936994664,1.6456313978496253,1.639166529886583,1.6321164761523612,1.6250428533751582,1.6186568823007985,1.6119402709316282,1.6056509064587605,1.6001016340844312,1.5936036576221086,1.5879239640215428,1.5821770528963637,1.576898376260063,1.5718173061815082,1.5664199439671032,1.5608916733058562,1.5558437138761185,1.5506782144918405,1.5453707106586456,1.5388723051613158,1.5342822832856136,1.5296344094678218,1.5247127254524508,1.5201355039994915,1.515808322471725,1.510997672710175,1.5070003843473507,1.5020811011073316,1.497843971187352,1.4927974667518589,1.4891072555830178,1.4840448915737692,1.4813854325619493,1.4780142274693502,1.4740382916064796,1.4703559050949733,1.4668154793824404,1.4630932332677056,1.459177164167449,1.4559240057828444,1.4531364578741477,1.449322802862862,1.4457422872940113,1.4428606634850565,1.4403302237321705,1.4371192799347972,1.4343442862185567,1.4315841745595306,1.4285177435736196,1.426620005003193,1.4246131674091076,1.4220189586316376,1.4196276816231281,1.4170221715712372,1.4146671366975796,1.4134073800891278,1.4112983768503637,1.4094501179038263,1.4079199373890323,1.4069836233579756,1.4046090134753453,1.4030788466720523,1.4010305089988706,1.3990302911662829,1.397673642530837,1.3961760889656385,1.3941907921055359,1.3928704864519637,1.3905960122328933,1.3899213665091497,1.3883762739748862,1.3862299103856077,1.384682157852072,1.381952016347637,1.3813014127525767,1.3799150855294098,1.3795085147834154,1.37887034561136,1.3773850380336004,1.3775225353957088,1.3770413362347314,1.3760731662631005,1.375789409613258,1.3749576170652607,1.3743833638644252,1.373939621587228,1.373352626792355,1.3730158934887544,1.3723516938932987,1.371216444377166,1.3705034819630155,1.369522038143916,1.3693842803208782,1.368807678740514,1.3685425561219762,1.3680495771317012,1.3675247515084106,1.3678440659306415,1.3672722039548626,1.3670423031186925,1.3662054287952732,1.3660452751481449,1.3660693070263852,1.3655798473104905,1.3654384584493706,1.3652530249397734,1.3650990008740835,1.3649108333120512,1.364919163928524,1.3646688877588373,1.3644797332364615,1.3642228516857695,1.36401334330762,1.363879067254459,1.3637614794823705,1.3635983802371707,1.3634513939883979,1.3633926172376563,1.3633540494790448,1.3633820243781327,1.3632794918973283,1.3631984880924009,1.3630988900650962,1.3630427976587876,1.3629382205905218,1.3629140219652716,1.3628731128070286,1.3627818702456254,1.3627124964242843,1.3627383696962225,1.3627014402195483,1.3627201088524048,1.3627006528362149,1.3627091029544094,1.3627220004190594,1.3626667177805971,1.3626372164817617,1.3626153478787628,1.3626301219728996,1.3626161727497244,1.3626096222883977,1.3626074576321832,1.3626092947225341,1.3625996649852357,1.3625926486651596,1.3625893231194803,1.3625807173194078,1.3625751256175496,1.362564289920861,1.362555418779858,1.3625587804899009,1.362562297337889,1.362568499640185,1.3625587672231878,1.3625620281561306,1.362554555728125,1.3625521517286348,1.3625561943792137,1.3625576321433703,1.3625568941714408,1.3625528440159453,1.362552219262681,1.362556089407817,1.362557394619102,1.3625567617961736,1.3625538889657025,1.3625541303126534,1.362553083575075,1.3625528436802856,1.362553103171658,1.362552412428612,1.362552337684963,1.3625526114146045,1.362552639537308,1.3625531804631141,1.3625529458426506,1.3625526689477303,1.362552618170866,1.362553127819606,1.3625530078842352,1.3625529651937152,1.362552746455395,1.3625528835459368,1.3625530262374514,1.3625531934519153,1.3625531120966998,1.3625530192472064,1.3625530728195567,1.3625531514659264,1.362553094007088,1.3625530991003787,1.3625531011074277,1.3625530601508606,1.3625530322044324,1.3625530140995872,1.362553003443091,1.3625530135535067,1.3625530045527918,1.3625530112830362,1.3625529878838705,1.362552966991231,1.3625529357272668,1.362552944335033,1.3625529363209763,1.3625529418071096,1.3625529363155477,1.362552939826673,1.36255293972425,1.3625529396423106],"type":"scatter","xaxis":"x","yaxis":"y"},{"line":{"color":"#FF0234","dash":"dash"},"showlegend":false,"x":[0,300],"y":[1.3625529396423106,1.3625529396423106],"type":"scatter","xaxis":"x","yaxis":"y"},{"line":{"color":"blue"},"mode":"lines","showlegend":false,"x":[0.2725105879284621,0.6167344884696775,0.9609583890108928,1.3051822895521081,1.6494061900933235,1.9936300906345388,2.337853991175754,2.682077891716969,3.0263017922581845,3.3705256927994,3.714749593340615,4.0589734938818305,4.403197394423046,4.747421294964261,5.0916451955054765,5.435869096046692,5.780092996587907,6.124316897129122,6.468540797670338,6.812764698211553],"y":[162.8242962245783,101.01526408670716,89.46135288993884,87.16054672367738,87.8728919510406,89.6867921890343,91.87964253247648,94.14846540715442,96.35724954053526,98.45268141535968,104.74893703818209,106.56426922221893,108.24686092571525,109.80758469796406,111.25787074008375,112.60853341062682,113.86942524151189,115.04937475144422,116.1562507649514,117.19704732413618],"type":"scatter","xaxis":"x2","yaxis":"y2"},{"marker":{"color":"#FF0234","size":10},"mode":"markers","showlegend":false,"x":[1.3625529396423106],"y":[87.14641226203557],"type":"scatter","xaxis":"x2","yaxis":"y2"},{"line":{"color":"#FF0234","dash":"dash"},"mode":"markers+lines","showlegend":false,"x":[0,1.3625529396423106,1.3625529396423106],"y":[87.14641226203557,87.14641226203557,0],"type":"scatter","xaxis":"x2","yaxis":"y2"}],                        {"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}},"xaxis":{"anchor":"y","domain":[0.0,0.45],"title":{"text":"Iteration"}},"yaxis":{"anchor":"x","domain":[0.0,1.0],"title":{"text":"Bandwidth"}},"xaxis2":{"anchor":"y2","domain":[0.55,1.0],"title":{"text":"Bandwidth"}},"yaxis2":{"anchor":"x2","domain":[0.0,1.0],"title":{"text":"Loss"}},"annotations":[{"font":{"size":16},"showarrow":false,"text":"Bandwidth at each gradient descent step","x":0.225,"xanchor":"center","xref":"paper","y":1.0,"yanchor":"bottom","yref":"paper"},{"font":{"size":16},"showarrow":false,"text":"Loss vs bandwidth","x":0.775,"xanchor":"center","xref":"paper","y":1.0,"yanchor":"bottom","yref":"paper"}],"width":900,"height":450},                        {"responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('b515d47d-72b2-4b7c-a54d-6f261669c075');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };                });            </script>        </div>
</div>
</div>
<p>Copare the MSE and MAPE.</p>
<div id="872db2e6" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_absolute_percentage_error</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>y_pred2 <span class="op">=</span> gc2_fit.predict(X_test1)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mean_absolute_percentage_error(y_test1, y_pred2))</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mean_squared_error(y_test1, y_pred2))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.24503637805947015
98.97818710644086</code></pre>
</div>
</div>
<p>Let’s look at the <code>qq-plot</code>.</p>
<div id="08e035b9" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>gc2_fit.draw_learning_curve(y_test<span class="op">=</span>y_test1, fig_type<span class="op">=</span><span class="st">'qq'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>                            <div id="98308470-e8c0-4d0c-9dcd-ef7e4de61605" class="plotly-graph-div" style="height:450px; width:500px;"></div>            <script type="text/javascript">                require(["plotly"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("98308470-e8c0-4d0c-9dcd-ef7e4de61605")) {                    Plotly.newPlot(                        "98308470-e8c0-4d0c-9dcd-ef7e4de61605",                        [{"hovertemplate":"y_test=%{y}<extra></extra>","legendgroup":"","line":{"color":"red","dash":"solid"},"marker":{"symbol":"circle"},"mode":"lines","name":"","orientation":"v","showlegend":false,"x":[107.12908749668411,82.07729820341567,250.68582410503322,-228.20850045088835,-193.60755325508376,151.25473152208022,25.156734317388604,161.78057073873572,26.1031081041485,-128.4305534178685,27.90866808562813,-44.44116020741867,-138.93840475334991,-222.16681537868476,-192.19645427097396,0.9739650548381744,120.66403004876267,84.01493807657121,229.22301842153715,-65.01672019723868,3.5566914863945716,2.5011089169083967,-75.28038724279148,-51.17106492509048,63.9968795674746,-26.858243562563406,-88.62347922757598,125.3897181575711,159.45283298188983,-171.08163655117602,7.167740354736653,169.9866305208371,-45.476216321052725,196.64418560918458,6.916057547879813,-44.9209106885849,123.29161348759706,-237.05627320839048,4.793227605388368,-87.75386811360924,-204.7547493029273,300.5340481865176,36.6923441324542,223.1260158640755,37.57236489689603,-135.1432154129502,-22.09541283219769,-19.38279454211906,129.0570647553141,-131.32815842579072,422.6071726637826,71.56184791930542,117.97216683218622,71.21094747981446,-71.29424209716659,45.42212756418835,-142.2554807700287,240.68718226715367,45.496919732973716,-48.518054418620885,-248.65784662270624,11.069509335539475,72.05254229256354,-286.46158602249164,100.20919875515544,-263.20440044800785,75.54044381008978,-236.9865925366403,105.9176903979468,-134.89918697795054,-114.09922634996403,195.16438655741743,243.78235672220447,88.76976759082784,274.8524100729351,-7.340463168661583,94.42130245825987,129.61495960951078,219.86857083576825,-239.18599334930218,110.97942524958862,-12.68016776339869,-114.54869084590477,176.46149967380933,29.570182914896833,-50.97935587732554,-45.28967086237738,161.93634504078221,103.50214379224467,25.88535522075014,-33.8894128012218,-242.412557476674,-124.26093105060144,53.63679354263188,-43.3246525052849,-107.73746334414028,121.03273399140014,32.712898595689765,-100.75445110417151,58.67157625605954,-7.5825159865063645,76.6688495574999,13.023195942366515,39.90868904854326,-143.19719258661473,-13.71348176850614,60.61226850721811,-148.92705189944328,164.38182521163475,39.83948082067931,-86.61384134539973,120.35300376200641,-45.220565743218586,-104.6998236678622,-18.168293341880986,224.39055775799608,21.351714206857167,-166.77683714386322,-18.661455614473834,180.041691675834,-96.39307795038825,-33.99774184134089,96.04950261192579,18.87728379020152,-74.46124422252004,-21.456455525633885,-0.5333585972357191,-292.1727368917409,-95.19414501049333,17.940734995718827,-146.74593778483134,-151.00119220601815,62.09397266035934,-33.01234848388809,-25.855903663125307,-65.9126992584748,-8.839918780845649,-171.47171556758286,91.32353005610662,-240.08178210488447,219.3848875267175,19.62192020121106,25.88926237217787,1.9749052668889713,-18.538512569557994,-9.315419891495038,58.232711239576645,-119.70655249853377,80.46302077808511,-82.57388667481422,-255.60025925203018,-67.80947386301447,121.4794212995063,13.859804040726456,202.10891958905597,289.33699561903865,-53.84026788510968,147.75853654057175,30.709841161470898,-58.77980031762141,183.16604659565084,50.94542565632875,-36.02360824141309,184.5201050760169,-194.4973680663153,88.09606416062502,121.32323667682479,105.50454975796093,225.55853185642846,-91.78580216896597,-141.88424494072322,-201.60517536543819,-148.28651750873246,203.18360324017928,-195.80732271269335,-17.550815118335144,89.93641158461833,-65.46712045313103,82.92183773273398,-147.73268717843496,22.048591539069932,122.27445002412495,-55.39748189656167,-76.05201303998004,11.380731583762161,-31.744944384425988,-59.96965302532895,67.34534528686478,-19.045494372635954,215.36455175565462,-295.94662032883775,-103.98671227646881,60.23526349529168,76.56216887038755,-125.8529606820959,-52.89758037421899,-82.16104292148653,68.27941549262121,-227.58479803516835,-5.207533381235832],"xaxis":"x","y":[107.12908749668411,82.07729820341567,250.68582410503322,-228.20850045088835,-193.60755325508376,151.25473152208022,25.156734317388604,161.78057073873572,26.1031081041485,-128.4305534178685,27.90866808562813,-44.44116020741867,-138.93840475334991,-222.16681537868476,-192.19645427097396,0.9739650548381744,120.66403004876267,84.01493807657121,229.22301842153715,-65.01672019723868,3.5566914863945716,2.5011089169083967,-75.28038724279148,-51.17106492509048,63.9968795674746,-26.858243562563406,-88.62347922757598,125.3897181575711,159.45283298188983,-171.08163655117602,7.167740354736653,169.9866305208371,-45.476216321052725,196.64418560918458,6.916057547879813,-44.9209106885849,123.29161348759706,-237.05627320839048,4.793227605388368,-87.75386811360924,-204.7547493029273,300.5340481865176,36.6923441324542,223.1260158640755,37.57236489689603,-135.1432154129502,-22.09541283219769,-19.38279454211906,129.0570647553141,-131.32815842579072,422.6071726637826,71.56184791930542,117.97216683218622,71.21094747981446,-71.29424209716659,45.42212756418835,-142.2554807700287,240.68718226715367,45.496919732973716,-48.518054418620885,-248.65784662270624,11.069509335539475,72.05254229256354,-286.46158602249164,100.20919875515544,-263.20440044800785,75.54044381008978,-236.9865925366403,105.9176903979468,-134.89918697795054,-114.09922634996403,195.16438655741743,243.78235672220447,88.76976759082784,274.8524100729351,-7.340463168661583,94.42130245825987,129.61495960951078,219.86857083576825,-239.18599334930218,110.97942524958862,-12.68016776339869,-114.54869084590477,176.46149967380933,29.570182914896833,-50.97935587732554,-45.28967086237738,161.93634504078221,103.50214379224467,25.88535522075014,-33.8894128012218,-242.412557476674,-124.26093105060144,53.63679354263188,-43.3246525052849,-107.73746334414028,121.03273399140014,32.712898595689765,-100.75445110417151,58.67157625605954,-7.5825159865063645,76.6688495574999,13.023195942366515,39.90868904854326,-143.19719258661473,-13.71348176850614,60.61226850721811,-148.92705189944328,164.38182521163475,39.83948082067931,-86.61384134539973,120.35300376200641,-45.220565743218586,-104.6998236678622,-18.168293341880986,224.39055775799608,21.351714206857167,-166.77683714386322,-18.661455614473834,180.041691675834,-96.39307795038825,-33.99774184134089,96.04950261192579,18.87728379020152,-74.46124422252004,-21.456455525633885,-0.5333585972357191,-292.1727368917409,-95.19414501049333,17.940734995718827,-146.74593778483134,-151.00119220601815,62.09397266035934,-33.01234848388809,-25.855903663125307,-65.9126992584748,-8.839918780845649,-171.47171556758286,91.32353005610662,-240.08178210488447,219.3848875267175,19.62192020121106,25.88926237217787,1.9749052668889713,-18.538512569557994,-9.315419891495038,58.232711239576645,-119.70655249853377,80.46302077808511,-82.57388667481422,-255.60025925203018,-67.80947386301447,121.4794212995063,13.859804040726456,202.10891958905597,289.33699561903865,-53.84026788510968,147.75853654057175,30.709841161470898,-58.77980031762141,183.16604659565084,50.94542565632875,-36.02360824141309,184.5201050760169,-194.4973680663153,88.09606416062502,121.32323667682479,105.50454975796093,225.55853185642846,-91.78580216896597,-141.88424494072322,-201.60517536543819,-148.28651750873246,203.18360324017928,-195.80732271269335,-17.550815118335144,89.93641158461833,-65.46712045313103,82.92183773273398,-147.73268717843496,22.048591539069932,122.27445002412495,-55.39748189656167,-76.05201303998004,11.380731583762161,-31.744944384425988,-59.96965302532895,67.34534528686478,-19.045494372635954,215.36455175565462,-295.94662032883775,-103.98671227646881,60.23526349529168,76.56216887038755,-125.8529606820959,-52.89758037421899,-82.16104292148653,68.27941549262121,-227.58479803516835,-5.207533381235832],"yaxis":"y","type":"scatter"},{"hovertemplate":"y_pred=%{x}<br>y_test=%{y}<extra></extra>","legendgroup":"","marker":{"color":"#636efa","symbol":"circle"},"mode":"markers","name":"","orientation":"v","showlegend":false,"x":[102.59500417561223,82.51198129015133,245.55147309296967,-221.9444794435411,-204.6071644200217,149.1997300191376,23.526258942864278,157.63718272176263,23.40102870615637,-123.49069839717228,22.37954600338029,-41.97647309053153,-133.5084780444285,-214.62473912022372,-200.1435622682667,4.036456254072051,117.25357185535262,80.76362335352533,226.35386957944326,-63.59259443962358,-3.489314602466324,-1.3132163969226305,-67.30442560422283,-55.58894679778955,72.47001645776363,-22.400690495735024,-87.13980919245563,129.60128124893293,157.39047265511346,-214.05513557727707,3.851427923255051,159.67677884715087,-44.3744519969202,193.52071020739632,1.7211741621743597,-41.44896577814845,116.1838050249026,-242.11108695272858,5.0188721681522805,-85.86105697772722,-209.51669699992584,295.5926728107438,31.918542477976434,209.16988244910854,30.070255470164398,-131.37582623966279,-12.612758815296715,-17.863358731312722,137.22058055642876,-131.1055980302611,342.12718323988815,77.15908699397458,113.60653548693615,85.52686993161005,-68.3957367286953,43.900442774384736,-149.87563999362703,243.76167171822584,45.494360415296036,-52.03664744875902,-243.92508929132646,11.932753108252133,74.0752966105025,-263.6166656768555,90.61700078904552,-263.9928520094575,77.8789425412618,-238.02001793535788,105.13366124495964,-130.91244531684828,-112.26896176762115,192.7206543997759,244.427912317957,86.45477506591628,274.2963949795256,-2.3022121147188517,92.38446562029478,134.0011340432046,218.30121484906886,-228.55966518754164,109.09394960250926,-6.243712322865343,-117.25519817389532,166.58240026014406,30.1774711030784,-50.79017508044032,-39.3718878986091,158.14516995497263,96.10955413094274,19.530730457527426,-38.46085321688166,-247.48788160053584,-124.5316901939949,51.91189411021498,-38.45818661252364,-106.33670800354379,128.13163669468543,32.41530859274905,-97.77879294460553,66.97949821733286,-4.775095692811985,81.60641477802524,12.113834429969254,38.55870541933183,-137.3272334889592,-10.510572814741227,61.75488220609361,-144.38354940525878,167.3971683581828,44.380631203377,-75.3872790569771,110.52195265009216,-46.315774641859186,-94.66360292976712,-12.172304637756847,213.96389427852307,17.11819069970762,-159.13339473451094,-16.721311634578957,169.13639933391724,-90.20663953040483,-32.25363444327607,90.71976852522378,17.378429945101647,-69.70146151783428,-20.140768588374033,-12.172791666003283,-265.181664619037,-93.54255289830155,12.341402602722425,-160.96118627389424,-158.03779264889354,73.01199625661506,-27.333565516502738,-20.855286242671692,-60.25515990773898,-6.739950495120524,-173.99952905762552,94.83374712580189,-232.05881588868357,219.8811556486839,16.704762097750745,30.176964676724744,5.951121831478574,-14.860381899327862,-5.14169611197567,59.194843537900425,-118.84373653959082,81.72077887571758,-77.76463892264297,-240.6529519758221,-70.1208904091429,118.5974264596814,13.43758078812645,202.6791019253215,294.5681176118837,-50.51413019545231,145.91350744904216,36.08837456575683,-62.388263465902746,192.67368179959945,41.71456322107136,-31.15494891736027,176.6514045030279,-193.09225000405885,84.41510380288531,130.98360169931217,104.58177798930119,224.04056671676202,-90.03827939287021,-98.43536070014969,-204.9623147785765,-151.68066293776178,196.50858296510103,-186.51259745843456,-27.993469203982496,90.36150831389733,-64.51298396931999,82.47968515116546,-104.88813504528596,16.6858543552236,117.00867633675014,-51.585628429760845,-74.26829535962669,9.226988407525734,-29.37698074789426,-56.005913013544486,65.10586941639836,-31.98566914585346,203.48175472292667,-274.11478087676124,-105.80678802207198,57.85777171156533,66.0210560711727,-121.88189347256458,-58.999554183270256,-80.78736988595077,73.11729498610339,-221.9521040530443,-11.549073362056639],"xaxis":"x","y":[107.12908749668411,82.07729820341567,250.68582410503322,-228.20850045088835,-193.60755325508376,151.25473152208022,25.156734317388604,161.78057073873572,26.1031081041485,-128.4305534178685,27.90866808562813,-44.44116020741867,-138.93840475334991,-222.16681537868476,-192.19645427097396,0.9739650548381744,120.66403004876267,84.01493807657121,229.22301842153715,-65.01672019723868,3.5566914863945716,2.5011089169083967,-75.28038724279148,-51.17106492509048,63.9968795674746,-26.858243562563406,-88.62347922757598,125.3897181575711,159.45283298188983,-171.08163655117602,7.167740354736653,169.9866305208371,-45.476216321052725,196.64418560918458,6.916057547879813,-44.9209106885849,123.29161348759706,-237.05627320839048,4.793227605388368,-87.75386811360924,-204.7547493029273,300.5340481865176,36.6923441324542,223.1260158640755,37.57236489689603,-135.1432154129502,-22.09541283219769,-19.38279454211906,129.0570647553141,-131.32815842579072,422.6071726637826,71.56184791930542,117.97216683218622,71.21094747981446,-71.29424209716659,45.42212756418835,-142.2554807700287,240.68718226715367,45.496919732973716,-48.518054418620885,-248.65784662270624,11.069509335539475,72.05254229256354,-286.46158602249164,100.20919875515544,-263.20440044800785,75.54044381008978,-236.9865925366403,105.9176903979468,-134.89918697795054,-114.09922634996403,195.16438655741743,243.78235672220447,88.76976759082784,274.8524100729351,-7.340463168661583,94.42130245825987,129.61495960951078,219.86857083576825,-239.18599334930218,110.97942524958862,-12.68016776339869,-114.54869084590477,176.46149967380933,29.570182914896833,-50.97935587732554,-45.28967086237738,161.93634504078221,103.50214379224467,25.88535522075014,-33.8894128012218,-242.412557476674,-124.26093105060144,53.63679354263188,-43.3246525052849,-107.73746334414028,121.03273399140014,32.712898595689765,-100.75445110417151,58.67157625605954,-7.5825159865063645,76.6688495574999,13.023195942366515,39.90868904854326,-143.19719258661473,-13.71348176850614,60.61226850721811,-148.92705189944328,164.38182521163475,39.83948082067931,-86.61384134539973,120.35300376200641,-45.220565743218586,-104.6998236678622,-18.168293341880986,224.39055775799608,21.351714206857167,-166.77683714386322,-18.661455614473834,180.041691675834,-96.39307795038825,-33.99774184134089,96.04950261192579,18.87728379020152,-74.46124422252004,-21.456455525633885,-0.5333585972357191,-292.1727368917409,-95.19414501049333,17.940734995718827,-146.74593778483134,-151.00119220601815,62.09397266035934,-33.01234848388809,-25.855903663125307,-65.9126992584748,-8.839918780845649,-171.47171556758286,91.32353005610662,-240.08178210488447,219.3848875267175,19.62192020121106,25.88926237217787,1.9749052668889713,-18.538512569557994,-9.315419891495038,58.232711239576645,-119.70655249853377,80.46302077808511,-82.57388667481422,-255.60025925203018,-67.80947386301447,121.4794212995063,13.859804040726456,202.10891958905597,289.33699561903865,-53.84026788510968,147.75853654057175,30.709841161470898,-58.77980031762141,183.16604659565084,50.94542565632875,-36.02360824141309,184.5201050760169,-194.4973680663153,88.09606416062502,121.32323667682479,105.50454975796093,225.55853185642846,-91.78580216896597,-141.88424494072322,-201.60517536543819,-148.28651750873246,203.18360324017928,-195.80732271269335,-17.550815118335144,89.93641158461833,-65.46712045313103,82.92183773273398,-147.73268717843496,22.048591539069932,122.27445002412495,-55.39748189656167,-76.05201303998004,11.380731583762161,-31.744944384425988,-59.96965302532895,67.34534528686478,-19.045494372635954,215.36455175565462,-295.94662032883775,-103.98671227646881,60.23526349529168,76.56216887038755,-125.8529606820959,-52.89758037421899,-82.16104292148653,68.27941549262121,-227.58479803516835,-5.207533381235832],"yaxis":"y","type":"scatter"}],                        {"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}},"title":{"text":"QQplot of predicted and actual values","x":0.5,"y":0.925},"width":500,"height":450,"xaxis":{"title":{"text":"Prediction"}},"yaxis":{"title":{"text":"Actual target"}}},                        {"responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('98308470-e8c0-4d0c-9dcd-ef7e4de61605');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };                });            </script>        </div>
</div>
</div>
</section>
</section>
<section id="mixcobraregressor-with-non-default-parameters" class="level3">
<h3 class="anchored" data-anchor-id="mixcobraregressor-with-non-default-parameters"><code>MixCOBRARegressor</code> with non-default parameters</h3>
<p><code>MixCOBRARegressor</code> offers various options to enhance the performance of the method. By default, grid search algorithm is used to estimate the parameters <span class="math inline">\((\alpha, \beta)\)</span>, however, gradient descent algorithm can also be used to optimize the method by setting <code>opt_method = "grad"</code> as shown in case of one bandwidth parameter above. Moveover, you can control the hyperparameters of the basic estimators to enhance the aggregation performance just like in <a href="https://hassothea.github.io/files/CodesPhD/gradientcobra_doc.html"><code>GradientCOBRA</code></a> method. This can be done as follows:</p>
<ul>
<li><strong>learning_rate</strong> : control the learning rate of gradient descent in estimating the bandwidth parameter</li>
<li><strong>speed</strong> : the speed of the learning rate.</li>
<li><strong>kernel</strong> : the kernel function used for the aggregation</li>
<li><strong>opt_method</strong> : the optimiztaion algorithm for estimating the bandwidth. It can be gradient descent (<code>grad</code>) or grid search (<code>grid</code>).</li>
<li><strong>kernel</strong> : kernel function which is <code>radial</code> by default. It must be an element of <code>['exponential', 'gaussian', 'radial', 'cauchy', 'reverse_cosh', 'epanechnikov'</code>, <code>'biweight', 'triweight', 'triangular']</code>.</li>
<li><strong>alpha_list</strong> : list or array to search for <span class="math inline">\(\alpha\)</span>.</li>
<li><strong>beta_list</strong> : list or array to search for <span class="math inline">\(\beta\)</span>.</li>
<li><strong>bandwidth_list</strong> : : list or array to search for single bandwidth parameter <span class="math inline">\(h\)</span> instead of <span class="math inline">\((\alpha, \beta)\)</span>. To do this, we have to set <code>one_parameter = True</code> when fitting the method.</li>
<li><strong>max_iter</strong> : maximum iteration in gradient descent.</li>
<li><strong>loss_function</strong> : control the type of loss function used for optimizing the bandwidth.</li>
<li><strong>opt_params</strong> : control the optimization algorithm such as adjusting <code>n_cv</code>, <code>start</code>, <code>n_tries</code>…</li>
<li><strong>estiamtor_list</strong> : the list of basic estimators used for the aggregation.</li>
<li><strong>estimator_params</strong> : controlling the hyperparameters of the basic estimators. It must be a dictionary with <code>(key, dict) = (estimator, dict)</code>, i.e.&nbsp;the key must be the name of the basic estimator, and the value is a dictionary containing its hyperparamaters.</li>
</ul>
<p>We create another object <code>gc3</code> with non-default parameters, then fit it to the same training data as in the previous example.</p>
<div id="2488a550" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>gc3 <span class="op">=</span> MixCOBRARegressor(learning_rate<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>                    speed<span class="op">=</span><span class="st">"linear"</span>,</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>                    kernel<span class="op">=</span><span class="st">'radial'</span>,</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>                    opt_method<span class="op">=</span><span class="st">'grad'</span>,</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>                    loss_function<span class="op">=</span><span class="st">"weighted_mse"</span>,</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>                    max_iter<span class="op">=</span><span class="dv">300</span>,</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>                    estimator_list<span class="op">=</span>[<span class="st">'random_forest'</span>, </span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">'adaboost'</span>, </span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">'knn'</span>, </span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">'svm'</span>, </span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">'lasso'</span>, </span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">'ridge'</span>],</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>                    estimator_params<span class="op">=</span>{</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>                        <span class="st">'random_forest'</span> : {</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>                            <span class="st">'n_estimators'</span> : <span class="dv">300</span>,</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>                            <span class="st">'min_samples_leaf'</span> : <span class="dv">10</span>},</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>                        <span class="st">'adaboost'</span> : {</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>                            <span class="st">'n_estimators'</span> : <span class="dv">300</span>,</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>                            <span class="st">'max_depth'</span> : <span class="dv">10</span>},</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>                        <span class="st">'knn'</span> : {</span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>                            <span class="st">'n_neighbors'</span> : <span class="dv">30</span>},</span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>                            <span class="st">'svm'</span> : {<span class="st">'C'</span> : <span class="dv">7</span>}</span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>                    })</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>gc3_fit <span class="op">=</span> gc3.fit(X_train1, y_train1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    * Gradient descent of two parameters with radial kernel is implemented...
        ~ Initial t = 0:        ~ (alpha, beta): (1.000, 3.775)     ~ |gradient|_1: 0.252    ~ threshold: 1e-05
        ~     Iteration: 1  ~ (alpha, beta): (1.000, 3.775)     ~ |gradient|_1: 0.072   ~ stopping criterion: 0.126214      ~     Iteration: 2  ~ (alpha, beta): (1.000, 3.775)     ~ |gradient|_1: 0.072   ~ stopping criterion: 0.136685      ~     Iteration: 3  ~ (alpha, beta): (1.000, 3.775)     ~ |gradient|_1: 0.072   ~ stopping criterion: 0.147157      ~     Iteration: 4  ~ (alpha, beta): (1.000, 3.775)     ~ |gradient|_1: 0.072   ~ stopping criterion: 0.157628      ~     Iteration: 5  ~ (alpha, beta): (0.885, 4.060)     ~ |gradient|_1: 0.011   ~ stopping criterion: 0.126214      ~     Iteration: 6  ~ (alpha, beta): (0.863, 3.418)     ~ |gradient|_1: -0.287  ~ stopping criterion: 0.167818      ~     Iteration: 7  ~ (alpha, beta): (1.544, 3.346)     ~ |gradient|_1: 0.082   ~ stopping criterion: 0.162011      ~     Iteration: 8  ~ (alpha, beta): (1.361, 3.572)     ~ |gradient|_1: 0.053   ~ stopping criterion: 0.092113      ~     Iteration: 9  ~ (alpha, beta): (1.253, 3.096)     ~ |gradient|_1: 0.105   ~ stopping criterion: 0.143997      ~     Iteration: 10     ~ (alpha, beta): (1.013, 2.692)     ~ |gradient|_1: -0.115  ~ stopping criterion: 0.163432      ~     Iteration: 11     ~ (alpha, beta): (1.304, 2.855)     ~ |gradient|_1: 0.166   ~ stopping criterion: 0.097541      ~     Iteration: 12     ~ (alpha, beta): (0.933, 2.590)     ~ |gradient|_1: 0.215   ~ stopping criterion: 0.157144      ~     Iteration: 13     ~ (alpha, beta): (0.514, 3.863)     ~ |gradient|_1: -0.036  ~ stopping criterion: 0.516204      ~     Iteration: 14     ~ (alpha, beta): (0.591, 4.092)     ~ |gradient|_1: 0.018   ~ stopping criterion: 0.103005      ~     Iteration: 15     ~ (alpha, beta): (0.559, 4.097)     ~ |gradient|_1: -0.046  ~ stopping criterion: 0.010631      ~     Iteration: 16     ~ (alpha, beta): (0.631, 4.180)     ~ |gradient|_1: 0.041   ~ stopping criterion: 0.049579      ~     Iteration: 17     ~ (alpha, beta): (0.577, 4.406)     ~ |gradient|_1: -0.008  ~ stopping criterion: 0.088228      ~     Iteration: 18     ~ (alpha, beta): (0.586, 3.836)     ~ |gradient|_1: 0.129   ~ stopping criterion: 0.165476      ~     Iteration: 19     ~ (alpha, beta): (0.463, 3.541)     ~ |gradient|_1: -0.173  ~ stopping criterion: 0.162863      ~     Iteration: 20     ~ (alpha, beta): (0.602, 3.249)     ~ |gradient|_1: -0.030  ~ stopping criterion: 0.178933      ~     Iteration: 21     ~ (alpha, beta): (0.623, 3.509)     ~ |gradient|_1: 0.068   ~ stopping criterion: 0.092886      ~     Iteration: 22     ~ (alpha, beta): (0.574, 3.234)     ~ |gradient|_1: 0.168   ~ stopping criterion: 0.132553      ~     Iteration: 23     ~ (alpha, beta): (0.473, 3.789)     ~ |gradient|_1: -0.196  ~ stopping criterion: 0.321406      ~     Iteration: 24     ~ (alpha, beta): (0.596, 3.810)     ~ |gradient|_1: -0.195  ~ stopping criterion: 0.108196      ~     Iteration: 25     ~ (alpha, beta): (0.698, 3.452)     ~ |gradient|_1: 0.082   ~ stopping criterion: 0.272678      ~     Iteration: 26     ~ (alpha, beta): (0.653, 3.444)     ~ |gradient|_1: -0.006  ~ stopping criterion: 0.045820      ~     Iteration: 27     ~ (alpha, beta): (0.656, 3.630)     ~ |gradient|_1: 0.065   ~ stopping criterion: 0.107919      ~     Iteration: 28     ~ (alpha, beta): (0.631, 3.442)     ~ |gradient|_1: 0.033   ~ stopping criterion: 0.160378      ~     Iteration: 29     ~ (alpha, beta): (0.621, 3.425)     ~ |gradient|_1: 0.109   ~ stopping criterion: 0.030255      ~     Iteration: 30     ~ (alpha, beta): (0.586, 3.540)     ~ |gradient|_1: -0.017  ~ stopping criterion: 0.145288      ~     Iteration: 31     ~ (alpha, beta): (0.592, 3.745)     ~ |gradient|_1: 0.151   ~ stopping criterion: 0.205198      ~     Iteration: 32     ~ (alpha, beta): (0.550, 3.830)     ~ |gradient|_1: 0.079   ~ stopping criterion: 0.153860      ~     Iteration: 33     ~ (alpha, beta): (0.532, 3.789)     ~ |gradient|_1: 0.420   ~ stopping criterion: 0.076099      ~     Iteration: 34     ~ (alpha, beta): (0.433, 3.780)     ~ |gradient|_1: 0.177   ~ stopping criterion: 0.219359      ~     Iteration: 35     ~ (alpha, beta): (0.390, 3.827)     ~ |gradient|_1: 0.259   ~ stopping criterion: 0.137842      ~     Iteration: 36     ~ (alpha, beta): (0.325, 3.884)     ~ |gradient|_1: -0.047  ~ stopping criterion: 0.203101      ~     Iteration: 37     ~ (alpha, beta): (0.337, 3.854)     ~ |gradient|_1: 0.013   ~ stopping criterion: 0.061793      ~     Iteration: 38     ~ (alpha, beta): (0.335, 3.868)     ~ |gradient|_1: -0.023  ~ stopping criterion: 0.027657      ~     Iteration: 39     ~ (alpha, beta): (0.339, 3.895)     ~ |gradient|_1: -0.143  ~ stopping criterion: 0.060838      ~     Iteration: 40     ~ (alpha, beta): (0.359, 3.958)     ~ |gradient|_1: 0.005   ~ stopping criterion: 0.185755      ~     Iteration: 41     ~ (alpha, beta): (0.358, 3.826)     ~ |gradient|_1: -0.241  ~ stopping criterion: 0.233741      ~     Iteration: 42     ~ (alpha, beta): (0.387, 3.823)     ~ |gradient|_1: 0.285   ~ stopping criterion: 0.127676      ~     Iteration: 43     ~ (alpha, beta): (0.359, 3.798)     ~ |gradient|_1: -0.078  ~ stopping criterion: 0.193461      ~     Iteration: 44     ~ (alpha, beta): (0.365, 3.761)     ~ |gradient|_1: -0.173  ~ stopping criterion: 0.114544      ~     Iteration: 45     ~ (alpha, beta): (0.377, 3.700)     ~ |gradient|_1: 0.085   ~ stopping criterion: 0.208220      ~     Iteration: 46     ~ (alpha, beta): (0.371, 3.696)     ~ |gradient|_1: 0.013   ~ stopping criterion: 0.050778      ~     Iteration: 47     ~ (alpha, beta): (0.370, 3.624)     ~ |gradient|_1: 0.047   ~ stopping criterion: 0.142680      ~     Iteration: 48     ~ (alpha, beta): (0.368, 3.530)     ~ |gradient|_1: -0.001  ~ stopping criterion: 0.199648      ~     Iteration: 49     ~ (alpha, beta): (0.368, 3.419)     ~ |gradient|_1: 0.019   ~ stopping criterion: 0.202105      ~     Iteration: 50     ~ (alpha, beta): (0.367, 3.416)     ~ |gradient|_1: -0.278  ~ stopping criterion: 0.015493      ~     Iteration: 51     ~ (alpha, beta): (0.378, 3.408)     ~ |gradient|_1: -0.006  ~ stopping criterion: 0.153362      ~     Iteration: 52     ~ (alpha, beta): (0.378, 3.410)     ~ |gradient|_1: 0.132   ~ stopping criterion: 0.006942      ~     Iteration: 53     ~ (alpha, beta): (0.374, 3.374)     ~ |gradient|_1: 0.106   ~ stopping criterion: 0.142465      ~     Iteration: 54     ~ (alpha, beta): (0.371, 3.394)     ~ |gradient|_1: -0.049  ~ stopping criterion: 0.105722      ~     Iteration: 55     ~ (alpha, beta): (0.372, 3.353)     ~ |gradient|_1: -0.131  ~ stopping criterion: 0.154400      ~     Iteration: 56     ~ (alpha, beta): (0.375, 3.420)     ~ |gradient|_1: 0.260   ~ stopping criterion: 0.325186      ~     Iteration: 57     ~ (alpha, beta): (0.369, 3.428)     ~ |gradient|_1: -0.158  ~ stopping criterion: 0.170571      ~     Iteration: 58     ~ (alpha, beta): (0.372, 3.418)     ~ |gradient|_1: 0.130   ~ stopping criterion: 0.126227      ~     Iteration: 59     ~ (alpha, beta): (0.370, 3.402)     ~ |gradient|_1: -0.062  ~ stopping criterion: 0.158846      ~     Iteration: 60     ~ (alpha, beta): (0.371, 3.394)     ~ |gradient|_1: 0.066   ~ stopping criterion: 0.077045      ~     Iteration: 61     ~ (alpha, beta): (0.370, 3.387)     ~ |gradient|_1: 0.004   ~ stopping criterion: 0.069263      ~     Iteration: 62     ~ (alpha, beta): (0.370, 3.359)     ~ |gradient|_1: -0.472  ~ stopping criterion: 0.155756      ~     Iteration: 63     ~ (alpha, beta): (0.374, 3.345)     ~ |gradient|_1: 0.157   ~ stopping criterion: 0.312603      ~     Iteration: 64     ~ (alpha, beta): (0.373, 3.339)     ~ |gradient|_1: -0.354  ~ stopping criterion: 0.109777      ~     Iteration: 65     ~ (alpha, beta): (0.375, 3.333)     ~ |gradient|_1: -0.205  ~ stopping criterion: 0.209799      ~     Iteration: 66     ~ (alpha, beta): (0.376, 3.327)     ~ |gradient|_1: 0.238   ~ stopping criterion: 0.130167      ~     Iteration: 67     ~ (alpha, beta): (0.375, 3.304)     ~ |gradient|_1: -0.104  ~ stopping criterion: 0.239188      ~     Iteration: 68     ~ (alpha, beta): (0.375, 3.296)     ~ |gradient|_1: -0.113  ~ stopping criterion: 0.087199      ~     Iteration: 69     ~ (alpha, beta): (0.375, 3.297)     ~ |gradient|_1: -0.058  ~ stopping criterion: 0.061475      ~     Iteration: 70     ~ (alpha, beta): (0.376, 3.308)     ~ |gradient|_1: 0.005   ~ stopping criterion: 0.094929      ~     Iteration: 71     ~ (alpha, beta): (0.376, 3.312)     ~ |gradient|_1: -0.059  ~ stopping criterion: 0.023598      ~     Iteration: 72     ~ (alpha, beta): (0.376, 3.316)     ~ |gradient|_1: -0.089  ~ stopping criterion: 0.051149      ~     Iteration: 73     ~ (alpha, beta): (0.376, 3.331)     ~ |gradient|_1: 0.235   ~ stopping criterion: 0.131322      ~     Iteration: 74     ~ (alpha, beta): (0.375, 3.310)     ~ |gradient|_1: -0.040  ~ stopping criterion: 0.232815      ~     Iteration: 75     ~ (alpha, beta): (0.375, 3.311)     ~ |gradient|_1: 0.309   ~ stopping criterion: 0.027130      ~     Iteration: 76     ~ (alpha, beta): (0.375, 3.313)     ~ |gradient|_1: 0.302   ~ stopping criterion: 0.169384      ~     Iteration: 77     ~ (alpha, beta): (0.375, 3.299)     ~ |gradient|_1: -0.105  ~ stopping criterion: 0.270599      ~     Iteration: 78     ~ (alpha, beta): (0.375, 3.297)     ~ |gradient|_1: 0.276   ~ stopping criterion: 0.074094      ~     Iteration: 79     ~ (alpha, beta): (0.375, 3.281)     ~ |gradient|_1: -0.026  ~ stopping criterion: 0.305038      ~     Iteration: 80     ~ (alpha, beta): (0.375, 3.270)     ~ |gradient|_1: 0.111   ~ stopping criterion: 0.127982      ~     Iteration: 81     ~ (alpha, beta): (0.375, 3.269)     ~ |gradient|_1: 0.132   ~ stopping criterion: 0.061687      ~     Iteration: 82     ~ (alpha, beta): (0.374, 3.261)     ~ |gradient|_1: 0.081   ~ stopping criterion: 0.148038      ~     Iteration: 83     ~ (alpha, beta): (0.374, 3.278)     ~ |gradient|_1: 0.044   ~ stopping criterion: 0.202977      ~     Iteration: 84     ~ (alpha, beta): (0.374, 3.287)     ~ |gradient|_1: 0.056   ~ stopping criterion: 0.136441      ~     Iteration: 85     ~ (alpha, beta): (0.374, 3.273)     ~ |gradient|_1: 0.066   ~ stopping criterion: 0.190809      ~     Iteration: 86     ~ (alpha, beta): (0.374, 3.273)     ~ |gradient|_1: 0.038   ~ stopping criterion: 0.035906      ~     Iteration: 87     ~ (alpha, beta): (0.374, 3.256)     ~ |gradient|_1: 0.040   ~ stopping criterion: 0.280325      ~     Iteration: 88     ~ (alpha, beta): (0.374, 3.259)     ~ |gradient|_1: -0.118  ~ stopping criterion: 0.062702      ~     Iteration: 89     ~ (alpha, beta): (0.374, 3.256)     ~ |gradient|_1: 0.092   ~ stopping criterion: 0.110999      ~     Iteration: 90     ~ (alpha, beta): (0.374, 3.252)     ~ |gradient|_1: 0.065   ~ stopping criterion: 0.116948      ~     Iteration: 91     ~ (alpha, beta): (0.374, 3.247)     ~ |gradient|_1: 0.188   ~ stopping criterion: 0.164687      ~     Iteration: 92     ~ (alpha, beta): (0.374, 3.249)     ~ |gradient|_1: -0.330  ~ stopping criterion: 0.150298      ~     Iteration: 93     ~ (alpha, beta): (0.374, 3.248)     ~ |gradient|_1: 0.110   ~ stopping criterion: 0.181729      ~     Iteration: 94     ~ (alpha, beta): (0.374, 3.247)     ~ |gradient|_1: -0.125  ~ stopping criterion: 0.100241      ~     Iteration: 95     ~ (alpha, beta): (0.374, 3.245)     ~ |gradient|_1: -0.141  ~ stopping criterion: 0.130554      ~     Iteration: 96     ~ (alpha, beta): (0.374, 3.247)     ~ |gradient|_1: 0.007   ~ stopping criterion: 0.117068      ~     Iteration: 97     ~ (alpha, beta): (0.374, 3.248)     ~ |gradient|_1: 0.140   ~ stopping criterion: 0.058623      ~     Iteration: 98     ~ (alpha, beta): (0.374, 3.246)     ~ |gradient|_1: 0.180   ~ stopping criterion: 0.128249      ~     Iteration: 99     ~ (alpha, beta): (0.374, 3.248)     ~ |gradient|_1: 0.108   ~ stopping criterion: 0.164499      ~     Iteration: 100    ~ (alpha, beta): (0.374, 3.248)     ~ |gradient|_1: 0.165   ~ stopping criterion: 0.079171      ~     Iteration: 101    ~ (alpha, beta): (0.374, 3.247)     ~ |gradient|_1: -0.154  ~ stopping criterion: 0.154197      ~     Iteration: 102    ~ (alpha, beta): (0.374, 3.247)     ~ |gradient|_1: 0.001   ~ stopping criterion: 0.091087      ~     Iteration: 103    ~ (alpha, beta): (0.374, 3.246)     ~ |gradient|_1: 0.155   ~ stopping criterion: 0.051729      ~     Iteration: 104    ~ (alpha, beta): (0.374, 3.244)     ~ |gradient|_1: -0.179  ~ stopping criterion: 0.237657      ~     Iteration: 105    ~ (alpha, beta): (0.374, 3.244)     ~ |gradient|_1: -0.229  ~ stopping criterion: 0.096965      ~     Iteration: 106    ~ (alpha, beta): (0.374, 3.245)     ~ |gradient|_1: 0.180   ~ stopping criterion: 0.193956      ~     Iteration: 107    ~ (alpha, beta): (0.374, 3.246)     ~ |gradient|_1: 0.017   ~ stopping criterion: 0.162595      ~     Iteration: 108    ~ (alpha, beta): (0.374, 3.246)     ~ |gradient|_1: -0.090  ~ stopping criterion: 0.012144      ~     Iteration: 109    ~ (alpha, beta): (0.374, 3.249)     ~ |gradient|_1: 0.118   ~ stopping criterion: 0.341650      ~     Iteration: 110    ~ (alpha, beta): (0.374, 3.249)     ~ |gradient|_1: 0.020   ~ stopping criterion: 0.153151      ~     Iteration: 111    ~ (alpha, beta): (0.374, 3.249)     ~ |gradient|_1: -0.138  ~ stopping criterion: 0.039031      ~     Iteration: 112    ~ (alpha, beta): (0.374, 3.250)     ~ |gradient|_1: -0.021  ~ stopping criterion: 0.159269      ~     Iteration: 113    ~ (alpha, beta): (0.374, 3.250)     ~ |gradient|_1: 0.235   ~ stopping criterion: 0.057307      ~     Iteration: 114    ~ (alpha, beta): (0.374, 3.251)     ~ |gradient|_1: 0.187   ~ stopping criterion: 0.180171      ~     Iteration: 115    ~ (alpha, beta): (0.374, 3.250)     ~ |gradient|_1: 0.210   ~ stopping criterion: 0.157740      ~     Iteration: 116    ~ (alpha, beta): (0.374, 3.251)     ~ |gradient|_1: -0.227  ~ stopping criterion: 0.163074      ~     Iteration: 117    ~ (alpha, beta): (0.374, 3.251)     ~ |gradient|_1: -0.082  ~ stopping criterion: 0.151492      ~     Iteration: 118    ~ (alpha, beta): (0.374, 3.252)     ~ |gradient|_1: 0.205   ~ stopping criterion: 0.163170      ~     Iteration: 119    ~ (alpha, beta): (0.374, 3.252)     ~ |gradient|_1: -0.090  ~ stopping criterion: 0.219772      ~     Iteration: 120    ~ (alpha, beta): (0.374, 3.253)     ~ |gradient|_1: -0.094  ~ stopping criterion: 0.110053      ~     Iteration: 121    ~ (alpha, beta): (0.374, 3.252)     ~ |gradient|_1: -0.285  ~ stopping criterion: 0.083155      ~     Iteration: 122    ~ (alpha, beta): (0.374, 3.252)     ~ |gradient|_1: -0.202  ~ stopping criterion: 0.169795      ~     Iteration: 123    ~ (alpha, beta): (0.374, 3.253)     ~ |gradient|_1: 0.177   ~ stopping criterion: 0.148330      ~     Iteration: 124    ~ (alpha, beta): (0.374, 3.253)     ~ |gradient|_1: 0.158   ~ stopping criterion: 0.098388      ~     Iteration: 125    ~ (alpha, beta): (0.374, 3.253)     ~ |gradient|_1: -0.089  ~ stopping criterion: 0.097286      ~     Iteration: 126    ~ (alpha, beta): (0.374, 3.253)     ~ |gradient|_1: 0.203   ~ stopping criterion: 0.081012      ~     Iteration: 127    ~ (alpha, beta): (0.374, 3.253)     ~ |gradient|_1: -0.103  ~ stopping criterion: 0.207341      ~     Iteration: 128    ~ (alpha, beta): (0.374, 3.253)     ~ |gradient|_1: 0.255   ~ stopping criterion: 0.112650      ~     Iteration: 129    ~ (alpha, beta): (0.374, 3.253)     ~ |gradient|_1: 0.252   ~ stopping criterion: 0.147016      ~     Iteration: 130    ~ (alpha, beta): (0.374, 3.253)     ~ |gradient|_1: 0.195   ~ stopping criterion: 0.177235      ~     Iteration: 131    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.091  ~ stopping criterion: 0.345077      ~     Iteration: 132    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.025   ~ stopping criterion: 0.056017      ~     Iteration: 133    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.073   ~ stopping criterion: 0.026693      ~     Iteration: 134    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.241  ~ stopping criterion: 0.146166      ~     Iteration: 135    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.151   ~ stopping criterion: 0.123284      ~     Iteration: 136    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.168062      ~     Iteration: 137    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.309  ~ stopping criterion: 0.174703      ~     Iteration: 138    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.023   ~ stopping criterion: 0.287186      ~     Iteration: 139    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.115   ~ stopping criterion: 0.062519      ~     Iteration: 140    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.256  ~ stopping criterion: 0.128105      ~     Iteration: 141    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.196   ~ stopping criterion: 0.278856      ~     Iteration: 142    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.137   ~ stopping criterion: 0.103505      ~     Iteration: 143    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.149   ~ stopping criterion: 0.092055      ~     Iteration: 144    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.125  ~ stopping criterion: 0.096112      ~     Iteration: 145    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.168  ~ stopping criterion: 0.213644      ~     Iteration: 146    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.196   ~ stopping criterion: 0.227230      ~     Iteration: 147    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.177   ~ stopping criterion: 0.165512      ~     Iteration: 148    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.219   ~ stopping criterion: 0.101222      ~     Iteration: 149    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.150  ~ stopping criterion: 0.188767      ~     Iteration: 150    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.236   ~ stopping criterion: 0.083937      ~     Iteration: 151    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.043   ~ stopping criterion: 0.121120      ~     Iteration: 152    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.157   ~ stopping criterion: 0.035724      ~     Iteration: 153    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.155   ~ stopping criterion: 0.110750      ~     Iteration: 154    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.288  ~ stopping criterion: 0.090326      ~     Iteration: 155    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.147   ~ stopping criterion: 0.361548      ~     Iteration: 156    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.080   ~ stopping criterion: 0.143850      ~     Iteration: 157    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.223   ~ stopping criterion: 0.078862      ~     Iteration: 158    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.171   ~ stopping criterion: 0.170337      ~     Iteration: 159    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.138   ~ stopping criterion: 0.136228      ~     Iteration: 160    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.161   ~ stopping criterion: 0.118624      ~     Iteration: 161    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.140  ~ stopping criterion: 0.179159      ~     Iteration: 162    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.261   ~ stopping criterion: 0.190258      ~     Iteration: 163    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.019   ~ stopping criterion: 0.183705      ~     Iteration: 164    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.310  ~ stopping criterion: 0.264581      ~     Iteration: 165    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.137  ~ stopping criterion: 0.178501      ~     Iteration: 166    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.179   ~ stopping criterion: 0.090032      ~     Iteration: 167    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.241  ~ stopping criterion: 0.175522      ~     Iteration: 168    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.032   ~ stopping criterion: 0.148129      ~     Iteration: 169    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.101  ~ stopping criterion: 0.162556      ~     Iteration: 170    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.133   ~ stopping criterion: 0.081547      ~     Iteration: 171    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.050   ~ stopping criterion: 0.241056      ~     Iteration: 172    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.184   ~ stopping criterion: 0.077615      ~     Iteration: 173    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.193   ~ stopping criterion: 0.095902      ~     Iteration: 174    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.210   ~ stopping criterion: 0.140475      ~     Iteration: 175    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.149  ~ stopping criterion: 0.161575      ~     Iteration: 176    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.209   ~ stopping criterion: 0.124403      ~     Iteration: 177    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.070   ~ stopping criterion: 0.198097      ~     Iteration: 178    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.224   ~ stopping criterion: 0.097768      ~     Iteration: 179    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.239  ~ stopping criterion: 0.114280      ~     Iteration: 180    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.103   ~ stopping criterion: 0.124344      ~     Iteration: 181    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.152   ~ stopping criterion: 0.132989      ~     Iteration: 182    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.153   ~ stopping criterion: 0.078174      ~     Iteration: 183    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.146   ~ stopping criterion: 0.164562      ~     Iteration: 184    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.062   ~ stopping criterion: 0.085225      ~     Iteration: 185    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.231   ~ stopping criterion: 0.111634      ~     Iteration: 186    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.236  ~ stopping criterion: 0.150047      ~     Iteration: 187    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.019   ~ stopping criterion: 0.194587      ~     Iteration: 188    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.143  ~ stopping criterion: 0.018172      ~     Iteration: 189    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.066   ~ stopping criterion: 0.158775      ~     Iteration: 190    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.227  ~ stopping criterion: 0.087800      ~     Iteration: 191    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.198   ~ stopping criterion: 0.155446      ~     Iteration: 192    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.185   ~ stopping criterion: 0.206178      ~     Iteration: 193    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.186  ~ stopping criterion: 0.109789      ~     Iteration: 194    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.202   ~ stopping criterion: 0.182458      ~     Iteration: 195    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.245  ~ stopping criterion: 0.103278      ~     Iteration: 196    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.147   ~ stopping criterion: 0.131835      ~     Iteration: 197    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.130  ~ stopping criterion: 0.080781      ~     Iteration: 198    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.225   ~ stopping criterion: 0.142275      ~     Iteration: 199    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.043   ~ stopping criterion: 0.185646      ~     Iteration: 200    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.023  ~ stopping criterion: 0.026905      ~     Iteration: 201    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.010   ~ stopping criterion: 0.068304      ~     Iteration: 202    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.215   ~ stopping criterion: 0.076434      ~     Iteration: 203    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.186   ~ stopping criterion: 0.131881      ~     Iteration: 204    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.191   ~ stopping criterion: 0.147627      ~     Iteration: 205    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.135  ~ stopping criterion: 0.115425      ~     Iteration: 206    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.176   ~ stopping criterion: 0.081343      ~     Iteration: 207    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.246  ~ stopping criterion: 0.106709      ~     Iteration: 208    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.193   ~ stopping criterion: 0.182675      ~     Iteration: 209    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.265  ~ stopping criterion: 0.184309      ~     Iteration: 210    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.269  ~ stopping criterion: 0.146201      ~     Iteration: 211    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.175  ~ stopping criterion: 0.217348      ~     Iteration: 212    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.019   ~ stopping criterion: 0.180842      ~     Iteration: 213    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.166   ~ stopping criterion: 0.151766      ~     Iteration: 214    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.130  ~ stopping criterion: 0.176663      ~     Iteration: 215    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.072   ~ stopping criterion: 0.126698      ~     Iteration: 216    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.130  ~ stopping criterion: 0.096947      ~     Iteration: 217    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.127133      ~     Iteration: 218    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.096  ~ stopping criterion: 0.121867      ~     Iteration: 219    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.219   ~ stopping criterion: 0.112325      ~     Iteration: 220    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.162899      ~     Iteration: 221    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.050   ~ stopping criterion: 0.169820      ~     Iteration: 222    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.186   ~ stopping criterion: 0.031121      ~     Iteration: 223    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.201   ~ stopping criterion: 0.098825      ~     Iteration: 224    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.201   ~ stopping criterion: 0.106560      ~     Iteration: 225    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.203   ~ stopping criterion: 0.105048      ~     Iteration: 226    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.395  ~ stopping criterion: 0.170049      ~     Iteration: 227    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.087   ~ stopping criterion: 0.250521      ~     Iteration: 228    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.087   ~ stopping criterion: 0.045698      ~     Iteration: 229    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.087   ~ stopping criterion: 0.045732      ~     Iteration: 230    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.100   ~ stopping criterion: 0.051406      ~     Iteration: 231    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.230   ~ stopping criterion: 0.058747      ~     Iteration: 232    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.208   ~ stopping criterion: 0.123539      ~     Iteration: 233    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.197   ~ stopping criterion: 0.113053      ~     Iteration: 234    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.195   ~ stopping criterion: 0.107663      ~     Iteration: 235    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.075   ~ stopping criterion: 0.177288      ~     Iteration: 236    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.053   ~ stopping criterion: 0.040952      ~     Iteration: 237    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.053   ~ stopping criterion: 0.030613      ~     Iteration: 238    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.395  ~ stopping criterion: 0.080629      ~     Iteration: 239    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.197   ~ stopping criterion: 0.250521      ~     Iteration: 240    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: 0.195   ~ stopping criterion: 0.107644      ~     Iteration: 241    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.258  ~ stopping criterion: 0.177476      ~     Iteration: 242    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.249  ~ stopping criterion: 0.186456      ~     Iteration: 243    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.258  ~ stopping criterion: 0.204984      ~     Iteration: 244    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.375  ~ stopping criterion: 0.187994      ~     Iteration: 245    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.249  ~ stopping criterion: 0.240358      ~     Iteration: 246    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.264  ~ stopping criterion: 0.204983      ~     Iteration: 247    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.365  ~ stopping criterion: 0.184798      ~     Iteration: 248    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.249  ~ stopping criterion: 0.237328      ~     Iteration: 249    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.375  ~ stopping criterion: 0.204984      ~     Iteration: 250    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.240409      ~     Iteration: 251    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.249  ~ stopping criterion: 0.169820      ~     Iteration: 252    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.365  ~ stopping criterion: 0.205018      ~     Iteration: 253    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.237328      ~     Iteration: 254    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.249  ~ stopping criterion: 0.169922      ~     Iteration: 255    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.205018      ~     Iteration: 256    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.169820      ~     Iteration: 257    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.229  ~ stopping criterion: 0.195539      ~     Iteration: 258    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.169338      ~     Iteration: 259    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.169922      ~     Iteration: 260    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.169928      ~     Iteration: 261    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.195190      ~     Iteration: 262    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.169922      ~     Iteration: 263    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.195383      ~     Iteration: 264    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.169922      ~     Iteration: 265    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.169928      ~     Iteration: 266    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.195383      ~     Iteration: 267    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.169928      ~     Iteration: 268    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.195539      ~     Iteration: 269    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.169922      ~     Iteration: 270    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.169928      ~     Iteration: 271    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.195539      ~     Iteration: 272    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.169928      ~     Iteration: 273    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.169928      ~     Iteration: 274    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.195539      ~     Iteration: 275    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.169928      ~     Iteration: 276    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.169928      ~     Iteration: 277    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.195539      ~     Iteration: 278    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.169928      ~     Iteration: 279    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.169928      ~     Iteration: 280    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.195539      ~     Iteration: 281    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.169928      ~     Iteration: 282    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.195539      ~     Iteration: 283    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.169928      ~     Iteration: 284    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.169928      ~     Iteration: 285    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.195539      ~     Iteration: 286    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.169928      ~     Iteration: 287    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.169928      ~     Iteration: 288    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.195539      ~     Iteration: 289    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.169928      ~     Iteration: 290    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.195539      ~     Iteration: 291    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.169928      ~     Iteration: 292    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.169928      ~     Iteration: 293    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.169928      ~     Iteration: 294    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.195539      ~     Iteration: 295    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.169928      ~     Iteration: 296    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.195539      ~     Iteration: 297    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.169928      ~     Iteration: 298    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.169928      ~     Iteration: 299    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.195539      ~     Iteration: 300    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.169928                                                                                                                                                                                  ~    Stopped at: 300    ~ (alpha, beta): (0.374, 3.254)     ~ |gradient|_1: -0.230  ~ stopping criterion: 0.169928</code></pre>
</div>
</div>
<p>Now, let’s compare it to the previous example.</p>
<div id="2eec402c" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># MixCOBRA with default parameter</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Estimated (alpha, beta) = (</span><span class="sc">{}</span><span class="st">, </span><span class="sc">{}</span><span class="st">)"</span>.<span class="bu">format</span>(gc3_fit.optimization_outputs[<span class="st">'opt_alpha'</span>], gc3_fit.optimization_outputs[<span class="st">'opt_beta'</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Estimated (alpha, beta) = (0.3743397706811509, 3.2544697789345673)</code></pre>
</div>
</div>
<p>Look at the learning surface using <code>draw_learning_curve()</code> method.</p>
<div id="ab8cddaf" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>gc3_fit.draw_learning_curve()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>                            <div id="38c9ff80-08b7-4ace-ac14-e44a68a79bc0" class="plotly-graph-div" style="height:450px; width:500px;"></div>            <script type="text/javascript">                require(["plotly"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("38c9ff80-08b7-4ace-ac14-e44a68a79bc0")) {                    Plotly.newPlot(                        "38c9ff80-08b7-4ace-ac14-e44a68a79bc0",                        [{"name":"Loss","opacity":0.8,"showlegend":false,"x":[[0.3253143785752216,0.38946967937441745,0.45362498017361336,0.5177802809728093,0.5819355817720051,0.646090882571201,0.7102461833703968,0.7744014841695928,0.8385567849687886,0.9027120857679845,0.9668673865671803,1.0310226873663764,1.095177988165572,1.1593332889647678,1.223488589763964,1.2876438905631598,1.3517991913623555,1.4159544921615517,1.4801097929607474,1.5442650937599431],[0.3253143785752216,0.38946967937441745,0.45362498017361336,0.5177802809728093,0.5819355817720051,0.646090882571201,0.7102461833703968,0.7744014841695928,0.8385567849687886,0.9027120857679845,0.9668673865671803,1.0310226873663764,1.095177988165572,1.1593332889647678,1.223488589763964,1.2876438905631598,1.3517991913623555,1.4159544921615517,1.4801097929607474,1.5442650937599431],[0.3253143785752216,0.38946967937441745,0.45362498017361336,0.5177802809728093,0.5819355817720051,0.646090882571201,0.7102461833703968,0.7744014841695928,0.8385567849687886,0.9027120857679845,0.9668673865671803,1.0310226873663764,1.095177988165572,1.1593332889647678,1.223488589763964,1.2876438905631598,1.3517991913623555,1.4159544921615517,1.4801097929607474,1.5442650937599431],[0.3253143785752216,0.38946967937441745,0.45362498017361336,0.5177802809728093,0.5819355817720051,0.646090882571201,0.7102461833703968,0.7744014841695928,0.8385567849687886,0.9027120857679845,0.9668673865671803,1.0310226873663764,1.095177988165572,1.1593332889647678,1.223488589763964,1.2876438905631598,1.3517991913623555,1.4159544921615517,1.4801097929607474,1.5442650937599431],[0.3253143785752216,0.38946967937441745,0.45362498017361336,0.5177802809728093,0.5819355817720051,0.646090882571201,0.7102461833703968,0.7744014841695928,0.8385567849687886,0.9027120857679845,0.9668673865671803,1.0310226873663764,1.095177988165572,1.1593332889647678,1.223488589763964,1.2876438905631598,1.3517991913623555,1.4159544921615517,1.4801097929607474,1.5442650937599431],[0.3253143785752216,0.38946967937441745,0.45362498017361336,0.5177802809728093,0.5819355817720051,0.646090882571201,0.7102461833703968,0.7744014841695928,0.8385567849687886,0.9027120857679845,0.9668673865671803,1.0310226873663764,1.095177988165572,1.1593332889647678,1.223488589763964,1.2876438905631598,1.3517991913623555,1.4159544921615517,1.4801097929607474,1.5442650937599431],[0.3253143785752216,0.38946967937441745,0.45362498017361336,0.5177802809728093,0.5819355817720051,0.646090882571201,0.7102461833703968,0.7744014841695928,0.8385567849687886,0.9027120857679845,0.9668673865671803,1.0310226873663764,1.095177988165572,1.1593332889647678,1.223488589763964,1.2876438905631598,1.3517991913623555,1.4159544921615517,1.4801097929607474,1.5442650937599431],[0.3253143785752216,0.38946967937441745,0.45362498017361336,0.5177802809728093,0.5819355817720051,0.646090882571201,0.7102461833703968,0.7744014841695928,0.8385567849687886,0.9027120857679845,0.9668673865671803,1.0310226873663764,1.095177988165572,1.1593332889647678,1.223488589763964,1.2876438905631598,1.3517991913623555,1.4159544921615517,1.4801097929607474,1.5442650937599431],[0.3253143785752216,0.38946967937441745,0.45362498017361336,0.5177802809728093,0.5819355817720051,0.646090882571201,0.7102461833703968,0.7744014841695928,0.8385567849687886,0.9027120857679845,0.9668673865671803,1.0310226873663764,1.095177988165572,1.1593332889647678,1.223488589763964,1.2876438905631598,1.3517991913623555,1.4159544921615517,1.4801097929607474,1.5442650937599431],[0.3253143785752216,0.38946967937441745,0.45362498017361336,0.5177802809728093,0.5819355817720051,0.646090882571201,0.7102461833703968,0.7744014841695928,0.8385567849687886,0.9027120857679845,0.9668673865671803,1.0310226873663764,1.095177988165572,1.1593332889647678,1.223488589763964,1.2876438905631598,1.3517991913623555,1.4159544921615517,1.4801097929607474,1.5442650937599431],[0.3253143785752216,0.38946967937441745,0.45362498017361336,0.5177802809728093,0.5819355817720051,0.646090882571201,0.7102461833703968,0.7744014841695928,0.8385567849687886,0.9027120857679845,0.9668673865671803,1.0310226873663764,1.095177988165572,1.1593332889647678,1.223488589763964,1.2876438905631598,1.3517991913623555,1.4159544921615517,1.4801097929607474,1.5442650937599431],[0.3253143785752216,0.38946967937441745,0.45362498017361336,0.5177802809728093,0.5819355817720051,0.646090882571201,0.7102461833703968,0.7744014841695928,0.8385567849687886,0.9027120857679845,0.9668673865671803,1.0310226873663764,1.095177988165572,1.1593332889647678,1.223488589763964,1.2876438905631598,1.3517991913623555,1.4159544921615517,1.4801097929607474,1.5442650937599431],[0.3253143785752216,0.38946967937441745,0.45362498017361336,0.5177802809728093,0.5819355817720051,0.646090882571201,0.7102461833703968,0.7744014841695928,0.8385567849687886,0.9027120857679845,0.9668673865671803,1.0310226873663764,1.095177988165572,1.1593332889647678,1.223488589763964,1.2876438905631598,1.3517991913623555,1.4159544921615517,1.4801097929607474,1.5442650937599431],[0.3253143785752216,0.38946967937441745,0.45362498017361336,0.5177802809728093,0.5819355817720051,0.646090882571201,0.7102461833703968,0.7744014841695928,0.8385567849687886,0.9027120857679845,0.9668673865671803,1.0310226873663764,1.095177988165572,1.1593332889647678,1.223488589763964,1.2876438905631598,1.3517991913623555,1.4159544921615517,1.4801097929607474,1.5442650937599431],[0.3253143785752216,0.38946967937441745,0.45362498017361336,0.5177802809728093,0.5819355817720051,0.646090882571201,0.7102461833703968,0.7744014841695928,0.8385567849687886,0.9027120857679845,0.9668673865671803,1.0310226873663764,1.095177988165572,1.1593332889647678,1.223488589763964,1.2876438905631598,1.3517991913623555,1.4159544921615517,1.4801097929607474,1.5442650937599431],[0.3253143785752216,0.38946967937441745,0.45362498017361336,0.5177802809728093,0.5819355817720051,0.646090882571201,0.7102461833703968,0.7744014841695928,0.8385567849687886,0.9027120857679845,0.9668673865671803,1.0310226873663764,1.095177988165572,1.1593332889647678,1.223488589763964,1.2876438905631598,1.3517991913623555,1.4159544921615517,1.4801097929607474,1.5442650937599431],[0.3253143785752216,0.38946967937441745,0.45362498017361336,0.5177802809728093,0.5819355817720051,0.646090882571201,0.7102461833703968,0.7744014841695928,0.8385567849687886,0.9027120857679845,0.9668673865671803,1.0310226873663764,1.095177988165572,1.1593332889647678,1.223488589763964,1.2876438905631598,1.3517991913623555,1.4159544921615517,1.4801097929607474,1.5442650937599431],[0.3253143785752216,0.38946967937441745,0.45362498017361336,0.5177802809728093,0.5819355817720051,0.646090882571201,0.7102461833703968,0.7744014841695928,0.8385567849687886,0.9027120857679845,0.9668673865671803,1.0310226873663764,1.095177988165572,1.1593332889647678,1.223488589763964,1.2876438905631598,1.3517991913623555,1.4159544921615517,1.4801097929607474,1.5442650937599431],[0.3253143785752216,0.38946967937441745,0.45362498017361336,0.5177802809728093,0.5819355817720051,0.646090882571201,0.7102461833703968,0.7744014841695928,0.8385567849687886,0.9027120857679845,0.9668673865671803,1.0310226873663764,1.095177988165572,1.1593332889647678,1.223488589763964,1.2876438905631598,1.3517991913623555,1.4159544921615517,1.4801097929607474,1.5442650937599431],[0.3253143785752216,0.38946967937441745,0.45362498017361336,0.5177802809728093,0.5819355817720051,0.646090882571201,0.7102461833703968,0.7744014841695928,0.8385567849687886,0.9027120857679845,0.9668673865671803,1.0310226873663764,1.095177988165572,1.1593332889647678,1.223488589763964,1.2876438905631598,1.3517991913623555,1.4159544921615517,1.4801097929607474,1.5442650937599431]],"y":[[2.590171462721533,2.590171462721533,2.590171462721533,2.590171462721533,2.590171462721533,2.590171462721533,2.590171462721533,2.590171462721533,2.590171462721533,2.590171462721533,2.590171462721533,2.590171462721533,2.590171462721533,2.590171462721533,2.590171462721533,2.590171462721533,2.590171462721533,2.590171462721533,2.590171462721533,2.590171462721533],[2.685726825332487,2.685726825332487,2.685726825332487,2.685726825332487,2.685726825332487,2.685726825332487,2.685726825332487,2.685726825332487,2.685726825332487,2.685726825332487,2.685726825332487,2.685726825332487,2.685726825332487,2.685726825332487,2.685726825332487,2.685726825332487,2.685726825332487,2.685726825332487,2.685726825332487,2.685726825332487],[2.7812821879434413,2.7812821879434413,2.7812821879434413,2.7812821879434413,2.7812821879434413,2.7812821879434413,2.7812821879434413,2.7812821879434413,2.7812821879434413,2.7812821879434413,2.7812821879434413,2.7812821879434413,2.7812821879434413,2.7812821879434413,2.7812821879434413,2.7812821879434413,2.7812821879434413,2.7812821879434413,2.7812821879434413,2.7812821879434413],[2.876837550554396,2.876837550554396,2.876837550554396,2.876837550554396,2.876837550554396,2.876837550554396,2.876837550554396,2.876837550554396,2.876837550554396,2.876837550554396,2.876837550554396,2.876837550554396,2.876837550554396,2.876837550554396,2.876837550554396,2.876837550554396,2.876837550554396,2.876837550554396,2.876837550554396,2.876837550554396],[2.97239291316535,2.97239291316535,2.97239291316535,2.97239291316535,2.97239291316535,2.97239291316535,2.97239291316535,2.97239291316535,2.97239291316535,2.97239291316535,2.97239291316535,2.97239291316535,2.97239291316535,2.97239291316535,2.97239291316535,2.97239291316535,2.97239291316535,2.97239291316535,2.97239291316535,2.97239291316535],[3.0679482757763044,3.0679482757763044,3.0679482757763044,3.0679482757763044,3.0679482757763044,3.0679482757763044,3.0679482757763044,3.0679482757763044,3.0679482757763044,3.0679482757763044,3.0679482757763044,3.0679482757763044,3.0679482757763044,3.0679482757763044,3.0679482757763044,3.0679482757763044,3.0679482757763044,3.0679482757763044,3.0679482757763044,3.0679482757763044],[3.163503638387259,3.163503638387259,3.163503638387259,3.163503638387259,3.163503638387259,3.163503638387259,3.163503638387259,3.163503638387259,3.163503638387259,3.163503638387259,3.163503638387259,3.163503638387259,3.163503638387259,3.163503638387259,3.163503638387259,3.163503638387259,3.163503638387259,3.163503638387259,3.163503638387259,3.163503638387259],[3.259059000998213,3.259059000998213,3.259059000998213,3.259059000998213,3.259059000998213,3.259059000998213,3.259059000998213,3.259059000998213,3.259059000998213,3.259059000998213,3.259059000998213,3.259059000998213,3.259059000998213,3.259059000998213,3.259059000998213,3.259059000998213,3.259059000998213,3.259059000998213,3.259059000998213,3.259059000998213],[3.3546143636091674,3.3546143636091674,3.3546143636091674,3.3546143636091674,3.3546143636091674,3.3546143636091674,3.3546143636091674,3.3546143636091674,3.3546143636091674,3.3546143636091674,3.3546143636091674,3.3546143636091674,3.3546143636091674,3.3546143636091674,3.3546143636091674,3.3546143636091674,3.3546143636091674,3.3546143636091674,3.3546143636091674,3.3546143636091674],[3.4501697262201216,3.4501697262201216,3.4501697262201216,3.4501697262201216,3.4501697262201216,3.4501697262201216,3.4501697262201216,3.4501697262201216,3.4501697262201216,3.4501697262201216,3.4501697262201216,3.4501697262201216,3.4501697262201216,3.4501697262201216,3.4501697262201216,3.4501697262201216,3.4501697262201216,3.4501697262201216,3.4501697262201216,3.4501697262201216],[3.545725088831076,3.545725088831076,3.545725088831076,3.545725088831076,3.545725088831076,3.545725088831076,3.545725088831076,3.545725088831076,3.545725088831076,3.545725088831076,3.545725088831076,3.545725088831076,3.545725088831076,3.545725088831076,3.545725088831076,3.545725088831076,3.545725088831076,3.545725088831076,3.545725088831076,3.545725088831076],[3.6412804514420305,3.6412804514420305,3.6412804514420305,3.6412804514420305,3.6412804514420305,3.6412804514420305,3.6412804514420305,3.6412804514420305,3.6412804514420305,3.6412804514420305,3.6412804514420305,3.6412804514420305,3.6412804514420305,3.6412804514420305,3.6412804514420305,3.6412804514420305,3.6412804514420305,3.6412804514420305,3.6412804514420305,3.6412804514420305],[3.7368358140529847,3.7368358140529847,3.7368358140529847,3.7368358140529847,3.7368358140529847,3.7368358140529847,3.7368358140529847,3.7368358140529847,3.7368358140529847,3.7368358140529847,3.7368358140529847,3.7368358140529847,3.7368358140529847,3.7368358140529847,3.7368358140529847,3.7368358140529847,3.7368358140529847,3.7368358140529847,3.7368358140529847,3.7368358140529847],[3.832391176663939,3.832391176663939,3.832391176663939,3.832391176663939,3.832391176663939,3.832391176663939,3.832391176663939,3.832391176663939,3.832391176663939,3.832391176663939,3.832391176663939,3.832391176663939,3.832391176663939,3.832391176663939,3.832391176663939,3.832391176663939,3.832391176663939,3.832391176663939,3.832391176663939,3.832391176663939],[3.9279465392748936,3.9279465392748936,3.9279465392748936,3.9279465392748936,3.9279465392748936,3.9279465392748936,3.9279465392748936,3.9279465392748936,3.9279465392748936,3.9279465392748936,3.9279465392748936,3.9279465392748936,3.9279465392748936,3.9279465392748936,3.9279465392748936,3.9279465392748936,3.9279465392748936,3.9279465392748936,3.9279465392748936,3.9279465392748936],[4.023501901885847,4.023501901885847,4.023501901885847,4.023501901885847,4.023501901885847,4.023501901885847,4.023501901885847,4.023501901885847,4.023501901885847,4.023501901885847,4.023501901885847,4.023501901885847,4.023501901885847,4.023501901885847,4.023501901885847,4.023501901885847,4.023501901885847,4.023501901885847,4.023501901885847,4.023501901885847],[4.119057264496802,4.119057264496802,4.119057264496802,4.119057264496802,4.119057264496802,4.119057264496802,4.119057264496802,4.119057264496802,4.119057264496802,4.119057264496802,4.119057264496802,4.119057264496802,4.119057264496802,4.119057264496802,4.119057264496802,4.119057264496802,4.119057264496802,4.119057264496802,4.119057264496802,4.119057264496802],[4.214612627107757,4.214612627107757,4.214612627107757,4.214612627107757,4.214612627107757,4.214612627107757,4.214612627107757,4.214612627107757,4.214612627107757,4.214612627107757,4.214612627107757,4.214612627107757,4.214612627107757,4.214612627107757,4.214612627107757,4.214612627107757,4.214612627107757,4.214612627107757,4.214612627107757,4.214612627107757],[4.31016798971871,4.31016798971871,4.31016798971871,4.31016798971871,4.31016798971871,4.31016798971871,4.31016798971871,4.31016798971871,4.31016798971871,4.31016798971871,4.31016798971871,4.31016798971871,4.31016798971871,4.31016798971871,4.31016798971871,4.31016798971871,4.31016798971871,4.31016798971871,4.31016798971871,4.31016798971871],[4.405723352329665,4.405723352329665,4.405723352329665,4.405723352329665,4.405723352329665,4.405723352329665,4.405723352329665,4.405723352329665,4.405723352329665,4.405723352329665,4.405723352329665,4.405723352329665,4.405723352329665,4.405723352329665,4.405723352329665,4.405723352329665,4.405723352329665,4.405723352329665,4.405723352329665,4.405723352329665]],"z":[[19.132715565843547,19.132747321368228,19.132769635499443,19.132806551145723,19.13284990267065,19.132870852200746,19.132908429206196,19.132964721536364,19.133002450514134,19.133027979378618,19.13306580422273,19.13312083430703,19.133158635037567,19.13320878806229,19.13325636986174,19.13329185102678,19.133322353086864,19.133337612044084,19.133380736782776,19.133424787381934],[19.102271661428396,19.102310301934388,19.10236205381634,19.102413901173286,19.102472893004414,19.102516686779126,19.102569391170707,19.102629225155088,19.102683010346983,19.102712387518487,19.102769988133872,19.102813728597024,19.102865851479358,19.10292131829037,19.102973285469524,19.103037758444792,19.10309900464156,19.10313100681737,19.103187829366927,19.103249988747056],[19.077271016503833,19.077341273275493,19.077411602714673,19.0774629811646,19.077522842380567,19.0775880464025,19.07765218967,19.077716455561262,19.077789217844035,19.07784670070591,19.077905468167938,19.077970849036817,19.078032350376454,19.07809939886922,19.07816549084497,19.078221238219378,19.078290836714125,19.07835482853072,19.078416860035773,19.078478119440508],[19.057221139474997,19.05727699996106,19.05735130891302,19.05743083371626,19.05749568451341,19.057577114010492,19.057652261680968,19.057711209373913,19.05779455213352,19.057863382007387,19.057940758407025,19.05800529674496,19.0580881161464,19.058160911782736,19.058253357560844,19.05830330183837,19.058393167616494,19.058475638903804,19.058559856573886,19.05863692678477],[19.04156137793748,19.041632423019824,19.041707900480908,19.041796359559065,19.041886264018,19.041966161272246,19.04205286599639,19.042141154835267,19.04221657718298,19.042297212041422,19.042395994824144,19.04247304143234,19.042549686830956,19.04262608345722,19.04271598401394,19.042796773552578,19.042881245240974,19.042978168828277,19.043051675240388,19.043149403148483],[19.02983871168318,19.029932966044974,19.03001892622478,19.030118324643205,19.030212475705632,19.03029883007629,19.030382472909704,19.030483302508102,19.03058476564445,19.030666127368495,19.030773373539304,19.030848399483965,19.03095459955437,19.031047538002106,19.031149087511032,19.031228383828594,19.031337246857646,19.031412962871478,19.031524884018353,19.031609447330332],[19.02165965421023,19.021764711174917,19.021866914390895,19.02195574997769,19.022057470241194,19.022162845760754,19.022265532013698,19.022363400499067,19.02247194711951,19.022569360653918,19.02266843828775,19.022766139964748,19.022873195715746,19.022972754434846,19.02307579843255,19.023177391733388,19.02328042480741,19.023382433783883,19.023488969580328,19.023594474215688],[19.016626765801433,19.016734146542873,19.016841581683508,19.016951667605614,19.01707025303426,19.017174460399765,19.017289868374718,19.01739019495214,19.01750725717381,19.01761142545083,19.01772340072418,19.017827274068942,19.017950434884536,19.018048426631037,19.018167829691343,19.018273483663336,19.01839093293267,19.01849626195269,19.01861376582074,19.018720190836774],[19.014435382030705,19.014522777295905,19.014651579371584,19.014770315981902,19.01489780841802,19.01500259457277,19.015133334588597,19.015225975565013,19.015355895709252,19.015479972450766,19.01559188651408,19.01570551361585,19.015833532137286,19.01594051364355,19.01606104796446,19.016188951377835,19.016294621846807,19.016419702725667,19.01653208192897,19.016648204038933],[19.014727942922498,19.014852905057502,19.014974635131985,19.015100746116133,19.015217031135116,19.015342897068102,19.015460944505755,19.01559463094738,19.015715109975908,19.01584185836742,19.015958264469816,19.016090241752043,19.016206681572044,19.01633920032291,19.016463061761307,19.016590306029197,19.016715573676613,19.016839550735998,19.01696667736907,19.017095390925398],[19.017270155293915,19.017393588881394,19.01753189899497,19.017653909006064,19.017795759480915,19.017912649287247,19.01805107484886,19.018169443910487,19.01831168499489,19.018438698808758,19.018564962919452,19.018701377416946,19.018824412090144,19.018965468923895,19.01909775360827,19.01922799873706,19.019344761411052,19.019493355703936,19.019617058864775,19.01974896738344],[19.02178414008019,19.02191644839463,19.022056847728987,19.0221947540548,19.02233139420945,19.022465999738714,19.02260259779589,19.022741418611936,19.022873889332967,19.023016213150253,19.023154890234277,19.02328559189685,19.0234230894606,19.02357530341855,19.023712586677277,19.02384802358433,19.023985545906648,19.024121430355628,19.02426524992758,19.024404091110064],[19.028092160041496,19.028226524446456,19.0283608979393,19.028500792859088,19.028659997633703,19.02880027518902,19.028941030481096,19.029078015004927,19.02921340246266,19.0293647976112,19.029507367426866,19.02965157294255,19.02980187205628,19.029926476676376,19.030088762146207,19.030228921090977,19.030367687910232,19.030514428894566,19.030667827720272,19.030810102180947],[19.03592153038001,19.036062548664493,19.036211843196234,19.03635795064806,19.03652108804445,19.03666599665937,19.03680127316779,19.036953089980347,19.037099864518037,19.037240767318462,19.037403240278458,19.03754106779119,19.037693273767534,19.037846472725214,19.03800768401462,19.03815240748305,19.038309439380832,19.03845711306494,19.03860669891693,19.03874137730965],[19.04516389823319,19.0453117468523,19.045472422051397,19.045618026712653,19.045773169126527,19.045931658338066,19.046087849589274,19.046237771588565,19.046393269255415,19.046548949867223,19.04670942745363,19.046850203828377,19.04700126349116,19.0471682771277,19.047322213437692,19.047456927443612,19.047613023891877,19.04777718863583,19.047943386953293,19.048079045989514],[19.0556510028571,19.05579785315401,19.05595094341031,19.056129685486322,19.056273891383483,19.056432457243567,19.056588271615844,19.05674749142623,19.056914288102558,19.057070468545625,19.05721950210698,19.0573752653604,19.057527174098617,19.057707620074957,19.057858676437984,19.05801858474145,19.058175608465053,19.05833659313249,19.058492906397124,19.058660334814515],[19.06719359186198,19.067375560565115,19.067522371117022,19.067691556344332,19.067850117313853,19.06801040165689,19.06817894064701,19.068341526658955,19.06850896900925,19.0686675867927,19.06883222954492,19.06899938794375,19.069155053707203,19.06931237868254,19.069482291145448,19.069647577345282,19.069810299241574,19.069971704782382,19.070140439731034,19.07029601675184],[19.079728262376904,19.079896273134302,19.08006014183307,19.08022143031203,19.080385125586176,19.080568543113742,19.080716425330824,19.080895069437112,19.081060185213072,19.081226782747933,19.0814008607949,19.08155721120301,19.081740426809127,19.081891698682654,19.08206555444779,19.08223390160738,19.08239961154264,19.08257257124761,19.08273529764767,19.08291078723341],[19.09309058739216,19.093263288553366,19.09342659605036,19.093610601894163,19.093784594761708,19.093942887008907,19.094113044549026,19.09428935313136,19.09445384751769,19.094626424961753,19.094810321838846,19.094964659532106,19.095144490704733,19.09530767432422,19.09548547056369,19.09566277486639,19.095811761793982,19.095995323140862,19.096164785674148,19.096335690618023],[19.107187587958332,19.107359762783577,19.10753635757346,19.107716958071947,19.107890292317357,19.10805812956857,19.10823679517656,19.108412707239342,19.108591892675655,19.108765188896317,19.108934563393248,19.109122594662903,19.10929039699112,19.109467716617566,19.10963778904044,19.109817203253666,19.109991352286208,19.110171100355196,19.11034595857943,19.110521374945858]],"type":"surface"},{"line":{"color":["#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7"],"width":5},"marker":{"color":["#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7","#0E94F7"],"size":[7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7]},"mode":"markers+lines","name":"Gradient path","showlegend":false,"x":[1.0,0.8631367487885976,1.3037844019333886,0.63062887818949,0.6226542190335449,0.6531739275716506,0.5917281034446648,0.3253143785752216,0.35829037251499296,0.37113064307566035,0.3776059870824912,0.37497031410713355,0.3702621169912124,0.3757118171628454,0.3755211672181045,0.37503839288354773,0.37455154464358553,0.3743751489246231,0.37433757135171725,0.3744079557036711,0.37432010287898504,0.3743637450546167,0.374346998400189,0.3743341626741579,0.37434094205096,0.37434482525045676,0.3743394770774826,0.37434003258267173,0.3743407841759631,0.374340519317956,0.3743400701514979,0.3743399902221596,0.37433976591545176,0.374339822345592,0.37433982096532864,0.37433979507339343,0.3743397812382687,0.37433976407165304,0.3743397728354387,0.3743397712555781,0.3743397705987257,0.3743397700717218,0.37433977020606946,0.3743397702368749,0.374339770310041,0.3743397702373773,0.37433977025005566,0.3743397701987366,0.3743397701990081,0.37433977024312803,0.3743397702890697,0.37433977033085547,0.3743397703678368,0.37433977040556643,0.37433977044401345,0.3743397704831777,0.3743397705230592,0.3743397705636581,0.3743397706049742],"y":[3.7750000000000004,3.417629435721663,2.85470003440368,4.17992307615456,3.5085951265921453,3.4439945378657613,3.745218978504802,3.8844318683638397,3.826087867443655,3.6956034698492335,3.407660066228146,3.4197194277825425,3.3871724100869303,3.327289376143182,3.311919581807759,3.3130696471150705,3.2693943630555378,3.273269022612605,3.2465226653743997,3.246514413437782,3.2471474317642794,3.245082466940223,3.2494634948350676,3.250836071834779,3.2523848547409884,3.2526766527564575,3.2537796867537288,3.2538609732805144,3.254176493117493,3.2541752095096363,3.2541702920865556,3.254264725313487,3.254353839968913,3.254437739069405,3.2544512417350555,3.2544633540398267,3.2544681575742618,3.254468603738268,3.254466882113879,3.2544694031807615,3.2544701211909,3.25446973222159,3.254469686961074,3.2544697472413873,3.2544697613521256,3.254469781316171,3.2544697728221976,3.2544697886771776,3.254469783777107,3.2544697821857844,3.254469778425458,3.254469778926725,3.2544697790792583,3.2544697790225086,3.254469778999188,3.254469778921611,3.2544697789317043,3.2544697789359143,3.2544697789362815],"z":[19.03256678097774,19.015369781367575,19.062544176186222,19.075865562711343,19.01662153073624,19.015265714396048,19.029306153952163,19.04080564397598,19.035425143693868,19.025255133082958,19.014400265499045,19.014457539721256,19.01433426526275,19.014861384328082,19.015171440229064,19.015143603537382,19.016335201252442,19.016216063356826,19.0171974480271,19.01720447258534,19.017178262015328,19.017256189568954,19.017085877958785,19.017033798745672,19.016973712846458,19.016956885075178,19.01692060428711,19.016915799430084,19.016899686176405,19.016893929174806,19.016895330280207,19.01690019439497,19.01690256974759,19.01689254354452,19.016903445524058,19.016903220535376,19.016885314002383,19.01687771288949,19.016896231277663,19.016891361824342,19.01688181041472,19.01688481891933,19.016893518713047,19.01689495578953,19.016884725223385,19.016892632198466,19.016889607202057,19.016887220552235,19.016883452630363,19.01689359620563,19.016895973192288,19.016896530869758,19.016896700385132,19.01689663737379,19.01689661154766,19.01689652562886,19.016896536972425,19.01689654177451,19.016896542304465],"type":"scatter3d"},{"marker":{"color":"#27B629","size":7},"mode":"markers","name":"Optimal point","showlegend":false,"x":[0.3743397706811509],"y":[3.2544697789345673],"z":[19.016896540621563],"type":"scatter3d"}],                        {"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}},"title":{"text":"Loss vs parameters (alpha, beta) for (radial kernel)","x":0.5,"y":0.925},"scene":{"xaxis":{"title":{"text":"Alpha"}},"yaxis":{"title":{"text":"Beta"}},"zaxis":{"title":{"text":"Loss"}}},"width":500,"height":450},                        {"responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('38c9ff80-08b7-4ace-ac14-e44a68a79bc0');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };                });            </script>        </div>
</div>
</div>
<p>We evaluate the performance of the method on the testing data using MSE and MAPE.</p>
<div id="d74b83ce" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_absolute_percentage_error</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>y_pred3 <span class="op">=</span> gc3_fit.predict(X_test1)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mean_absolute_percentage_error(y_test1, y_pred3))</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mean_squared_error(y_test1, y_pred3))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.13304424506505247
81.99367408815925</code></pre>
</div>
</div>
<p>Let’s look at <code>qq-plot</code> using <code>draw_learning_curve()</code> method.</p>
<div id="8a88f47d" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>gc3_fit.draw_learning_curve(y_test<span class="op">=</span>y_test1, fig_type<span class="op">=</span><span class="st">'qq'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>                            <div id="d8fd5e63-c0ae-48e2-a163-202410cf3cd2" class="plotly-graph-div" style="height:450px; width:500px;"></div>            <script type="text/javascript">                require(["plotly"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("d8fd5e63-c0ae-48e2-a163-202410cf3cd2")) {                    Plotly.newPlot(                        "d8fd5e63-c0ae-48e2-a163-202410cf3cd2",                        [{"hovertemplate":"y_test=%{y}<extra></extra>","legendgroup":"","line":{"color":"red","dash":"solid"},"marker":{"symbol":"circle"},"mode":"lines","name":"","orientation":"v","showlegend":false,"x":[107.12908749668411,82.07729820341567,250.68582410503322,-228.20850045088835,-193.60755325508376,151.25473152208022,25.156734317388604,161.78057073873572,26.1031081041485,-128.4305534178685,27.90866808562813,-44.44116020741867,-138.93840475334991,-222.16681537868476,-192.19645427097396,0.9739650548381744,120.66403004876267,84.01493807657121,229.22301842153715,-65.01672019723868,3.5566914863945716,2.5011089169083967,-75.28038724279148,-51.17106492509048,63.9968795674746,-26.858243562563406,-88.62347922757598,125.3897181575711,159.45283298188983,-171.08163655117602,7.167740354736653,169.9866305208371,-45.476216321052725,196.64418560918458,6.916057547879813,-44.9209106885849,123.29161348759706,-237.05627320839048,4.793227605388368,-87.75386811360924,-204.7547493029273,300.5340481865176,36.6923441324542,223.1260158640755,37.57236489689603,-135.1432154129502,-22.09541283219769,-19.38279454211906,129.0570647553141,-131.32815842579072,422.6071726637826,71.56184791930542,117.97216683218622,71.21094747981446,-71.29424209716659,45.42212756418835,-142.2554807700287,240.68718226715367,45.496919732973716,-48.518054418620885,-248.65784662270624,11.069509335539475,72.05254229256354,-286.46158602249164,100.20919875515544,-263.20440044800785,75.54044381008978,-236.9865925366403,105.9176903979468,-134.89918697795054,-114.09922634996403,195.16438655741743,243.78235672220447,88.76976759082784,274.8524100729351,-7.340463168661583,94.42130245825987,129.61495960951078,219.86857083576825,-239.18599334930218,110.97942524958862,-12.68016776339869,-114.54869084590477,176.46149967380933,29.570182914896833,-50.97935587732554,-45.28967086237738,161.93634504078221,103.50214379224467,25.88535522075014,-33.8894128012218,-242.412557476674,-124.26093105060144,53.63679354263188,-43.3246525052849,-107.73746334414028,121.03273399140014,32.712898595689765,-100.75445110417151,58.67157625605954,-7.5825159865063645,76.6688495574999,13.023195942366515,39.90868904854326,-143.19719258661473,-13.71348176850614,60.61226850721811,-148.92705189944328,164.38182521163475,39.83948082067931,-86.61384134539973,120.35300376200641,-45.220565743218586,-104.6998236678622,-18.168293341880986,224.39055775799608,21.351714206857167,-166.77683714386322,-18.661455614473834,180.041691675834,-96.39307795038825,-33.99774184134089,96.04950261192579,18.87728379020152,-74.46124422252004,-21.456455525633885,-0.5333585972357191,-292.1727368917409,-95.19414501049333,17.940734995718827,-146.74593778483134,-151.00119220601815,62.09397266035934,-33.01234848388809,-25.855903663125307,-65.9126992584748,-8.839918780845649,-171.47171556758286,91.32353005610662,-240.08178210488447,219.3848875267175,19.62192020121106,25.88926237217787,1.9749052668889713,-18.538512569557994,-9.315419891495038,58.232711239576645,-119.70655249853377,80.46302077808511,-82.57388667481422,-255.60025925203018,-67.80947386301447,121.4794212995063,13.859804040726456,202.10891958905597,289.33699561903865,-53.84026788510968,147.75853654057175,30.709841161470898,-58.77980031762141,183.16604659565084,50.94542565632875,-36.02360824141309,184.5201050760169,-194.4973680663153,88.09606416062502,121.32323667682479,105.50454975796093,225.55853185642846,-91.78580216896597,-141.88424494072322,-201.60517536543819,-148.28651750873246,203.18360324017928,-195.80732271269335,-17.550815118335144,89.93641158461833,-65.46712045313103,82.92183773273398,-147.73268717843496,22.048591539069932,122.27445002412495,-55.39748189656167,-76.05201303998004,11.380731583762161,-31.744944384425988,-59.96965302532895,67.34534528686478,-19.045494372635954,215.36455175565462,-295.94662032883775,-103.98671227646881,60.23526349529168,76.56216887038755,-125.8529606820959,-52.89758037421899,-82.16104292148653,68.27941549262121,-227.58479803516835,-5.207533381235832],"xaxis":"x","y":[107.12908749668411,82.07729820341567,250.68582410503322,-228.20850045088835,-193.60755325508376,151.25473152208022,25.156734317388604,161.78057073873572,26.1031081041485,-128.4305534178685,27.90866808562813,-44.44116020741867,-138.93840475334991,-222.16681537868476,-192.19645427097396,0.9739650548381744,120.66403004876267,84.01493807657121,229.22301842153715,-65.01672019723868,3.5566914863945716,2.5011089169083967,-75.28038724279148,-51.17106492509048,63.9968795674746,-26.858243562563406,-88.62347922757598,125.3897181575711,159.45283298188983,-171.08163655117602,7.167740354736653,169.9866305208371,-45.476216321052725,196.64418560918458,6.916057547879813,-44.9209106885849,123.29161348759706,-237.05627320839048,4.793227605388368,-87.75386811360924,-204.7547493029273,300.5340481865176,36.6923441324542,223.1260158640755,37.57236489689603,-135.1432154129502,-22.09541283219769,-19.38279454211906,129.0570647553141,-131.32815842579072,422.6071726637826,71.56184791930542,117.97216683218622,71.21094747981446,-71.29424209716659,45.42212756418835,-142.2554807700287,240.68718226715367,45.496919732973716,-48.518054418620885,-248.65784662270624,11.069509335539475,72.05254229256354,-286.46158602249164,100.20919875515544,-263.20440044800785,75.54044381008978,-236.9865925366403,105.9176903979468,-134.89918697795054,-114.09922634996403,195.16438655741743,243.78235672220447,88.76976759082784,274.8524100729351,-7.340463168661583,94.42130245825987,129.61495960951078,219.86857083576825,-239.18599334930218,110.97942524958862,-12.68016776339869,-114.54869084590477,176.46149967380933,29.570182914896833,-50.97935587732554,-45.28967086237738,161.93634504078221,103.50214379224467,25.88535522075014,-33.8894128012218,-242.412557476674,-124.26093105060144,53.63679354263188,-43.3246525052849,-107.73746334414028,121.03273399140014,32.712898595689765,-100.75445110417151,58.67157625605954,-7.5825159865063645,76.6688495574999,13.023195942366515,39.90868904854326,-143.19719258661473,-13.71348176850614,60.61226850721811,-148.92705189944328,164.38182521163475,39.83948082067931,-86.61384134539973,120.35300376200641,-45.220565743218586,-104.6998236678622,-18.168293341880986,224.39055775799608,21.351714206857167,-166.77683714386322,-18.661455614473834,180.041691675834,-96.39307795038825,-33.99774184134089,96.04950261192579,18.87728379020152,-74.46124422252004,-21.456455525633885,-0.5333585972357191,-292.1727368917409,-95.19414501049333,17.940734995718827,-146.74593778483134,-151.00119220601815,62.09397266035934,-33.01234848388809,-25.855903663125307,-65.9126992584748,-8.839918780845649,-171.47171556758286,91.32353005610662,-240.08178210488447,219.3848875267175,19.62192020121106,25.88926237217787,1.9749052668889713,-18.538512569557994,-9.315419891495038,58.232711239576645,-119.70655249853377,80.46302077808511,-82.57388667481422,-255.60025925203018,-67.80947386301447,121.4794212995063,13.859804040726456,202.10891958905597,289.33699561903865,-53.84026788510968,147.75853654057175,30.709841161470898,-58.77980031762141,183.16604659565084,50.94542565632875,-36.02360824141309,184.5201050760169,-194.4973680663153,88.09606416062502,121.32323667682479,105.50454975796093,225.55853185642846,-91.78580216896597,-141.88424494072322,-201.60517536543819,-148.28651750873246,203.18360324017928,-195.80732271269335,-17.550815118335144,89.93641158461833,-65.46712045313103,82.92183773273398,-147.73268717843496,22.048591539069932,122.27445002412495,-55.39748189656167,-76.05201303998004,11.380731583762161,-31.744944384425988,-59.96965302532895,67.34534528686478,-19.045494372635954,215.36455175565462,-295.94662032883775,-103.98671227646881,60.23526349529168,76.56216887038755,-125.8529606820959,-52.89758037421899,-82.16104292148653,68.27941549262121,-227.58479803516835,-5.207533381235832],"yaxis":"y","type":"scatter"},{"hovertemplate":"y_pred=%{x}<br>y_test=%{y}<extra></extra>","legendgroup":"","marker":{"color":"#636efa","symbol":"circle"},"mode":"markers","name":"","orientation":"v","showlegend":false,"x":[95.03960615438808,83.20538033965832,273.98386707156783,-215.47123637277556,-181.59904115945795,161.35957520021614,22.921091464830802,160.38698110698607,25.03224375409153,-126.67766967964081,24.65936063767634,-45.18891525597392,-139.6403451826661,-220.89751408424954,-174.55701700059547,2.7626016084310736,115.26243633451497,79.19268026519363,216.87939670535363,-61.02531324508422,3.574177665960886,0.36944330237759176,-61.742426373484186,-52.679331237528615,77.73823138219525,-23.18412807155081,-90.57891663823209,112.70313699411139,160.9342094148103,-162.08078853593284,1.0701308192881427,173.51814141553956,-53.13092093258018,198.68995362188457,13.633146535729923,-46.92664133863292,115.81943220150737,-228.70961745477743,3.3490065230020423,-70.09533837106842,-217.3377230291194,292.3979174253703,34.730968403838645,212.07279911391183,38.670829946210176,-131.81516908306028,-18.314238493107514,-14.403125949148372,132.6016596566967,-129.819883248712,337.3463096015629,73.21519958151755,114.53827153526025,74.39776012310735,-71.18686971104361,44.121620023772806,-148.59209430464975,238.60049049203235,38.91119472240138,-53.590278406723094,-260.3276338262253,6.040681678038498,67.24772838546444,-280.20869774025596,93.00126258736306,-261.32322522569837,78.73738115138424,-224.15348331865113,108.5454540059365,-141.34677769502602,-119.10282875032179,187.86357476940992,232.11676071411287,79.54648240753666,285.74528096049835,-9.925500722284132,95.09167068576352,128.72862096625875,203.6976512790134,-232.26446189899784,112.10307554072836,-13.331746822077031,-101.9167733032606,170.8420915800367,30.233286764621063,-50.25924190794132,-51.61984511245719,161.2043482705479,102.4485073678804,22.569862100519586,-36.009570732674234,-260.3170004051461,-135.9400980734037,53.50460394425024,-37.03291582880305,-113.0124306273487,125.45163687492014,30.25120033853218,-105.38849378176361,65.79967384628995,-10.03428251179511,69.99602588852605,18.03322701387543,36.94449372025264,-149.39712493608076,-12.68751033177296,65.44100596475259,-151.58348869590532,165.63338847636734,42.827282919258344,-87.45004782283422,121.50958810700484,-47.50794337897877,-104.44188244449961,-17.59319334230225,205.47805332414208,15.008312764500515,-165.2019747900856,-20.251938453932933,180.60330467591268,-94.23886066373333,-29.49536001136955,95.66714407959601,18.28205534506571,-66.01267980014607,-19.865282322114343,-3.5632672937466667,-293.0992561625893,-93.31898441402433,17.122775775857388,-145.9096368647214,-160.79047476268943,62.94905870130848,-26.579706946709432,-22.652349806654627,-60.89118710585366,-10.037940197843547,-175.44159212502288,88.9233194115353,-220.71520979417983,221.79219613781137,14.140367578977441,26.297688766905523,8.550310853920287,-20.89337471544992,-9.306765666524603,57.61129033829931,-112.57033852336062,77.41837099975223,-84.55027066080756,-266.53799808481756,-59.85004821162904,117.23779517014685,14.503755777888472,195.52789970748194,271.80839932428387,-56.95073817654023,151.40016224616517,27.92651584939074,-66.93707490983971,197.4984832734365,50.66793516706867,-41.52033853494976,181.43055917594089,-214.936192102752,79.58063658768415,121.49444227409327,104.04978632755584,211.19883675823422,-88.55906963153792,-143.87433750823052,-191.22704698227838,-146.53127300984835,202.0291380857063,-201.561476036932,-16.10104649409774,95.85676898111358,-69.1954058233512,78.44797595531054,-148.78206657854187,21.057559242308955,118.90870514013926,-54.43090436122325,-67.198688997211,13.48341441538494,-28.232326427380332,-56.808339688834344,72.41300558440109,-17.054419516669558,215.20044300132326,-291.283536148003,-102.26544114609133,62.29718842442808,71.08040392218041,-119.02444607555852,-52.84254600659702,-83.22225451849019,73.85056210161223,-221.30258372681112,-4.268675955169759],"xaxis":"x","y":[107.12908749668411,82.07729820341567,250.68582410503322,-228.20850045088835,-193.60755325508376,151.25473152208022,25.156734317388604,161.78057073873572,26.1031081041485,-128.4305534178685,27.90866808562813,-44.44116020741867,-138.93840475334991,-222.16681537868476,-192.19645427097396,0.9739650548381744,120.66403004876267,84.01493807657121,229.22301842153715,-65.01672019723868,3.5566914863945716,2.5011089169083967,-75.28038724279148,-51.17106492509048,63.9968795674746,-26.858243562563406,-88.62347922757598,125.3897181575711,159.45283298188983,-171.08163655117602,7.167740354736653,169.9866305208371,-45.476216321052725,196.64418560918458,6.916057547879813,-44.9209106885849,123.29161348759706,-237.05627320839048,4.793227605388368,-87.75386811360924,-204.7547493029273,300.5340481865176,36.6923441324542,223.1260158640755,37.57236489689603,-135.1432154129502,-22.09541283219769,-19.38279454211906,129.0570647553141,-131.32815842579072,422.6071726637826,71.56184791930542,117.97216683218622,71.21094747981446,-71.29424209716659,45.42212756418835,-142.2554807700287,240.68718226715367,45.496919732973716,-48.518054418620885,-248.65784662270624,11.069509335539475,72.05254229256354,-286.46158602249164,100.20919875515544,-263.20440044800785,75.54044381008978,-236.9865925366403,105.9176903979468,-134.89918697795054,-114.09922634996403,195.16438655741743,243.78235672220447,88.76976759082784,274.8524100729351,-7.340463168661583,94.42130245825987,129.61495960951078,219.86857083576825,-239.18599334930218,110.97942524958862,-12.68016776339869,-114.54869084590477,176.46149967380933,29.570182914896833,-50.97935587732554,-45.28967086237738,161.93634504078221,103.50214379224467,25.88535522075014,-33.8894128012218,-242.412557476674,-124.26093105060144,53.63679354263188,-43.3246525052849,-107.73746334414028,121.03273399140014,32.712898595689765,-100.75445110417151,58.67157625605954,-7.5825159865063645,76.6688495574999,13.023195942366515,39.90868904854326,-143.19719258661473,-13.71348176850614,60.61226850721811,-148.92705189944328,164.38182521163475,39.83948082067931,-86.61384134539973,120.35300376200641,-45.220565743218586,-104.6998236678622,-18.168293341880986,224.39055775799608,21.351714206857167,-166.77683714386322,-18.661455614473834,180.041691675834,-96.39307795038825,-33.99774184134089,96.04950261192579,18.87728379020152,-74.46124422252004,-21.456455525633885,-0.5333585972357191,-292.1727368917409,-95.19414501049333,17.940734995718827,-146.74593778483134,-151.00119220601815,62.09397266035934,-33.01234848388809,-25.855903663125307,-65.9126992584748,-8.839918780845649,-171.47171556758286,91.32353005610662,-240.08178210488447,219.3848875267175,19.62192020121106,25.88926237217787,1.9749052668889713,-18.538512569557994,-9.315419891495038,58.232711239576645,-119.70655249853377,80.46302077808511,-82.57388667481422,-255.60025925203018,-67.80947386301447,121.4794212995063,13.859804040726456,202.10891958905597,289.33699561903865,-53.84026788510968,147.75853654057175,30.709841161470898,-58.77980031762141,183.16604659565084,50.94542565632875,-36.02360824141309,184.5201050760169,-194.4973680663153,88.09606416062502,121.32323667682479,105.50454975796093,225.55853185642846,-91.78580216896597,-141.88424494072322,-201.60517536543819,-148.28651750873246,203.18360324017928,-195.80732271269335,-17.550815118335144,89.93641158461833,-65.46712045313103,82.92183773273398,-147.73268717843496,22.048591539069932,122.27445002412495,-55.39748189656167,-76.05201303998004,11.380731583762161,-31.744944384425988,-59.96965302532895,67.34534528686478,-19.045494372635954,215.36455175565462,-295.94662032883775,-103.98671227646881,60.23526349529168,76.56216887038755,-125.8529606820959,-52.89758037421899,-82.16104292148653,68.27941549262121,-227.58479803516835,-5.207533381235832],"yaxis":"y","type":"scatter"}],                        {"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}},"title":{"text":"QQplot of predicted and actual values","x":0.5,"y":0.925},"width":500,"height":450,"xaxis":{"title":{"text":"Prediction"}},"yaxis":{"title":{"text":"Actual target"}}},                        {"responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('d8fd5e63-c0ae-48e2-a163-202410cf3cd2');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };                });            </script>        </div>
</div>
</div>
</section>
</section>
</section>
<section id="real-dataset" class="level1">
<h1>Real dataset</h1>
<p>We look at the <a href="https://www.kaggle.com/datasets/camnugent/california-housing-prices">California</a> housing dataset from <code>sklearn.datasets</code> module. To illustrate the idea, we only work with the first <span class="math inline">\(1000\)</span> observations.</p>
<div id="ac08bbab" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_california_housing</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> fetch_california_housing()</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>X_real, y_real <span class="op">=</span> data[<span class="st">'data'</span>], data[<span class="st">'target'</span>]</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>X_train_real, X_test_real, y_train_real, y_test_real <span class="op">=</span> train_test_split(X_real[:<span class="dv">1000</span>,:], y_real[:<span class="dv">1000</span>], test_size<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'shape: x_train = </span><span class="sc">{}</span><span class="st"> , x_train = </span><span class="sc">{}</span><span class="st"> , y_train = </span><span class="sc">{}</span><span class="st"> , y_test = </span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(X_train_real.shape, X_test_real.shape, y_train_real.shape, y_test_real.shape))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>shape: x_train = (800, 8) , x_train = (200, 8) , y_train = (800,) , y_test = (200,)</code></pre>
</div>
</div>
<p>We gave some random parameters to the method as follows.</p>
<div id="c5413b71" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>gc_real <span class="op">=</span> MixCOBRARegressor(opt_method<span class="op">=</span><span class="st">"grad"</span>,</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>                            estimator_list<span class="op">=</span>[<span class="st">'random_forest'</span>, </span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>                                            <span class="st">'knn'</span>, </span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>                                            <span class="st">'ridge'</span>, </span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>                                            <span class="st">'lasso'</span>],</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>                            estimator_params<span class="op">=</span>{</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>                                <span class="st">'random_forest'</span> : {<span class="st">'n_estimators'</span>: <span class="dv">300</span>},</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>                                <span class="st">'knn'</span> : {<span class="st">'n_neighbors'</span> : <span class="dv">30</span>}</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>                        })</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>gc_real_fit <span class="op">=</span> gc_real.fit(X_train_real, y_train_real)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    * Gradient descent of two parameters with radial kernel is implemented...
        ~ Initial t = 0:        ~ (alpha, beta): (5.000, 2.550)     ~ |gradient|_1: 0.001    ~ threshold: 1e-05
        ~     Iteration: 1  ~ (alpha, beta): (5.000, 2.550)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001157      ~     Iteration: 2  ~ (alpha, beta): (5.000, 2.550)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001157      ~     Iteration: 3  ~ (alpha, beta): (5.000, 2.550)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001157      ~     Iteration: 4  ~ (alpha, beta): (5.000, 2.550)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001157      ~     Iteration: 5  ~ (alpha, beta): (4.998, 2.542)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000495      ~     Iteration: 6  ~ (alpha, beta): (4.999, 2.532)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.000503      ~     Iteration: 7  ~ (alpha, beta): (4.998, 2.521)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.000598      ~     Iteration: 8  ~ (alpha, beta): (4.998, 2.511)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000589      ~     Iteration: 9  ~ (alpha, beta): (4.999, 2.502)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000544      ~     Iteration: 10     ~ (alpha, beta): (5.000, 2.494)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000469      ~     Iteration: 11     ~ (alpha, beta): (5.001, 2.484)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.000555      ~     Iteration: 12     ~ (alpha, beta): (5.000, 2.476)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000483      ~     Iteration: 13     ~ (alpha, beta): (5.000, 2.468)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000429      ~     Iteration: 14     ~ (alpha, beta): (5.000, 2.462)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000330      ~     Iteration: 15     ~ (alpha, beta): (5.000, 2.454)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000411      ~     Iteration: 16     ~ (alpha, beta): (5.000, 2.448)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.000291      ~     Iteration: 17     ~ (alpha, beta): (5.000, 2.437)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000554      ~     Iteration: 18     ~ (alpha, beta): (5.000, 2.431)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000345      ~     Iteration: 19     ~ (alpha, beta): (5.000, 2.425)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.000313      ~     Iteration: 20     ~ (alpha, beta): (5.000, 2.418)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000433      ~     Iteration: 21     ~ (alpha, beta): (5.000, 2.413)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000303      ~     Iteration: 22     ~ (alpha, beta): (5.000, 2.409)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.000232      ~     Iteration: 23     ~ (alpha, beta): (5.000, 2.403)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.000372      ~     Iteration: 24     ~ (alpha, beta): (5.000, 2.398)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000381      ~     Iteration: 25     ~ (alpha, beta): (5.000, 2.394)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000306      ~     Iteration: 26     ~ (alpha, beta): (5.000, 2.390)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000248      ~     Iteration: 27     ~ (alpha, beta): (5.000, 2.386)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.000211      ~     Iteration: 28     ~ (alpha, beta): (5.000, 2.382)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000217      ~     Iteration: 29     ~ (alpha, beta): (5.000, 2.376)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000410      ~     Iteration: 30     ~ (alpha, beta): (5.000, 2.371)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.000272      ~     Iteration: 31     ~ (alpha, beta): (5.000, 2.366)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000249      ~     Iteration: 32     ~ (alpha, beta): (5.000, 2.362)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000224      ~     Iteration: 33     ~ (alpha, beta): (5.000, 2.360)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000198      ~     Iteration: 34     ~ (alpha, beta): (5.000, 2.360)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.000050      ~     Iteration: 35     ~ (alpha, beta): (5.000, 2.358)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.000145      ~     Iteration: 36     ~ (alpha, beta): (5.000, 2.355)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000134      ~     Iteration: 37     ~ (alpha, beta): (5.000, 2.352)     ~ |gradient|_1: -0.001  ~ stopping criterion: 0.000306      ~     Iteration: 38     ~ (alpha, beta): (5.000, 2.348)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000442      ~     Iteration: 39     ~ (alpha, beta): (5.000, 2.344)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000308      ~     Iteration: 40     ~ (alpha, beta): (5.001, 2.340)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.000268      ~     Iteration: 41     ~ (alpha, beta): (5.000, 2.339)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000093      ~     Iteration: 42     ~ (alpha, beta): (5.001, 2.335)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000251      ~     Iteration: 43     ~ (alpha, beta): (5.001, 2.329)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.000281      ~     Iteration: 44     ~ (alpha, beta): (5.000, 2.327)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000217      ~     Iteration: 45     ~ (alpha, beta): (5.001, 2.326)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000170      ~     Iteration: 46     ~ (alpha, beta): (5.001, 2.324)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.000199      ~     Iteration: 47     ~ (alpha, beta): (5.001, 2.323)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000082      ~     Iteration: 48     ~ (alpha, beta): (5.001, 2.323)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000047      ~     Iteration: 49     ~ (alpha, beta): (5.001, 2.325)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000162      ~     Iteration: 50     ~ (alpha, beta): (5.001, 2.325)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000107      ~     Iteration: 51     ~ (alpha, beta): (5.001, 2.324)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.000249      ~     Iteration: 52     ~ (alpha, beta): (5.001, 2.323)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.000141      ~     Iteration: 53     ~ (alpha, beta): (5.001, 2.322)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.000079      ~     Iteration: 54     ~ (alpha, beta): (5.001, 2.322)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000086      ~     Iteration: 55     ~ (alpha, beta): (5.001, 2.321)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.000099      ~     Iteration: 56     ~ (alpha, beta): (5.001, 2.320)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.000111      ~     Iteration: 57     ~ (alpha, beta): (5.001, 2.319)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.000205      ~     Iteration: 58     ~ (alpha, beta): (5.001, 2.318)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000088      ~     Iteration: 59     ~ (alpha, beta): (5.001, 2.320)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000142      ~     Iteration: 60     ~ (alpha, beta): (5.001, 2.319)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000251      ~     Iteration: 61     ~ (alpha, beta): (5.001, 2.318)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.000143      ~     Iteration: 62     ~ (alpha, beta): (5.001, 2.317)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.000086      ~     Iteration: 63     ~ (alpha, beta): (5.001, 2.317)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.000038      ~     Iteration: 64     ~ (alpha, beta): (5.001, 2.317)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.000062      ~     Iteration: 65     ~ (alpha, beta): (5.001, 2.318)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.000054      ~     Iteration: 66     ~ (alpha, beta): (5.001, 2.318)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.000032      ~     Iteration: 67     ~ (alpha, beta): (5.001, 2.317)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.000076      ~     Iteration: 68     ~ (alpha, beta): (5.001, 2.318)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.000167      ~     Iteration: 69     ~ (alpha, beta): (5.001, 2.317)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000067      ~     Iteration: 70     ~ (alpha, beta): (5.001, 2.317)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.000132      ~     Iteration: 71     ~ (alpha, beta): (5.001, 2.318)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.000161      ~     Iteration: 72     ~ (alpha, beta): (5.001, 2.318)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000133      ~     Iteration: 73     ~ (alpha, beta): (5.001, 2.317)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.000133      ~     Iteration: 74     ~ (alpha, beta): (5.001, 2.317)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.000105      ~     Iteration: 75     ~ (alpha, beta): (5.001, 2.317)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000116      ~     Iteration: 76     ~ (alpha, beta): (5.001, 2.317)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.000137      ~     Iteration: 77     ~ (alpha, beta): (5.001, 2.317)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.000038      ~     Iteration: 78     ~ (alpha, beta): (5.001, 2.317)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.000086      ~     Iteration: 79     ~ (alpha, beta): (5.001, 2.317)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.000125      ~     Iteration: 80     ~ (alpha, beta): (5.001, 2.317)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000080      ~     Iteration: 81     ~ (alpha, beta): (5.001, 2.317)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000032      ~     Iteration: 82     ~ (alpha, beta): (5.001, 2.317)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000189      ~     Iteration: 83     ~ (alpha, beta): (5.001, 2.317)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000152      ~     Iteration: 84     ~ (alpha, beta): (5.001, 2.317)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000167      ~     Iteration: 85     ~ (alpha, beta): (5.001, 2.317)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000078      ~     Iteration: 86     ~ (alpha, beta): (5.001, 2.317)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000046      ~     Iteration: 87     ~ (alpha, beta): (5.001, 2.317)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000195      ~     Iteration: 88     ~ (alpha, beta): (5.001, 2.317)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.000140      ~     Iteration: 89     ~ (alpha, beta): (5.001, 2.317)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.000140      ~     Iteration: 90     ~ (alpha, beta): (5.001, 2.317)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.000174      ~     Iteration: 91     ~ (alpha, beta): (5.001, 2.317)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.000031      ~     Iteration: 92     ~ (alpha, beta): (5.001, 2.317)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.000008                                                                                                                                                                                  ~    Stopped at: 92     ~ (alpha, beta): (5.001, 2.317)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.000008</code></pre>
</div>
</div>
<p>Now, let’s look at the obtained bandwidth and the optimization result.</p>
<div id="f72d8fdd" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># MixCOBRA with default parameter</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Estimated (alpha, beta) = (</span><span class="sc">{}</span><span class="st">, </span><span class="sc">{}</span><span class="st">)"</span>.<span class="bu">format</span>(gc_real_fit.optimization_outputs[<span class="st">'opt_alpha'</span>], gc_real_fit.optimization_outputs[<span class="st">'opt_beta'</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Estimated (alpha, beta) = (5.000548593352378, 2.317108668514407)</code></pre>
</div>
</div>
<p>We look at the numerical and graphical performance.</p>
<div id="73fc7fb2" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>y_pred_real <span class="op">=</span> gc_real_fit.predict(X_test_real)</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mean_absolute_percentage_error(y_test_real, y_pred_real))</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mean_squared_error(y_test_real, y_pred_real))</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>gc_real_fit.draw_learning_curve(y_test<span class="op">=</span>y_test_real, fig_type<span class="op">=</span><span class="st">'qq'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.1564928387746817
0.32411390750247704</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>                            <div id="adb1e063-0665-4867-8688-e3b838085fec" class="plotly-graph-div" style="height:450px; width:500px;"></div>            <script type="text/javascript">                require(["plotly"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("adb1e063-0665-4867-8688-e3b838085fec")) {                    Plotly.newPlot(                        "adb1e063-0665-4867-8688-e3b838085fec",                        [{"hovertemplate":"y_test=%{y}<extra></extra>","legendgroup":"","line":{"color":"red","dash":"solid"},"marker":{"symbol":"circle"},"mode":"lines","name":"","orientation":"v","showlegend":false,"x":[4.833,2.952,2.132,2.345,1.563,1.775,2.525,0.764,5.00001,2.664,1.609,1.148,1.816,1.512,1.25,1.671,1.417,1.531,0.82,2.778,1.22,3.588,2.062,2.573,0.824,1.188,1.582,1.0,2.192,3.628,2.917,1.981,2.385,2.063,2.056,2.242,4.758,1.673,2.042,3.011,2.835,1.448,4.661,1.584,2.899,2.213,1.781,1.023,2.306,1.791,1.905,2.75,3.932,1.831,2.737,2.713,3.5,2.108,2.068,2.454,1.944,2.184,1.789,2.952,0.943,1.74,2.309,3.356,1.904,1.779,2.686,1.326,2.821,1.617,3.661,2.542,1.895,3.334,2.25,2.992,2.47,2.93,0.833,2.0,2.989,2.292,1.981,2.317,1.964,2.08,1.406,2.398,3.673,2.825,2.155,1.497,1.799,0.983,4.125,2.529,2.875,1.079,1.423,1.619,5.00001,0.912,1.653,1.647,2.168,1.938,1.354,2.095,2.75,2.298,2.333,3.659,1.869,0.997,1.4,2.063,2.138,1.125,2.545,1.837,3.33,0.982,0.925,1.969,2.12,2.695,1.353,4.716,1.681,4.188,3.422,1.841,1.872,2.735,1.878,3.686,1.227,3.325,2.25,2.074,2.256,3.898,1.419,2.22,0.871,2.535,2.052,3.986,0.761,2.341,3.769,3.507,1.5,1.952,0.821,4.896,2.032,3.004,1.914,2.125,2.284,1.957,1.795,1.266,1.672,1.042,1.25,1.063,1.573,2.849,3.72,4.175,3.711,2.188,3.911,1.969,1.883,1.32,2.185,2.415,3.063,1.668,1.842,0.893,2.596,1.27,5.00001,2.258,1.625,2.54,2.751,0.923,1.827,0.871,2.489,1.607],"xaxis":"x","y":[4.833,2.952,2.132,2.345,1.563,1.775,2.525,0.764,5.00001,2.664,1.609,1.148,1.816,1.512,1.25,1.671,1.417,1.531,0.82,2.778,1.22,3.588,2.062,2.573,0.824,1.188,1.582,1.0,2.192,3.628,2.917,1.981,2.385,2.063,2.056,2.242,4.758,1.673,2.042,3.011,2.835,1.448,4.661,1.584,2.899,2.213,1.781,1.023,2.306,1.791,1.905,2.75,3.932,1.831,2.737,2.713,3.5,2.108,2.068,2.454,1.944,2.184,1.789,2.952,0.943,1.74,2.309,3.356,1.904,1.779,2.686,1.326,2.821,1.617,3.661,2.542,1.895,3.334,2.25,2.992,2.47,2.93,0.833,2.0,2.989,2.292,1.981,2.317,1.964,2.08,1.406,2.398,3.673,2.825,2.155,1.497,1.799,0.983,4.125,2.529,2.875,1.079,1.423,1.619,5.00001,0.912,1.653,1.647,2.168,1.938,1.354,2.095,2.75,2.298,2.333,3.659,1.869,0.997,1.4,2.063,2.138,1.125,2.545,1.837,3.33,0.982,0.925,1.969,2.12,2.695,1.353,4.716,1.681,4.188,3.422,1.841,1.872,2.735,1.878,3.686,1.227,3.325,2.25,2.074,2.256,3.898,1.419,2.22,0.871,2.535,2.052,3.986,0.761,2.341,3.769,3.507,1.5,1.952,0.821,4.896,2.032,3.004,1.914,2.125,2.284,1.957,1.795,1.266,1.672,1.042,1.25,1.063,1.573,2.849,3.72,4.175,3.711,2.188,3.911,1.969,1.883,1.32,2.185,2.415,3.063,1.668,1.842,0.893,2.596,1.27,5.00001,2.258,1.625,2.54,2.751,0.923,1.827,0.871,2.489,1.607],"yaxis":"y","type":"scatter"},{"hovertemplate":"y_pred=%{x}<br>y_test=%{y}<extra></extra>","legendgroup":"","marker":{"color":"#636efa","symbol":"circle"},"mode":"markers","name":"","orientation":"v","showlegend":false,"x":[2.643653644509061,2.827492353044297,2.1034675087314225,2.2491089964052735,1.890761005450245,1.9728415946772726,2.5380567683745068,1.174675879254153,3.607561803966481,2.4770349303940282,1.8801433517491977,1.379819061235763,1.93086603584311,1.6556559206921269,1.3949862103030835,1.7605097979209339,1.3729417849754006,1.9016708348920484,1.100789074649707,2.037747528152077,1.2789387774906489,3.228060696861372,2.3470207413145725,2.6293856370971613,1.2438475813133374,1.1451830236053913,1.757980776249296,1.1594269365992171,2.041630043210998,3.1632633392505953,2.5180188834858264,1.7370090206570352,2.0997785171060124,2.1752802607732233,1.7734741229803619,2.300097032451691,4.189874401542147,1.2730712704425045,1.9520087930407937,2.040564782117131,2.6418382127187963,1.9169416278974027,3.8622403936178573,1.5683268296040231,2.8240751163326783,2.288741119494293,1.8111462487433665,1.1610767061813703,1.9755090368487154,1.9347566830775376,1.9475714925169296,1.8073897788682045,3.189505108447414,1.6158427049237967,3.1956205607120407,2.111562468861848,1.3647263266751009,1.940585774606616,2.1969476957676353,1.923941183666721,2.0580504158879735,2.3688638530646315,1.8713460657350456,3.2555429965470877,1.4638609519196444,1.4084365574147204,2.3022549790739246,3.0249962888335733,1.8206523934054006,2.412386477256142,2.308082919840556,1.5378708112039616,1.9556051556649237,1.7085877442089243,3.1289535968677855,2.2866179739387187,1.942708886035949,3.263950960038506,2.399728832210336,2.3556321055490637,2.5213703148229722,3.16826398727688,1.9258282488078229,2.077160315517762,2.6846765052821846,2.1820460315037797,2.79362777761603,2.2734262617004526,2.278669626336964,2.245836140183623,1.7277242993016033,2.399612809837033,3.24586531991764,3.126379818798353,2.419803857040385,1.767288165321325,1.651979593473774,1.095439069776504,3.1708045430326384,2.2974917055832194,1.3968315320009967,1.2285016174073065,1.1391070346675394,1.7437544170971682,4.101258225247639,1.0934628307654635,1.9480157704337298,1.8260989239110752,2.3377371843024677,1.8976901441124305,1.8048914909762994,1.9481929777264564,1.4251681988158287,2.2313904307640366,2.7448416149751313,3.5869554390268132,2.1628180347485046,1.2662619879912735,1.3066523055508987,2.1510547836992973,2.096526702557953,1.0806757565105243,2.2846497103827064,1.9765663020290682,3.050886507742877,1.17187341053888,1.1403287737225662,2.2416465832197043,2.141000422195386,2.2259911561766703,1.6917268018603746,3.6302120769381867,1.8926040128211403,3.477622729227768,3.178745322050355,1.5472015500776277,2.0695317861338856,2.8270181650442776,2.5510641073337434,3.20211859664893,1.0613418609191576,2.5995109606234768,1.4619573527132363,2.534451708882966,2.16437698175643,3.2098174835868822,1.503158964556974,2.0714773575372565,1.0042210882033655,2.8285887475040448,2.046030781756573,3.1027056252460414,1.0199751274826097,2.266298584641252,3.0790001326618945,3.427076333127207,1.310883504425039,1.690854842435193,1.06122040919028,1.6219727384934903,2.142357705864865,3.0747616000157727,2.249708855409685,2.058357394493205,2.4888398217135963,1.9428860724899366,1.823402412679884,1.157459655870286,1.7067274852608136,1.0485795957280215,1.231671850530306,1.1810830965635781,1.8900537847937349,2.789922304007289,2.7890222957700974,3.3236438755108475,3.3606485772363803,1.632682764283162,3.306564106697788,1.9037650831903061,2.204346263004485,1.1536899668671037,2.0034336383887763,2.6603157764182765,3.05593234078568,2.133951516552684,1.9334802495254433,1.196680362698918,2.394521036010268,1.145342357499984,3.630419020320647,2.2330612982255107,4.977620211706039,2.305173546461754,2.5197086745339896,1.1556722743828933,1.7529181988432225,1.0225768081093118,2.267762621605236,1.7564272456530372],"xaxis":"x","y":[4.833,2.952,2.132,2.345,1.563,1.775,2.525,0.764,5.00001,2.664,1.609,1.148,1.816,1.512,1.25,1.671,1.417,1.531,0.82,2.778,1.22,3.588,2.062,2.573,0.824,1.188,1.582,1.0,2.192,3.628,2.917,1.981,2.385,2.063,2.056,2.242,4.758,1.673,2.042,3.011,2.835,1.448,4.661,1.584,2.899,2.213,1.781,1.023,2.306,1.791,1.905,2.75,3.932,1.831,2.737,2.713,3.5,2.108,2.068,2.454,1.944,2.184,1.789,2.952,0.943,1.74,2.309,3.356,1.904,1.779,2.686,1.326,2.821,1.617,3.661,2.542,1.895,3.334,2.25,2.992,2.47,2.93,0.833,2.0,2.989,2.292,1.981,2.317,1.964,2.08,1.406,2.398,3.673,2.825,2.155,1.497,1.799,0.983,4.125,2.529,2.875,1.079,1.423,1.619,5.00001,0.912,1.653,1.647,2.168,1.938,1.354,2.095,2.75,2.298,2.333,3.659,1.869,0.997,1.4,2.063,2.138,1.125,2.545,1.837,3.33,0.982,0.925,1.969,2.12,2.695,1.353,4.716,1.681,4.188,3.422,1.841,1.872,2.735,1.878,3.686,1.227,3.325,2.25,2.074,2.256,3.898,1.419,2.22,0.871,2.535,2.052,3.986,0.761,2.341,3.769,3.507,1.5,1.952,0.821,4.896,2.032,3.004,1.914,2.125,2.284,1.957,1.795,1.266,1.672,1.042,1.25,1.063,1.573,2.849,3.72,4.175,3.711,2.188,3.911,1.969,1.883,1.32,2.185,2.415,3.063,1.668,1.842,0.893,2.596,1.27,5.00001,2.258,1.625,2.54,2.751,0.923,1.827,0.871,2.489,1.607],"yaxis":"y","type":"scatter"}],                        {"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}},"title":{"text":"QQplot of predicted and actual values","x":0.5,"y":0.925},"width":500,"height":450,"xaxis":{"title":{"text":"Prediction"}},"yaxis":{"title":{"text":"Actual target"}}},                        {"responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('adb1e063-0665-4867-8688-e3b838085fec');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };                });            </script>        </div>
</div>
</div>
<section id="compare-to-adaboost" class="level3">
<h3 class="anchored" data-anchor-id="compare-to-adaboost">Compare to Adaboost</h3>
<p>We campare the fitted method on <code>California</code> data with Adaboost method.</p>
<div id="34b0f2e7" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> AdaBoostRegressor</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>ada <span class="op">=</span> AdaBoostRegressor(n_estimators<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>ada_fit <span class="op">=</span> ada.fit(X_train_real, y_train_real)</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>ada_pred <span class="op">=</span> ada_fit.predict(X_test_real)</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mean_absolute_percentage_error(y_test_real, ada_pred))</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mean_squared_error(y_test_real, ada_pred))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.250919725905263
0.29848698840195953</code></pre>
</div>
</div>
</section>
</section>
<section id="pretrained-basic-estimators" class="level1">
<h1>Pretrained basic estimators</h1>
<p>You can also train other models then aggregate them using our method. Here, we build pretrained estimators including <code>XGBoost</code> then aggregate it to some <code>sklearn</code> basic estimators in <code>MixCOBRARegressor</code>.</p>
<p>We first split the training data into two parts: <span class="math inline">\(X_k\)</span> for building basic estimators, and <span class="math inline">\(X_\ell\)</span> for aggregation. We use the constructed estimators to predict the test data and both the input <span class="math inline">\(X_{\text{test}}\)</span> and its predictions <strong>pred_feature_test</strong> are used in the final predictions.</p>
<div id="510572b7" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsRegressor</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeRegressor</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a><span class="co"># X_k and X_l split</span></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>id_k <span class="op">=</span> np.random.permutation(<span class="bu">range</span>(<span class="bu">len</span>(y_train_real)))</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>k <span class="op">=</span><span class="bu">int</span>(<span class="fl">.5</span> <span class="op">*</span> <span class="bu">len</span>(y_train_real))</span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>X_k, X_l, y_k, y_l <span class="op">=</span> X_train_real[id_k[:k],:], X_train_real[id_k[k:],:], y_train_real[id_k[:k]], y_train_real[id_k[k:]]</span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Building basic estiators</span></span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a>rf_real <span class="op">=</span> RandomForestRegressor(n_estimators<span class="op">=</span><span class="dv">300</span>).fit(X_k, y_k)</span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a>lm_real <span class="op">=</span> LinearRegression().fit(X_k, y_k)</span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a>knn_real <span class="op">=</span> KNeighborsRegressor(n_neighbors<span class="op">=</span><span class="dv">10</span>).fit(X_k, y_k)</span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a>tr_real <span class="op">=</span> DecisionTreeRegressor(min_samples_leaf<span class="op">=</span><span class="dv">5</span>).fit(X_k, y_k)</span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a><span class="co"># External XGBoost estiator</span></span>
<span id="cb39-19"><a href="#cb39-19" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> xgboost </span>
<span id="cb39-20"><a href="#cb39-20" aria-hidden="true" tabindex="-1"></a>xgb <span class="op">=</span> xgboost.XGBRegressor(n_estimators <span class="op">=</span> <span class="dv">500</span>)</span>
<span id="cb39-21"><a href="#cb39-21" aria-hidden="true" tabindex="-1"></a>xgb_real <span class="op">=</span> xgb.fit(X_k, y_k)</span>
<span id="cb39-22"><a href="#cb39-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-23"><a href="#cb39-23" aria-hidden="true" tabindex="-1"></a><span class="co"># All pretrained estimators</span></span>
<span id="cb39-24"><a href="#cb39-24" aria-hidden="true" tabindex="-1"></a>basic_estimators <span class="op">=</span> (rf_real, lm_real, knn_real, tr_real, xgb_real)</span>
<span id="cb39-25"><a href="#cb39-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-26"><a href="#cb39-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Predicted features on X_l for aggregation</span></span>
<span id="cb39-27"><a href="#cb39-27" aria-hidden="true" tabindex="-1"></a>pred_feature_l <span class="op">=</span> np.column_stack([est.predict(X_l) <span class="cf">for</span> est <span class="kw">in</span> basic_estimators])</span>
<span id="cb39-28"><a href="#cb39-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-29"><a href="#cb39-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Predicted features on Testing data</span></span>
<span id="cb39-30"><a href="#cb39-30" aria-hidden="true" tabindex="-1"></a>pred_feature_test <span class="op">=</span> np.column_stack([est.predict(X_test_real) <span class="cf">for</span> est <span class="kw">in</span> basic_estimators])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>To fit the aggregation method on predicted features, we need to provide both input and predicted features to <code>fit</code> method.</p>
<div id="73d56c02" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>gc4_fit <span class="op">=</span> MixCOBRARegressor(opt_method<span class="op">=</span><span class="st">'grad'</span>).fit(X<span class="op">=</span>X_l,</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>                                                   Pred_features<span class="op">=</span>pred_feature_l,</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>                                                   y<span class="op">=</span>y_l)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    * Gradient descent of two parameters with radial kernel is implemented...
        ~ Initial t = 0:        ~ (alpha, beta): (5.000, 5.000)     ~ |gradient|_1: 0.006    ~ threshold: 1e-05
        ~     Iteration: 1  ~ (alpha, beta): (5.000, 5.000)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.003684      ~     Iteration: 2  ~ (alpha, beta): (5.000, 5.000)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.003684      ~     Iteration: 3  ~ (alpha, beta): (5.000, 5.000)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.003684      ~     Iteration: 4  ~ (alpha, beta): (5.000, 5.000)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.003684      ~     Iteration: 5  ~ (alpha, beta): (5.000, 5.010)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.003184      ~     Iteration: 6  ~ (alpha, beta): (5.000, 5.019)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.003006      ~     Iteration: 7  ~ (alpha, beta): (5.000, 5.029)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002989      ~     Iteration: 8  ~ (alpha, beta): (5.000, 5.038)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002930      ~     Iteration: 9  ~ (alpha, beta): (5.000, 5.047)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002956      ~     Iteration: 10     ~ (alpha, beta): (5.000, 5.056)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002860      ~     Iteration: 11     ~ (alpha, beta): (5.000, 5.065)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.003091      ~     Iteration: 12     ~ (alpha, beta): (5.000, 5.075)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002977      ~     Iteration: 13     ~ (alpha, beta): (5.000, 5.084)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002964      ~     Iteration: 14     ~ (alpha, beta): (5.000, 5.093)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.003179      ~     Iteration: 15     ~ (alpha, beta): (5.000, 5.103)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.003009      ~     Iteration: 16     ~ (alpha, beta): (5.000, 5.112)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002965      ~     Iteration: 17     ~ (alpha, beta): (5.000, 5.122)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.003222      ~     Iteration: 18     ~ (alpha, beta): (5.000, 5.130)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002872      ~     Iteration: 19     ~ (alpha, beta): (5.000, 5.139)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002926      ~     Iteration: 20     ~ (alpha, beta): (5.000, 5.148)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002747      ~     Iteration: 21     ~ (alpha, beta): (5.000, 5.157)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002973      ~     Iteration: 22     ~ (alpha, beta): (5.000, 5.165)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002900      ~     Iteration: 23     ~ (alpha, beta): (5.000, 5.174)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002754      ~     Iteration: 24     ~ (alpha, beta): (5.000, 5.183)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002792      ~     Iteration: 25     ~ (alpha, beta): (5.000, 5.191)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002734      ~     Iteration: 26     ~ (alpha, beta): (5.000, 5.200)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002786      ~     Iteration: 27     ~ (alpha, beta): (5.000, 5.208)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002624      ~     Iteration: 28     ~ (alpha, beta): (5.000, 5.217)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002831      ~     Iteration: 29     ~ (alpha, beta): (5.000, 5.226)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002864      ~     Iteration: 30     ~ (alpha, beta): (5.000, 5.234)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002620      ~     Iteration: 31     ~ (alpha, beta): (5.000, 5.242)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002587      ~     Iteration: 32     ~ (alpha, beta): (5.000, 5.250)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002673      ~     Iteration: 33     ~ (alpha, beta): (5.000, 5.258)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002781      ~     Iteration: 34     ~ (alpha, beta): (5.000, 5.267)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002680      ~     Iteration: 35     ~ (alpha, beta): (5.000, 5.274)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002451      ~     Iteration: 36     ~ (alpha, beta): (5.000, 5.283)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002912      ~     Iteration: 37     ~ (alpha, beta): (5.000, 5.291)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002631      ~     Iteration: 38     ~ (alpha, beta): (5.000, 5.299)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002792      ~     Iteration: 39     ~ (alpha, beta): (5.000, 5.307)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002628      ~     Iteration: 40     ~ (alpha, beta): (5.000, 5.316)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002782      ~     Iteration: 41     ~ (alpha, beta): (5.000, 5.323)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002499      ~     Iteration: 42     ~ (alpha, beta): (5.000, 5.332)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002768      ~     Iteration: 43     ~ (alpha, beta): (5.000, 5.340)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002746      ~     Iteration: 44     ~ (alpha, beta): (5.000, 5.348)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002520      ~     Iteration: 45     ~ (alpha, beta): (5.000, 5.356)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002516      ~     Iteration: 46     ~ (alpha, beta): (5.000, 5.363)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002535      ~     Iteration: 47     ~ (alpha, beta): (5.000, 5.371)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002411      ~     Iteration: 48     ~ (alpha, beta): (5.000, 5.379)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002809      ~     Iteration: 49     ~ (alpha, beta): (5.000, 5.387)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002579      ~     Iteration: 50     ~ (alpha, beta): (5.000, 5.394)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002353      ~     Iteration: 51     ~ (alpha, beta): (5.000, 5.402)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002564      ~     Iteration: 52     ~ (alpha, beta): (5.000, 5.410)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002442      ~     Iteration: 53     ~ (alpha, beta): (5.000, 5.417)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002571      ~     Iteration: 54     ~ (alpha, beta): (5.000, 5.425)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002469      ~     Iteration: 55     ~ (alpha, beta): (5.000, 5.432)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002442      ~     Iteration: 56     ~ (alpha, beta): (5.000, 5.440)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002386      ~     Iteration: 57     ~ (alpha, beta): (5.000, 5.447)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002377      ~     Iteration: 58     ~ (alpha, beta): (5.000, 5.454)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002327      ~     Iteration: 59     ~ (alpha, beta): (5.000, 5.462)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002448      ~     Iteration: 60     ~ (alpha, beta): (5.000, 5.469)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002350      ~     Iteration: 61     ~ (alpha, beta): (5.000, 5.476)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002414      ~     Iteration: 62     ~ (alpha, beta): (5.000, 5.483)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002315      ~     Iteration: 63     ~ (alpha, beta): (5.000, 5.491)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002400      ~     Iteration: 64     ~ (alpha, beta): (5.000, 5.498)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002337      ~     Iteration: 65     ~ (alpha, beta): (5.000, 5.505)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002446      ~     Iteration: 66     ~ (alpha, beta): (5.000, 5.513)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002459      ~     Iteration: 67     ~ (alpha, beta): (5.000, 5.519)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002122      ~     Iteration: 68     ~ (alpha, beta): (5.000, 5.527)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002417      ~     Iteration: 69     ~ (alpha, beta): (5.000, 5.534)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002295      ~     Iteration: 70     ~ (alpha, beta): (5.000, 5.541)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002356      ~     Iteration: 71     ~ (alpha, beta): (5.000, 5.548)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002526      ~     Iteration: 72     ~ (alpha, beta): (5.000, 5.555)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002175      ~     Iteration: 73     ~ (alpha, beta): (5.000, 5.562)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002324      ~     Iteration: 74     ~ (alpha, beta): (5.000, 5.569)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002379      ~     Iteration: 75     ~ (alpha, beta): (5.000, 5.576)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002244      ~     Iteration: 76     ~ (alpha, beta): (5.000, 5.583)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002192      ~     Iteration: 77     ~ (alpha, beta): (5.000, 5.589)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002060      ~     Iteration: 78     ~ (alpha, beta): (5.000, 5.596)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002336      ~     Iteration: 79     ~ (alpha, beta): (5.000, 5.603)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002180      ~     Iteration: 80     ~ (alpha, beta): (5.000, 5.610)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002264      ~     Iteration: 81     ~ (alpha, beta): (5.000, 5.617)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002316      ~     Iteration: 82     ~ (alpha, beta): (5.000, 5.624)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002174      ~     Iteration: 83     ~ (alpha, beta): (5.000, 5.630)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002180      ~     Iteration: 84     ~ (alpha, beta): (5.000, 5.637)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002364      ~     Iteration: 85     ~ (alpha, beta): (5.000, 5.644)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002306      ~     Iteration: 86     ~ (alpha, beta): (5.000, 5.651)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002126      ~     Iteration: 87     ~ (alpha, beta): (5.000, 5.657)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002288      ~     Iteration: 88     ~ (alpha, beta): (5.000, 5.664)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002243      ~     Iteration: 89     ~ (alpha, beta): (5.000, 5.670)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001986      ~     Iteration: 90     ~ (alpha, beta): (5.000, 5.677)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001983      ~     Iteration: 91     ~ (alpha, beta): (5.000, 5.683)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002158      ~     Iteration: 92     ~ (alpha, beta): (5.000, 5.690)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002010      ~     Iteration: 93     ~ (alpha, beta): (5.000, 5.696)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002103      ~     Iteration: 94     ~ (alpha, beta): (5.000, 5.703)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002199      ~     Iteration: 95     ~ (alpha, beta): (5.000, 5.709)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002165      ~     Iteration: 96     ~ (alpha, beta): (5.000, 5.716)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002095      ~     Iteration: 97     ~ (alpha, beta): (5.000, 5.722)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002110      ~     Iteration: 98     ~ (alpha, beta): (5.000, 5.729)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002101      ~     Iteration: 99     ~ (alpha, beta): (5.000, 5.735)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002117      ~     Iteration: 100    ~ (alpha, beta): (5.000, 5.741)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001875      ~     Iteration: 101    ~ (alpha, beta): (5.000, 5.747)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001887      ~     Iteration: 102    ~ (alpha, beta): (5.000, 5.753)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002039      ~     Iteration: 103    ~ (alpha, beta): (5.000, 5.758)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001839      ~     Iteration: 104    ~ (alpha, beta): (5.000, 5.764)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001845      ~     Iteration: 105    ~ (alpha, beta): (5.000, 5.770)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002123      ~     Iteration: 106    ~ (alpha, beta): (5.000, 5.776)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001850      ~     Iteration: 107    ~ (alpha, beta): (5.000, 5.782)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002079      ~     Iteration: 108    ~ (alpha, beta): (5.000, 5.789)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002140      ~     Iteration: 109    ~ (alpha, beta): (5.000, 5.795)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001993      ~     Iteration: 110    ~ (alpha, beta): (5.000, 5.801)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001912      ~     Iteration: 111    ~ (alpha, beta): (5.000, 5.807)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002008      ~     Iteration: 112    ~ (alpha, beta): (5.000, 5.814)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002240      ~     Iteration: 113    ~ (alpha, beta): (5.000, 5.820)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.002070      ~     Iteration: 114    ~ (alpha, beta): (5.000, 5.826)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002110      ~     Iteration: 115    ~ (alpha, beta): (5.000, 5.832)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.002016      ~     Iteration: 116    ~ (alpha, beta): (5.000, 5.837)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001858      ~     Iteration: 117    ~ (alpha, beta): (5.000, 5.842)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001813      ~     Iteration: 118    ~ (alpha, beta): (5.000, 5.848)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001778      ~     Iteration: 119    ~ (alpha, beta): (5.000, 5.853)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001933      ~     Iteration: 120    ~ (alpha, beta): (5.000, 5.859)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001948      ~     Iteration: 121    ~ (alpha, beta): (5.000, 5.865)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001878      ~     Iteration: 122    ~ (alpha, beta): (5.000, 5.870)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001739      ~     Iteration: 123    ~ (alpha, beta): (5.000, 5.876)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001896      ~     Iteration: 124    ~ (alpha, beta): (5.000, 5.881)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001733      ~     Iteration: 125    ~ (alpha, beta): (5.000, 5.887)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001808      ~     Iteration: 126    ~ (alpha, beta): (5.000, 5.892)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001761      ~     Iteration: 127    ~ (alpha, beta): (5.000, 5.899)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001992      ~     Iteration: 128    ~ (alpha, beta): (5.000, 5.904)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001817      ~     Iteration: 129    ~ (alpha, beta): (5.000, 5.909)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001713      ~     Iteration: 130    ~ (alpha, beta): (5.000, 5.915)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001741      ~     Iteration: 131    ~ (alpha, beta): (5.000, 5.920)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001787      ~     Iteration: 132    ~ (alpha, beta): (5.000, 5.926)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001876      ~     Iteration: 133    ~ (alpha, beta): (5.000, 5.931)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001681      ~     Iteration: 134    ~ (alpha, beta): (5.000, 5.937)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001731      ~     Iteration: 135    ~ (alpha, beta): (5.000, 5.942)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001846      ~     Iteration: 136    ~ (alpha, beta): (5.000, 5.947)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001645      ~     Iteration: 137    ~ (alpha, beta): (5.000, 5.952)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001741      ~     Iteration: 138    ~ (alpha, beta): (5.000, 5.958)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001737      ~     Iteration: 139    ~ (alpha, beta): (5.000, 5.963)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001858      ~     Iteration: 140    ~ (alpha, beta): (5.000, 5.969)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001747      ~     Iteration: 141    ~ (alpha, beta): (5.000, 5.974)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001764      ~     Iteration: 142    ~ (alpha, beta): (5.000, 5.979)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001656      ~     Iteration: 143    ~ (alpha, beta): (5.000, 5.984)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001754      ~     Iteration: 144    ~ (alpha, beta): (5.000, 5.990)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001945      ~     Iteration: 145    ~ (alpha, beta): (5.000, 5.995)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001738      ~     Iteration: 146    ~ (alpha, beta): (5.000, 6.000)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001630      ~     Iteration: 147    ~ (alpha, beta): (5.000, 6.006)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001750      ~     Iteration: 148    ~ (alpha, beta): (5.000, 6.011)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001782      ~     Iteration: 149    ~ (alpha, beta): (5.000, 6.017)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001762      ~     Iteration: 150    ~ (alpha, beta): (5.000, 6.022)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001867      ~     Iteration: 151    ~ (alpha, beta): (5.000, 6.027)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001696      ~     Iteration: 152    ~ (alpha, beta): (5.000, 6.033)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001754      ~     Iteration: 153    ~ (alpha, beta): (5.000, 6.038)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001815      ~     Iteration: 154    ~ (alpha, beta): (5.000, 6.043)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001646      ~     Iteration: 155    ~ (alpha, beta): (5.000, 6.048)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001631      ~     Iteration: 156    ~ (alpha, beta): (5.000, 6.053)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001519      ~     Iteration: 157    ~ (alpha, beta): (5.000, 6.058)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001613      ~     Iteration: 158    ~ (alpha, beta): (5.000, 6.063)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001746      ~     Iteration: 159    ~ (alpha, beta): (5.000, 6.068)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001832      ~     Iteration: 160    ~ (alpha, beta): (5.000, 6.073)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001648      ~     Iteration: 161    ~ (alpha, beta): (5.000, 6.078)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001655      ~     Iteration: 162    ~ (alpha, beta): (5.000, 6.083)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001699      ~     Iteration: 163    ~ (alpha, beta): (5.000, 6.088)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001568      ~     Iteration: 164    ~ (alpha, beta): (5.000, 6.094)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001770      ~     Iteration: 165    ~ (alpha, beta): (5.000, 6.099)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001645      ~     Iteration: 166    ~ (alpha, beta): (5.000, 6.103)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001409      ~     Iteration: 167    ~ (alpha, beta): (5.000, 6.108)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001673      ~     Iteration: 168    ~ (alpha, beta): (5.000, 6.113)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001624      ~     Iteration: 169    ~ (alpha, beta): (5.000, 6.118)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001610      ~     Iteration: 170    ~ (alpha, beta): (5.000, 6.123)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001641      ~     Iteration: 171    ~ (alpha, beta): (5.000, 6.128)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001653      ~     Iteration: 172    ~ (alpha, beta): (5.000, 6.133)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001561      ~     Iteration: 173    ~ (alpha, beta): (5.000, 6.137)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001651      ~     Iteration: 174    ~ (alpha, beta): (5.000, 6.142)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001620      ~     Iteration: 175    ~ (alpha, beta): (5.000, 6.147)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001573      ~     Iteration: 176    ~ (alpha, beta): (5.000, 6.152)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001496      ~     Iteration: 177    ~ (alpha, beta): (5.000, 6.156)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001474      ~     Iteration: 178    ~ (alpha, beta): (5.000, 6.161)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001536      ~     Iteration: 179    ~ (alpha, beta): (5.000, 6.165)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001508      ~     Iteration: 180    ~ (alpha, beta): (5.000, 6.170)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001564      ~     Iteration: 181    ~ (alpha, beta): (5.000, 6.175)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001717      ~     Iteration: 182    ~ (alpha, beta): (5.000, 6.180)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001555      ~     Iteration: 183    ~ (alpha, beta): (5.000, 6.184)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001536      ~     Iteration: 184    ~ (alpha, beta): (5.000, 6.189)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001637      ~     Iteration: 185    ~ (alpha, beta): (5.000, 6.194)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001391      ~     Iteration: 186    ~ (alpha, beta): (5.000, 6.199)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001766      ~     Iteration: 187    ~ (alpha, beta): (5.000, 6.204)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001666      ~     Iteration: 188    ~ (alpha, beta): (5.000, 6.208)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001397      ~     Iteration: 189    ~ (alpha, beta): (5.000, 6.213)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001621      ~     Iteration: 190    ~ (alpha, beta): (5.000, 6.218)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001481      ~     Iteration: 191    ~ (alpha, beta): (5.000, 6.222)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001466      ~     Iteration: 192    ~ (alpha, beta): (5.000, 6.227)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001470      ~     Iteration: 193    ~ (alpha, beta): (5.000, 6.231)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001398      ~     Iteration: 194    ~ (alpha, beta): (5.000, 6.235)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001510      ~     Iteration: 195    ~ (alpha, beta): (5.000, 6.239)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001401      ~     Iteration: 196    ~ (alpha, beta): (5.000, 6.244)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001589      ~     Iteration: 197    ~ (alpha, beta): (5.000, 6.249)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001546      ~     Iteration: 198    ~ (alpha, beta): (5.000, 6.253)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001424      ~     Iteration: 199    ~ (alpha, beta): (5.000, 6.258)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001450      ~     Iteration: 200    ~ (alpha, beta): (5.000, 6.262)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001400      ~     Iteration: 201    ~ (alpha, beta): (5.000, 6.267)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001622      ~     Iteration: 202    ~ (alpha, beta): (5.000, 6.272)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001522      ~     Iteration: 203    ~ (alpha, beta): (5.000, 6.276)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001480      ~     Iteration: 204    ~ (alpha, beta): (5.000, 6.280)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001520      ~     Iteration: 205    ~ (alpha, beta): (5.000, 6.284)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001379      ~     Iteration: 206    ~ (alpha, beta): (5.000, 6.289)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001341      ~     Iteration: 207    ~ (alpha, beta): (5.000, 6.293)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001416      ~     Iteration: 208    ~ (alpha, beta): (5.000, 6.297)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001503      ~     Iteration: 209    ~ (alpha, beta): (5.000, 6.301)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001422      ~     Iteration: 210    ~ (alpha, beta): (5.000, 6.305)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001316      ~     Iteration: 211    ~ (alpha, beta): (5.000, 6.310)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001399      ~     Iteration: 212    ~ (alpha, beta): (5.000, 6.314)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001333      ~     Iteration: 213    ~ (alpha, beta): (5.000, 6.318)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001398      ~     Iteration: 214    ~ (alpha, beta): (5.000, 6.322)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001481      ~     Iteration: 215    ~ (alpha, beta): (5.000, 6.327)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001565      ~     Iteration: 216    ~ (alpha, beta): (5.000, 6.331)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001300      ~     Iteration: 217    ~ (alpha, beta): (5.000, 6.335)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001378      ~     Iteration: 218    ~ (alpha, beta): (5.000, 6.340)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001487      ~     Iteration: 219    ~ (alpha, beta): (5.000, 6.344)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001307      ~     Iteration: 220    ~ (alpha, beta): (5.000, 6.348)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001340      ~     Iteration: 221    ~ (alpha, beta): (5.000, 6.352)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001338      ~     Iteration: 222    ~ (alpha, beta): (5.000, 6.356)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001320      ~     Iteration: 223    ~ (alpha, beta): (5.000, 6.359)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001279      ~     Iteration: 224    ~ (alpha, beta): (5.000, 6.364)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001550      ~     Iteration: 225    ~ (alpha, beta): (5.000, 6.368)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001437      ~     Iteration: 226    ~ (alpha, beta): (5.000, 6.372)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001322      ~     Iteration: 227    ~ (alpha, beta): (5.000, 6.376)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001261      ~     Iteration: 228    ~ (alpha, beta): (5.000, 6.380)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001322      ~     Iteration: 229    ~ (alpha, beta): (5.000, 6.384)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001382      ~     Iteration: 230    ~ (alpha, beta): (5.000, 6.387)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001167      ~     Iteration: 231    ~ (alpha, beta): (5.000, 6.391)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001398      ~     Iteration: 232    ~ (alpha, beta): (5.000, 6.396)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001447      ~     Iteration: 233    ~ (alpha, beta): (5.000, 6.400)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001288      ~     Iteration: 234    ~ (alpha, beta): (5.000, 6.403)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001249      ~     Iteration: 235    ~ (alpha, beta): (5.000, 6.407)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001248      ~     Iteration: 236    ~ (alpha, beta): (5.000, 6.411)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001302      ~     Iteration: 237    ~ (alpha, beta): (5.000, 6.415)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001218      ~     Iteration: 238    ~ (alpha, beta): (5.000, 6.419)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001493      ~     Iteration: 239    ~ (alpha, beta): (5.000, 6.423)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001354      ~     Iteration: 240    ~ (alpha, beta): (5.000, 6.426)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001195      ~     Iteration: 241    ~ (alpha, beta): (5.000, 6.430)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001212      ~     Iteration: 242    ~ (alpha, beta): (5.000, 6.434)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001350      ~     Iteration: 243    ~ (alpha, beta): (5.000, 6.438)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001278      ~     Iteration: 244    ~ (alpha, beta): (5.000, 6.441)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001106      ~     Iteration: 245    ~ (alpha, beta): (5.000, 6.446)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001514      ~     Iteration: 246    ~ (alpha, beta): (5.000, 6.449)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001281      ~     Iteration: 247    ~ (alpha, beta): (5.000, 6.453)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001199      ~     Iteration: 248    ~ (alpha, beta): (5.000, 6.457)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001242      ~     Iteration: 249    ~ (alpha, beta): (5.000, 6.461)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001318      ~     Iteration: 250    ~ (alpha, beta): (5.000, 6.465)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001244      ~     Iteration: 251    ~ (alpha, beta): (5.000, 6.468)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001102      ~     Iteration: 252    ~ (alpha, beta): (5.000, 6.472)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001252      ~     Iteration: 253    ~ (alpha, beta): (5.000, 6.475)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001368      ~     Iteration: 254    ~ (alpha, beta): (5.000, 6.480)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001446      ~     Iteration: 255    ~ (alpha, beta): (5.000, 6.483)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001116      ~     Iteration: 256    ~ (alpha, beta): (5.000, 6.487)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001328      ~     Iteration: 257    ~ (alpha, beta): (5.000, 6.490)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001109      ~     Iteration: 258    ~ (alpha, beta): (5.000, 6.494)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001333      ~     Iteration: 259    ~ (alpha, beta): (5.000, 6.498)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001273      ~     Iteration: 260    ~ (alpha, beta): (5.000, 6.501)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001268      ~     Iteration: 261    ~ (alpha, beta): (5.000, 6.505)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001158      ~     Iteration: 262    ~ (alpha, beta): (5.000, 6.508)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001132      ~     Iteration: 263    ~ (alpha, beta): (5.000, 6.512)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001189      ~     Iteration: 264    ~ (alpha, beta): (5.000, 6.515)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001210      ~     Iteration: 265    ~ (alpha, beta): (5.000, 6.519)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001257      ~     Iteration: 266    ~ (alpha, beta): (5.000, 6.523)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001232      ~     Iteration: 267    ~ (alpha, beta): (5.000, 6.526)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001150      ~     Iteration: 268    ~ (alpha, beta): (5.000, 6.530)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001167      ~     Iteration: 269    ~ (alpha, beta): (5.000, 6.533)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001218      ~     Iteration: 270    ~ (alpha, beta): (5.000, 6.537)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001250      ~     Iteration: 271    ~ (alpha, beta): (5.000, 6.541)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001172      ~     Iteration: 272    ~ (alpha, beta): (5.000, 6.544)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001046      ~     Iteration: 273    ~ (alpha, beta): (5.000, 6.547)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001157      ~     Iteration: 274    ~ (alpha, beta): (5.000, 6.551)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001089      ~     Iteration: 275    ~ (alpha, beta): (5.000, 6.554)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001120      ~     Iteration: 276    ~ (alpha, beta): (5.000, 6.558)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001252      ~     Iteration: 277    ~ (alpha, beta): (5.000, 6.561)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001161      ~     Iteration: 278    ~ (alpha, beta): (5.000, 6.565)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001222      ~     Iteration: 279    ~ (alpha, beta): (5.000, 6.569)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001410      ~     Iteration: 280    ~ (alpha, beta): (5.000, 6.572)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001318      ~     Iteration: 281    ~ (alpha, beta): (5.000, 6.576)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001272      ~     Iteration: 282    ~ (alpha, beta): (5.000, 6.580)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001205      ~     Iteration: 283    ~ (alpha, beta): (5.000, 6.583)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001144      ~     Iteration: 284    ~ (alpha, beta): (5.000, 6.588)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001412      ~     Iteration: 285    ~ (alpha, beta): (5.000, 6.591)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001296      ~     Iteration: 286    ~ (alpha, beta): (5.000, 6.594)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001107      ~     Iteration: 287    ~ (alpha, beta): (5.000, 6.598)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001186      ~     Iteration: 288    ~ (alpha, beta): (5.000, 6.601)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001058      ~     Iteration: 289    ~ (alpha, beta): (5.000, 6.604)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001250      ~     Iteration: 290    ~ (alpha, beta): (5.000, 6.607)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001012      ~     Iteration: 291    ~ (alpha, beta): (5.000, 6.611)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001281      ~     Iteration: 292    ~ (alpha, beta): (5.000, 6.615)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001089      ~     Iteration: 293    ~ (alpha, beta): (5.000, 6.618)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001187      ~     Iteration: 294    ~ (alpha, beta): (5.000, 6.621)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001177      ~     Iteration: 295    ~ (alpha, beta): (5.000, 6.625)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001143      ~     Iteration: 296    ~ (alpha, beta): (5.000, 6.628)     ~ |gradient|_1: -0.000  ~ stopping criterion: 0.001025      ~     Iteration: 297    ~ (alpha, beta): (5.000, 6.631)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001138      ~     Iteration: 298    ~ (alpha, beta): (5.000, 6.634)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001108      ~     Iteration: 299    ~ (alpha, beta): (5.000, 6.638)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001194      ~     Iteration: 300    ~ (alpha, beta): (5.000, 6.641)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001123                                                                                                                                                                                  ~    Stopped at: 300    ~ (alpha, beta): (5.000, 6.641)     ~ |gradient|_1: 0.000   ~ stopping criterion: 0.001123</code></pre>
</div>
</div>
<p>We look at the optimization algorithm performance.</p>
<div id="e2decd6e" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># MixCOBRA with default parameter</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Estimated (alpha, beta) = (</span><span class="sc">{}</span><span class="st">, </span><span class="sc">{}</span><span class="st">)"</span>.<span class="bu">format</span>(gc4_fit.optimization_outputs[<span class="st">'opt_alpha'</span>], gc4_fit.optimization_outputs[<span class="st">'opt_beta'</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Estimated (alpha, beta) = (4.999634631160196, 6.640839606789822)</code></pre>
</div>
</div>
<p>Now, let’s look at the result.</p>
<div id="014f96c9" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>pred_add <span class="op">=</span> gc4_fit.predict(X <span class="op">=</span> X_test_real, </span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>                           Pred_X <span class="op">=</span> pred_feature_test)</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mean_absolute_percentage_error(y_test_real, pred_add))</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mean_squared_error(y_test_real, pred_add))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.13380171835111443
0.2554615776412746</code></pre>
</div>
</div>
<!-- -->

</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        for (let i = 0; i < 2; i++) {
          container.appendChild(note.children[i].cloneNode(true));
        }
        return container.innerHTML
      } else {
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      return note.innerHTML;
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        console.log("RESIZE");
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb46" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "MixCOBRARegressor of [`gradientcobra v1.0.8`](https://pypi.org/project/gradientcobra/) package"</span></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "[`Sothea HAS`](https://hassothea.github.io/)"</span></span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span><span class="co"> </span></span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a><span class="co">    html:</span></span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a><span class="co">        anchor-sections: true</span></span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a><span class="co">        code-tools: true</span></span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a><span class="an">toc:</span><span class="co"> true</span></span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a><span class="an">toc-depth:</span><span class="co"> 3</span></span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a><span class="an">jupyter:</span><span class="co"> python3</span></span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a><span class="fu"># Installing and importing packages</span></span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-15"><a href="#cb46-15" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">gradientcobra</span><span class="co">](https://pypi.org/project/gradientcobra/)</span> can be installed from <span class="co">[</span><span class="ot">pypi</span><span class="co">](https://pypi.org/)</span> using <span class="in">`pip`</span>:</span>
<span id="cb46-16"><a href="#cb46-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-17"><a href="#cb46-17" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; ``pip install gradientcobra``</span></span>
<span id="cb46-18"><a href="#cb46-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-19"><a href="#cb46-19" aria-hidden="true" tabindex="-1"></a><span class="fu">## Importing packages</span></span>
<span id="cb46-20"><a href="#cb46-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-23"><a href="#cb46-23" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb46-24"><a href="#cb46-24" aria-hidden="true" tabindex="-1"></a><span class="co"># | warning: false</span></span>
<span id="cb46-25"><a href="#cb46-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-26"><a href="#cb46-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Metric of error</span></span>
<span id="cb46-27"><a href="#cb46-27" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error, mean_absolute_error, mean_absolute_percentage_error</span>
<span id="cb46-28"><a href="#cb46-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-29"><a href="#cb46-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting figures</span></span>
<span id="cb46-30"><a href="#cb46-30" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb46-31"><a href="#cb46-31" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> cm</span>
<span id="cb46-32"><a href="#cb46-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-33"><a href="#cb46-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Import class MixCOBRA from the mixcobra module of gradientcobra library</span></span>
<span id="cb46-34"><a href="#cb46-34" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gradientcobra.mixcobra <span class="im">import</span> MixCOBRARegressor</span>
<span id="cb46-35"><a href="#cb46-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-36"><a href="#cb46-36" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb46-37"><a href="#cb46-37" aria-hidden="true" tabindex="-1"></a>sns.<span class="bu">set</span>()</span>
<span id="cb46-38"><a href="#cb46-38" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-39"><a href="#cb46-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-40"><a href="#cb46-40" aria-hidden="true" tabindex="-1"></a><span class="fu">## Simulated data</span></span>
<span id="cb46-41"><a href="#cb46-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-42"><a href="#cb46-42" aria-hidden="true" tabindex="-1"></a>We simulate a regression data with $1000$ observations and $10$ inputs variables.</span>
<span id="cb46-43"><a href="#cb46-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-46"><a href="#cb46-46" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb46-47"><a href="#cb46-47" aria-hidden="true" tabindex="-1"></a><span class="co"># For simulating dataset</span></span>
<span id="cb46-48"><a href="#cb46-48" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_regression</span>
<span id="cb46-49"><a href="#cb46-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-50"><a href="#cb46-50" aria-hidden="true" tabindex="-1"></a>X1, y1 <span class="op">=</span> make_regression(n_samples<span class="op">=</span><span class="dv">1000</span>, n_features<span class="op">=</span><span class="dv">10</span>, noise<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb46-51"><a href="#cb46-51" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-52"><a href="#cb46-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-53"><a href="#cb46-53" aria-hidden="true" tabindex="-1"></a>Now, let's randoly split the simulated data into $80\%-20\%$ training-testing data.</span>
<span id="cb46-54"><a href="#cb46-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-57"><a href="#cb46-57" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb46-58"><a href="#cb46-58" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb46-59"><a href="#cb46-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-60"><a href="#cb46-60" aria-hidden="true" tabindex="-1"></a>X_train1, X_test1, y_train1, y_test1 <span class="op">=</span> train_test_split(X1, y1, test_size<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb46-61"><a href="#cb46-61" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'shape: x_train = </span><span class="sc">{}</span><span class="st"> , x_train = </span><span class="sc">{}</span><span class="st"> , y_train = </span><span class="sc">{}</span><span class="st"> , y_test = </span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(</span>
<span id="cb46-62"><a href="#cb46-62" aria-hidden="true" tabindex="-1"></a>    X_train1.shape, </span>
<span id="cb46-63"><a href="#cb46-63" aria-hidden="true" tabindex="-1"></a>    X_test1.shape, </span>
<span id="cb46-64"><a href="#cb46-64" aria-hidden="true" tabindex="-1"></a>    y_train1.shape, </span>
<span id="cb46-65"><a href="#cb46-65" aria-hidden="true" tabindex="-1"></a>    y_test1.shape))</span>
<span id="cb46-66"><a href="#cb46-66" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-67"><a href="#cb46-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-68"><a href="#cb46-68" aria-hidden="true" tabindex="-1"></a><span class="fu">### `MixCOBRARegressor` with default parameters</span></span>
<span id="cb46-69"><a href="#cb46-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-70"><a href="#cb46-70" aria-hidden="true" tabindex="-1"></a>We create <span class="in">`MixCOBRARegressor`</span> object called <span class="in">`gc1`</span>, with the default parameters, then fit it to the training data. </span>
<span id="cb46-71"><a href="#cb46-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-72"><a href="#cb46-72" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Note that by default, we use grid search algorithm to estimate the optimal parameter of the method.</span></span>
<span id="cb46-73"><a href="#cb46-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-74"><a href="#cb46-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-77"><a href="#cb46-77" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb46-78"><a href="#cb46-78" aria-hidden="true" tabindex="-1"></a>gc1 <span class="op">=</span> MixCOBRARegressor()</span>
<span id="cb46-79"><a href="#cb46-79" aria-hidden="true" tabindex="-1"></a>gc1_fit <span class="op">=</span> gc1.fit(X_train1, y_train1)</span>
<span id="cb46-80"><a href="#cb46-80" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-81"><a href="#cb46-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-82"><a href="#cb46-82" aria-hidden="true" tabindex="-1"></a>The estimated optimal bandwidth is given by <span class="in">`gc1.optimization_outputs['opt_bandwidth']`</span>.</span>
<span id="cb46-83"><a href="#cb46-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-86"><a href="#cb46-86" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb46-87"><a href="#cb46-87" aria-hidden="true" tabindex="-1"></a><span class="co"># MixCOBRA with default parameter</span></span>
<span id="cb46-88"><a href="#cb46-88" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Estimated (alpha, beta) = (</span><span class="sc">{}</span><span class="st">, </span><span class="sc">{}</span><span class="st">)"</span>.<span class="bu">format</span>(gc1_fit.optimization_outputs[<span class="st">'opt_alpha'</span>], gc1_fit.optimization_outputs[<span class="st">'opt_beta'</span>]))</span>
<span id="cb46-89"><a href="#cb46-89" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-90"><a href="#cb46-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-91"><a href="#cb46-91" aria-hidden="true" tabindex="-1"></a>We can look at the learning curve (surface) of the algorithm using <span class="in">`draw_learning_curve()`</span> method.</span>
<span id="cb46-92"><a href="#cb46-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-95"><a href="#cb46-95" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb46-96"><a href="#cb46-96" aria-hidden="true" tabindex="-1"></a>gc1_fit.draw_learning_curve()</span>
<span id="cb46-97"><a href="#cb46-97" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-98"><a href="#cb46-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-99"><a href="#cb46-99" aria-hidden="true" tabindex="-1"></a>We evaluate the performance of the method on the testing data using MSE and MAPE.</span>
<span id="cb46-100"><a href="#cb46-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-103"><a href="#cb46-103" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb46-104"><a href="#cb46-104" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_absolute_percentage_error</span>
<span id="cb46-105"><a href="#cb46-105" aria-hidden="true" tabindex="-1"></a>y_pred1 <span class="op">=</span> gc1_fit.predict(X_test1)</span>
<span id="cb46-106"><a href="#cb46-106" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mean_absolute_percentage_error(y_test1, y_pred1))</span>
<span id="cb46-107"><a href="#cb46-107" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mean_squared_error(y_test1, y_pred1))</span>
<span id="cb46-108"><a href="#cb46-108" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-109"><a href="#cb46-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-110"><a href="#cb46-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-111"><a href="#cb46-111" aria-hidden="true" tabindex="-1"></a>Let's look at <span class="in">`qq-plot`</span> of the predictions and the actual response values using <span class="in">`draw_learning_curve()`</span> method.</span>
<span id="cb46-112"><a href="#cb46-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-115"><a href="#cb46-115" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb46-116"><a href="#cb46-116" aria-hidden="true" tabindex="-1"></a>gc1_fit.draw_learning_curve(y_test<span class="op">=</span>y_test1, fig_type<span class="op">=</span><span class="st">'qq'</span>)</span>
<span id="cb46-117"><a href="#cb46-117" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-118"><a href="#cb46-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-119"><a href="#cb46-119" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Use one bandwidth parameter instead of ($\alpha, \beta$)</span></span>
<span id="cb46-120"><a href="#cb46-120" aria-hidden="true" tabindex="-1"></a>You can also try to implement <span class="in">`MixCOBRARegressor`</span> using only one bandwidth parameter. To do so, just set <span class="in">`one_parameter = True`</span> when fitting the method. We create another <span class="in">`MixCOBRARegressor`</span> object with gradient descent optimization method, then fit it on the same data as in the previous case using only one bandwidth parameter as follow.</span>
<span id="cb46-121"><a href="#cb46-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-124"><a href="#cb46-124" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb46-125"><a href="#cb46-125" aria-hidden="true" tabindex="-1"></a><span class="co"># MixCOBRA with one parameter</span></span>
<span id="cb46-126"><a href="#cb46-126" aria-hidden="true" tabindex="-1"></a>gc2 <span class="op">=</span> MixCOBRARegressor(opt_method<span class="op">=</span><span class="st">"grad"</span>)</span>
<span id="cb46-127"><a href="#cb46-127" aria-hidden="true" tabindex="-1"></a>gc2_fit <span class="op">=</span> gc2.fit(X_train1, y_train1, one_parameter<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb46-128"><a href="#cb46-128" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-129"><a href="#cb46-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-130"><a href="#cb46-130" aria-hidden="true" tabindex="-1"></a>Let's compare this to the previous case.</span>
<span id="cb46-131"><a href="#cb46-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-134"><a href="#cb46-134" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb46-135"><a href="#cb46-135" aria-hidden="true" tabindex="-1"></a><span class="co"># MixCOBRA with default parameter</span></span>
<span id="cb46-136"><a href="#cb46-136" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Estimated bandwidth = </span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(gc2_fit.optimization_outputs[<span class="st">'opt_bandwidth'</span>]))</span>
<span id="cb46-137"><a href="#cb46-137" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-138"><a href="#cb46-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-139"><a href="#cb46-139" aria-hidden="true" tabindex="-1"></a>The learning curve.</span>
<span id="cb46-140"><a href="#cb46-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-143"><a href="#cb46-143" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb46-144"><a href="#cb46-144" aria-hidden="true" tabindex="-1"></a>gc2_fit.draw_learning_curve()</span>
<span id="cb46-145"><a href="#cb46-145" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-146"><a href="#cb46-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-147"><a href="#cb46-147" aria-hidden="true" tabindex="-1"></a>Copare the MSE and MAPE.</span>
<span id="cb46-148"><a href="#cb46-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-151"><a href="#cb46-151" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb46-152"><a href="#cb46-152" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_absolute_percentage_error</span>
<span id="cb46-153"><a href="#cb46-153" aria-hidden="true" tabindex="-1"></a>y_pred2 <span class="op">=</span> gc2_fit.predict(X_test1)</span>
<span id="cb46-154"><a href="#cb46-154" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mean_absolute_percentage_error(y_test1, y_pred2))</span>
<span id="cb46-155"><a href="#cb46-155" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mean_squared_error(y_test1, y_pred2))</span>
<span id="cb46-156"><a href="#cb46-156" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-157"><a href="#cb46-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-158"><a href="#cb46-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-159"><a href="#cb46-159" aria-hidden="true" tabindex="-1"></a>Let's look at the <span class="in">`qq-plot`</span>.</span>
<span id="cb46-160"><a href="#cb46-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-163"><a href="#cb46-163" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb46-164"><a href="#cb46-164" aria-hidden="true" tabindex="-1"></a>gc2_fit.draw_learning_curve(y_test<span class="op">=</span>y_test1, fig_type<span class="op">=</span><span class="st">'qq'</span>)</span>
<span id="cb46-165"><a href="#cb46-165" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-166"><a href="#cb46-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-167"><a href="#cb46-167" aria-hidden="true" tabindex="-1"></a><span class="fu">### `MixCOBRARegressor` with non-default parameters</span></span>
<span id="cb46-168"><a href="#cb46-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-169"><a href="#cb46-169" aria-hidden="true" tabindex="-1"></a><span class="in">`MixCOBRARegressor`</span> offers various options to enhance the performance of the method. By default, grid search algorithm is used to estimate the parameters $(\alpha, \beta)$, however, gradient descent algorithm can also be used to optimize the method by setting <span class="in">`opt_method = "grad"`</span> as shown in case of one bandwidth parameter above. Moveover, you can control the hyperparameters of the basic estimators to enhance the aggregation performance just like in <span class="co">[</span><span class="ot">`GradientCOBRA`</span><span class="co">](https://hassothea.github.io/files/CodesPhD/gradientcobra_doc.html)</span> method. This can be done as follows:</span>
<span id="cb46-170"><a href="#cb46-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-171"><a href="#cb46-171" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**learning_rate** : control the learning rate of gradient descent in estimating the bandwidth parameter</span>
<span id="cb46-172"><a href="#cb46-172" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**speed** : the speed of the learning rate.</span>
<span id="cb46-173"><a href="#cb46-173" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**kernel** : the kernel function used for the aggregation</span>
<span id="cb46-174"><a href="#cb46-174" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**opt_method** : the optimiztaion algorithm for estimating the bandwidth. It can be gradient descent (<span class="in">`grad`</span>) or grid search (<span class="in">`grid`</span>).</span>
<span id="cb46-175"><a href="#cb46-175" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**kernel** : kernel function which is <span class="in">`radial`</span> by default. It must be an element of <span class="in">`['exponential', 'gaussian', 'radial', 'cauchy', 'reverse_cosh', 'epanechnikov'`</span>, <span class="in">`'biweight', 'triweight', 'triangular']`</span>.</span>
<span id="cb46-176"><a href="#cb46-176" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**alpha_list** : list or array to search for $\alpha$. </span>
<span id="cb46-177"><a href="#cb46-177" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**beta_list** : list or array to search for $\beta$.</span>
<span id="cb46-178"><a href="#cb46-178" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**bandwidth_list** : : list or array to search for single bandwidth parameter $h$ instead of $(\alpha, \beta)$. To do this, we have to set <span class="in">`one_parameter = True`</span> when fitting the method.</span>
<span id="cb46-179"><a href="#cb46-179" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**max_iter** : maximum iteration in gradient descent.</span>
<span id="cb46-180"><a href="#cb46-180" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**loss_function** : control the type of loss function used for optimizing the bandwidth.</span>
<span id="cb46-181"><a href="#cb46-181" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**opt_params** : control the optimization algorithm such as adjusting <span class="in">`n_cv`</span>, <span class="in">`start`</span>,  <span class="in">`n_tries`</span>...</span>
<span id="cb46-182"><a href="#cb46-182" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**estiamtor_list** : the list of basic estimators used for the aggregation.</span>
<span id="cb46-183"><a href="#cb46-183" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**estimator_params** : controlling the hyperparameters of the basic estimators. It must be a dictionary with <span class="in">`(key, dict) = (estimator, dict)`</span>, i.e. the key must be the name of the basic estimator, and the value is a dictionary containing its hyperparamaters.</span>
<span id="cb46-184"><a href="#cb46-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-185"><a href="#cb46-185" aria-hidden="true" tabindex="-1"></a>We create another object <span class="in">`gc3`</span> with non-default parameters, then fit it to the same training data as in the previous example.</span>
<span id="cb46-186"><a href="#cb46-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-189"><a href="#cb46-189" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb46-190"><a href="#cb46-190" aria-hidden="true" tabindex="-1"></a>gc3 <span class="op">=</span> MixCOBRARegressor(learning_rate<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb46-191"><a href="#cb46-191" aria-hidden="true" tabindex="-1"></a>                    speed<span class="op">=</span><span class="st">"linear"</span>,</span>
<span id="cb46-192"><a href="#cb46-192" aria-hidden="true" tabindex="-1"></a>                    kernel<span class="op">=</span><span class="st">'radial'</span>,</span>
<span id="cb46-193"><a href="#cb46-193" aria-hidden="true" tabindex="-1"></a>                    opt_method<span class="op">=</span><span class="st">'grad'</span>,</span>
<span id="cb46-194"><a href="#cb46-194" aria-hidden="true" tabindex="-1"></a>                    loss_function<span class="op">=</span><span class="st">"weighted_mse"</span>,</span>
<span id="cb46-195"><a href="#cb46-195" aria-hidden="true" tabindex="-1"></a>                    max_iter<span class="op">=</span><span class="dv">300</span>,</span>
<span id="cb46-196"><a href="#cb46-196" aria-hidden="true" tabindex="-1"></a>                    estimator_list<span class="op">=</span>[<span class="st">'random_forest'</span>, </span>
<span id="cb46-197"><a href="#cb46-197" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">'adaboost'</span>, </span>
<span id="cb46-198"><a href="#cb46-198" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">'knn'</span>, </span>
<span id="cb46-199"><a href="#cb46-199" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">'svm'</span>, </span>
<span id="cb46-200"><a href="#cb46-200" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">'lasso'</span>, </span>
<span id="cb46-201"><a href="#cb46-201" aria-hidden="true" tabindex="-1"></a>                                    <span class="st">'ridge'</span>],</span>
<span id="cb46-202"><a href="#cb46-202" aria-hidden="true" tabindex="-1"></a>                    estimator_params<span class="op">=</span>{</span>
<span id="cb46-203"><a href="#cb46-203" aria-hidden="true" tabindex="-1"></a>                        <span class="st">'random_forest'</span> : {</span>
<span id="cb46-204"><a href="#cb46-204" aria-hidden="true" tabindex="-1"></a>                            <span class="st">'n_estimators'</span> : <span class="dv">300</span>,</span>
<span id="cb46-205"><a href="#cb46-205" aria-hidden="true" tabindex="-1"></a>                            <span class="st">'min_samples_leaf'</span> : <span class="dv">10</span>},</span>
<span id="cb46-206"><a href="#cb46-206" aria-hidden="true" tabindex="-1"></a>                        <span class="st">'adaboost'</span> : {</span>
<span id="cb46-207"><a href="#cb46-207" aria-hidden="true" tabindex="-1"></a>                            <span class="st">'n_estimators'</span> : <span class="dv">300</span>,</span>
<span id="cb46-208"><a href="#cb46-208" aria-hidden="true" tabindex="-1"></a>                            <span class="st">'max_depth'</span> : <span class="dv">10</span>},</span>
<span id="cb46-209"><a href="#cb46-209" aria-hidden="true" tabindex="-1"></a>                        <span class="st">'knn'</span> : {</span>
<span id="cb46-210"><a href="#cb46-210" aria-hidden="true" tabindex="-1"></a>                            <span class="st">'n_neighbors'</span> : <span class="dv">30</span>},</span>
<span id="cb46-211"><a href="#cb46-211" aria-hidden="true" tabindex="-1"></a>                            <span class="st">'svm'</span> : {<span class="st">'C'</span> : <span class="dv">7</span>}</span>
<span id="cb46-212"><a href="#cb46-212" aria-hidden="true" tabindex="-1"></a>                    })</span>
<span id="cb46-213"><a href="#cb46-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-214"><a href="#cb46-214" aria-hidden="true" tabindex="-1"></a>gc3_fit <span class="op">=</span> gc3.fit(X_train1, y_train1)</span>
<span id="cb46-215"><a href="#cb46-215" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-216"><a href="#cb46-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-217"><a href="#cb46-217" aria-hidden="true" tabindex="-1"></a>Now, let's compare it to the previous example.</span>
<span id="cb46-218"><a href="#cb46-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-221"><a href="#cb46-221" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb46-222"><a href="#cb46-222" aria-hidden="true" tabindex="-1"></a><span class="co"># MixCOBRA with default parameter</span></span>
<span id="cb46-223"><a href="#cb46-223" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Estimated (alpha, beta) = (</span><span class="sc">{}</span><span class="st">, </span><span class="sc">{}</span><span class="st">)"</span>.<span class="bu">format</span>(gc3_fit.optimization_outputs[<span class="st">'opt_alpha'</span>], gc3_fit.optimization_outputs[<span class="st">'opt_beta'</span>]))</span>
<span id="cb46-224"><a href="#cb46-224" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-225"><a href="#cb46-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-226"><a href="#cb46-226" aria-hidden="true" tabindex="-1"></a>Look at the learning surface using <span class="in">`draw_learning_curve()`</span> method.</span>
<span id="cb46-227"><a href="#cb46-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-230"><a href="#cb46-230" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb46-231"><a href="#cb46-231" aria-hidden="true" tabindex="-1"></a>gc3_fit.draw_learning_curve()</span>
<span id="cb46-232"><a href="#cb46-232" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-233"><a href="#cb46-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-234"><a href="#cb46-234" aria-hidden="true" tabindex="-1"></a>We evaluate the performance of the method on the testing data using MSE and MAPE.</span>
<span id="cb46-235"><a href="#cb46-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-238"><a href="#cb46-238" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb46-239"><a href="#cb46-239" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_absolute_percentage_error</span>
<span id="cb46-240"><a href="#cb46-240" aria-hidden="true" tabindex="-1"></a>y_pred3 <span class="op">=</span> gc3_fit.predict(X_test1)</span>
<span id="cb46-241"><a href="#cb46-241" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mean_absolute_percentage_error(y_test1, y_pred3))</span>
<span id="cb46-242"><a href="#cb46-242" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mean_squared_error(y_test1, y_pred3))</span>
<span id="cb46-243"><a href="#cb46-243" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-244"><a href="#cb46-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-245"><a href="#cb46-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-246"><a href="#cb46-246" aria-hidden="true" tabindex="-1"></a>Let's look at <span class="in">`qq-plot`</span> using <span class="in">`draw_learning_curve()`</span> method.</span>
<span id="cb46-247"><a href="#cb46-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-250"><a href="#cb46-250" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb46-251"><a href="#cb46-251" aria-hidden="true" tabindex="-1"></a>gc3_fit.draw_learning_curve(y_test<span class="op">=</span>y_test1, fig_type<span class="op">=</span><span class="st">'qq'</span>)</span>
<span id="cb46-252"><a href="#cb46-252" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-253"><a href="#cb46-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-254"><a href="#cb46-254" aria-hidden="true" tabindex="-1"></a><span class="fu"># Real dataset</span></span>
<span id="cb46-255"><a href="#cb46-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-256"><a href="#cb46-256" aria-hidden="true" tabindex="-1"></a>We look at the <span class="co">[</span><span class="ot">California</span><span class="co">](https://www.kaggle.com/datasets/camnugent/california-housing-prices)</span> housing dataset from <span class="in">`sklearn.datasets`</span> module. To illustrate the idea, we only work with the first $1000$ observations.</span>
<span id="cb46-257"><a href="#cb46-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-260"><a href="#cb46-260" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb46-261"><a href="#cb46-261" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_california_housing</span>
<span id="cb46-262"><a href="#cb46-262" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> fetch_california_housing()</span>
<span id="cb46-263"><a href="#cb46-263" aria-hidden="true" tabindex="-1"></a>X_real, y_real <span class="op">=</span> data[<span class="st">'data'</span>], data[<span class="st">'target'</span>]</span>
<span id="cb46-264"><a href="#cb46-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-265"><a href="#cb46-265" aria-hidden="true" tabindex="-1"></a>X_train_real, X_test_real, y_train_real, y_test_real <span class="op">=</span> train_test_split(X_real[:<span class="dv">1000</span>,:], y_real[:<span class="dv">1000</span>], test_size<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb46-266"><a href="#cb46-266" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'shape: x_train = </span><span class="sc">{}</span><span class="st"> , x_train = </span><span class="sc">{}</span><span class="st"> , y_train = </span><span class="sc">{}</span><span class="st"> , y_test = </span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(X_train_real.shape, X_test_real.shape, y_train_real.shape, y_test_real.shape))</span>
<span id="cb46-267"><a href="#cb46-267" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-268"><a href="#cb46-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-269"><a href="#cb46-269" aria-hidden="true" tabindex="-1"></a>We gave some random parameters to the method as follows.</span>
<span id="cb46-270"><a href="#cb46-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-273"><a href="#cb46-273" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb46-274"><a href="#cb46-274" aria-hidden="true" tabindex="-1"></a>gc_real <span class="op">=</span> MixCOBRARegressor(opt_method<span class="op">=</span><span class="st">"grad"</span>,</span>
<span id="cb46-275"><a href="#cb46-275" aria-hidden="true" tabindex="-1"></a>                            estimator_list<span class="op">=</span>[<span class="st">'random_forest'</span>, </span>
<span id="cb46-276"><a href="#cb46-276" aria-hidden="true" tabindex="-1"></a>                                            <span class="st">'knn'</span>, </span>
<span id="cb46-277"><a href="#cb46-277" aria-hidden="true" tabindex="-1"></a>                                            <span class="st">'ridge'</span>, </span>
<span id="cb46-278"><a href="#cb46-278" aria-hidden="true" tabindex="-1"></a>                                            <span class="st">'lasso'</span>],</span>
<span id="cb46-279"><a href="#cb46-279" aria-hidden="true" tabindex="-1"></a>                            estimator_params<span class="op">=</span>{</span>
<span id="cb46-280"><a href="#cb46-280" aria-hidden="true" tabindex="-1"></a>                                <span class="st">'random_forest'</span> : {<span class="st">'n_estimators'</span>: <span class="dv">300</span>},</span>
<span id="cb46-281"><a href="#cb46-281" aria-hidden="true" tabindex="-1"></a>                                <span class="st">'knn'</span> : {<span class="st">'n_neighbors'</span> : <span class="dv">30</span>}</span>
<span id="cb46-282"><a href="#cb46-282" aria-hidden="true" tabindex="-1"></a>                        })</span>
<span id="cb46-283"><a href="#cb46-283" aria-hidden="true" tabindex="-1"></a>gc_real_fit <span class="op">=</span> gc_real.fit(X_train_real, y_train_real)</span>
<span id="cb46-284"><a href="#cb46-284" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-285"><a href="#cb46-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-286"><a href="#cb46-286" aria-hidden="true" tabindex="-1"></a>Now, let's look at the obtained bandwidth and the optimization result.</span>
<span id="cb46-287"><a href="#cb46-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-290"><a href="#cb46-290" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb46-291"><a href="#cb46-291" aria-hidden="true" tabindex="-1"></a><span class="co"># MixCOBRA with default parameter</span></span>
<span id="cb46-292"><a href="#cb46-292" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Estimated (alpha, beta) = (</span><span class="sc">{}</span><span class="st">, </span><span class="sc">{}</span><span class="st">)"</span>.<span class="bu">format</span>(gc_real_fit.optimization_outputs[<span class="st">'opt_alpha'</span>], gc_real_fit.optimization_outputs[<span class="st">'opt_beta'</span>]))</span>
<span id="cb46-293"><a href="#cb46-293" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-294"><a href="#cb46-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-295"><a href="#cb46-295" aria-hidden="true" tabindex="-1"></a>We look at the numerical and graphical performance.</span>
<span id="cb46-296"><a href="#cb46-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-299"><a href="#cb46-299" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb46-300"><a href="#cb46-300" aria-hidden="true" tabindex="-1"></a>y_pred_real <span class="op">=</span> gc_real_fit.predict(X_test_real)</span>
<span id="cb46-301"><a href="#cb46-301" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mean_absolute_percentage_error(y_test_real, y_pred_real))</span>
<span id="cb46-302"><a href="#cb46-302" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mean_squared_error(y_test_real, y_pred_real))</span>
<span id="cb46-303"><a href="#cb46-303" aria-hidden="true" tabindex="-1"></a>gc_real_fit.draw_learning_curve(y_test<span class="op">=</span>y_test_real, fig_type<span class="op">=</span><span class="st">'qq'</span>)</span>
<span id="cb46-304"><a href="#cb46-304" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-305"><a href="#cb46-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-306"><a href="#cb46-306" aria-hidden="true" tabindex="-1"></a><span class="fu">### Compare to Adaboost</span></span>
<span id="cb46-307"><a href="#cb46-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-308"><a href="#cb46-308" aria-hidden="true" tabindex="-1"></a>We campare the fitted method on <span class="in">`California`</span> data with Adaboost method.</span>
<span id="cb46-309"><a href="#cb46-309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-312"><a href="#cb46-312" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb46-313"><a href="#cb46-313" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> AdaBoostRegressor</span>
<span id="cb46-314"><a href="#cb46-314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-315"><a href="#cb46-315" aria-hidden="true" tabindex="-1"></a>ada <span class="op">=</span> AdaBoostRegressor(n_estimators<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb46-316"><a href="#cb46-316" aria-hidden="true" tabindex="-1"></a>ada_fit <span class="op">=</span> ada.fit(X_train_real, y_train_real)</span>
<span id="cb46-317"><a href="#cb46-317" aria-hidden="true" tabindex="-1"></a>ada_pred <span class="op">=</span> ada_fit.predict(X_test_real)</span>
<span id="cb46-318"><a href="#cb46-318" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mean_absolute_percentage_error(y_test_real, ada_pred))</span>
<span id="cb46-319"><a href="#cb46-319" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mean_squared_error(y_test_real, ada_pred))</span>
<span id="cb46-320"><a href="#cb46-320" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-321"><a href="#cb46-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-322"><a href="#cb46-322" aria-hidden="true" tabindex="-1"></a><span class="fu"># Pretrained basic estimators</span></span>
<span id="cb46-323"><a href="#cb46-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-324"><a href="#cb46-324" aria-hidden="true" tabindex="-1"></a>You can also train other models then aggregate them using our method. Here, we build pretrained estimators including <span class="in">`XGBoost`</span> then aggregate it to some <span class="in">`sklearn`</span> basic estimators in <span class="in">`MixCOBRARegressor`</span>.</span>
<span id="cb46-325"><a href="#cb46-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-326"><a href="#cb46-326" aria-hidden="true" tabindex="-1"></a>We first split the training data into two parts: $X_k$ for building basic estimators, and $X_\ell$ for aggregation. We use the constructed estimators to predict the test data and both the input $X_{\text{test}}$ and its predictions **pred_feature_test** are used in the final predictions.</span>
<span id="cb46-327"><a href="#cb46-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-330"><a href="#cb46-330" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb46-331"><a href="#cb46-331" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb46-332"><a href="#cb46-332" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor</span>
<span id="cb46-333"><a href="#cb46-333" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb46-334"><a href="#cb46-334" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsRegressor</span>
<span id="cb46-335"><a href="#cb46-335" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeRegressor</span>
<span id="cb46-336"><a href="#cb46-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-337"><a href="#cb46-337" aria-hidden="true" tabindex="-1"></a><span class="co"># X_k and X_l split</span></span>
<span id="cb46-338"><a href="#cb46-338" aria-hidden="true" tabindex="-1"></a>id_k <span class="op">=</span> np.random.permutation(<span class="bu">range</span>(<span class="bu">len</span>(y_train_real)))</span>
<span id="cb46-339"><a href="#cb46-339" aria-hidden="true" tabindex="-1"></a>k <span class="op">=</span><span class="bu">int</span>(<span class="fl">.5</span> <span class="op">*</span> <span class="bu">len</span>(y_train_real))</span>
<span id="cb46-340"><a href="#cb46-340" aria-hidden="true" tabindex="-1"></a>X_k, X_l, y_k, y_l <span class="op">=</span> X_train_real[id_k[:k],:], X_train_real[id_k[k:],:], y_train_real[id_k[:k]], y_train_real[id_k[k:]]</span>
<span id="cb46-341"><a href="#cb46-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-342"><a href="#cb46-342" aria-hidden="true" tabindex="-1"></a><span class="co"># Building basic estiators</span></span>
<span id="cb46-343"><a href="#cb46-343" aria-hidden="true" tabindex="-1"></a>rf_real <span class="op">=</span> RandomForestRegressor(n_estimators<span class="op">=</span><span class="dv">300</span>).fit(X_k, y_k)</span>
<span id="cb46-344"><a href="#cb46-344" aria-hidden="true" tabindex="-1"></a>lm_real <span class="op">=</span> LinearRegression().fit(X_k, y_k)</span>
<span id="cb46-345"><a href="#cb46-345" aria-hidden="true" tabindex="-1"></a>knn_real <span class="op">=</span> KNeighborsRegressor(n_neighbors<span class="op">=</span><span class="dv">10</span>).fit(X_k, y_k)</span>
<span id="cb46-346"><a href="#cb46-346" aria-hidden="true" tabindex="-1"></a>tr_real <span class="op">=</span> DecisionTreeRegressor(min_samples_leaf<span class="op">=</span><span class="dv">5</span>).fit(X_k, y_k)</span>
<span id="cb46-347"><a href="#cb46-347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-348"><a href="#cb46-348" aria-hidden="true" tabindex="-1"></a><span class="co"># External XGBoost estiator</span></span>
<span id="cb46-349"><a href="#cb46-349" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> xgboost </span>
<span id="cb46-350"><a href="#cb46-350" aria-hidden="true" tabindex="-1"></a>xgb <span class="op">=</span> xgboost.XGBRegressor(n_estimators <span class="op">=</span> <span class="dv">500</span>)</span>
<span id="cb46-351"><a href="#cb46-351" aria-hidden="true" tabindex="-1"></a>xgb_real <span class="op">=</span> xgb.fit(X_k, y_k)</span>
<span id="cb46-352"><a href="#cb46-352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-353"><a href="#cb46-353" aria-hidden="true" tabindex="-1"></a><span class="co"># All pretrained estimators</span></span>
<span id="cb46-354"><a href="#cb46-354" aria-hidden="true" tabindex="-1"></a>basic_estimators <span class="op">=</span> (rf_real, lm_real, knn_real, tr_real, xgb_real)</span>
<span id="cb46-355"><a href="#cb46-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-356"><a href="#cb46-356" aria-hidden="true" tabindex="-1"></a><span class="co"># Predicted features on X_l for aggregation</span></span>
<span id="cb46-357"><a href="#cb46-357" aria-hidden="true" tabindex="-1"></a>pred_feature_l <span class="op">=</span> np.column_stack([est.predict(X_l) <span class="cf">for</span> est <span class="kw">in</span> basic_estimators])</span>
<span id="cb46-358"><a href="#cb46-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-359"><a href="#cb46-359" aria-hidden="true" tabindex="-1"></a><span class="co"># Predicted features on Testing data</span></span>
<span id="cb46-360"><a href="#cb46-360" aria-hidden="true" tabindex="-1"></a>pred_feature_test <span class="op">=</span> np.column_stack([est.predict(X_test_real) <span class="cf">for</span> est <span class="kw">in</span> basic_estimators])</span>
<span id="cb46-361"><a href="#cb46-361" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-362"><a href="#cb46-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-363"><a href="#cb46-363" aria-hidden="true" tabindex="-1"></a>To fit the aggregation method on predicted features, we need to provide both input and predicted features to <span class="in">`fit`</span> method.</span>
<span id="cb46-364"><a href="#cb46-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-367"><a href="#cb46-367" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb46-368"><a href="#cb46-368" aria-hidden="true" tabindex="-1"></a>gc4_fit <span class="op">=</span> MixCOBRARegressor(opt_method<span class="op">=</span><span class="st">'grad'</span>).fit(X<span class="op">=</span>X_l,</span>
<span id="cb46-369"><a href="#cb46-369" aria-hidden="true" tabindex="-1"></a>                                                   Pred_features<span class="op">=</span>pred_feature_l,</span>
<span id="cb46-370"><a href="#cb46-370" aria-hidden="true" tabindex="-1"></a>                                                   y<span class="op">=</span>y_l)</span>
<span id="cb46-371"><a href="#cb46-371" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-372"><a href="#cb46-372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-373"><a href="#cb46-373" aria-hidden="true" tabindex="-1"></a>We look at the optimization algorithm performance.</span>
<span id="cb46-374"><a href="#cb46-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-377"><a href="#cb46-377" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb46-378"><a href="#cb46-378" aria-hidden="true" tabindex="-1"></a><span class="co"># MixCOBRA with default parameter</span></span>
<span id="cb46-379"><a href="#cb46-379" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Estimated (alpha, beta) = (</span><span class="sc">{}</span><span class="st">, </span><span class="sc">{}</span><span class="st">)"</span>.<span class="bu">format</span>(gc4_fit.optimization_outputs[<span class="st">'opt_alpha'</span>], gc4_fit.optimization_outputs[<span class="st">'opt_beta'</span>]))</span>
<span id="cb46-380"><a href="#cb46-380" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-381"><a href="#cb46-381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-382"><a href="#cb46-382" aria-hidden="true" tabindex="-1"></a>Now, let's look at the result.</span>
<span id="cb46-383"><a href="#cb46-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-386"><a href="#cb46-386" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb46-387"><a href="#cb46-387" aria-hidden="true" tabindex="-1"></a>pred_add <span class="op">=</span> gc4_fit.predict(X <span class="op">=</span> X_test_real, </span>
<span id="cb46-388"><a href="#cb46-388" aria-hidden="true" tabindex="-1"></a>                           Pred_X <span class="op">=</span> pred_feature_test)</span>
<span id="cb46-389"><a href="#cb46-389" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mean_absolute_percentage_error(y_test_real, pred_add))</span>
<span id="cb46-390"><a href="#cb46-390" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mean_squared_error(y_test_real, pred_add))</span>
<span id="cb46-391"><a href="#cb46-391" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>
